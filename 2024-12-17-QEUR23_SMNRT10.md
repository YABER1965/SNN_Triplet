---
title: QEUR23_SMNRT10: INTRODUCTION～TRIPLETの有効性とは
date: 2024-12-17
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "NSOARTC", "データセット", "外観検査", "Vision language Model"]
excerpt: Siamese Networkをやってみる
---

## QEUR23_SMNRT10: INTRODUCTION～TRIPLETの有効性とは

## ～ より簡単なシステムで、より高い性能を発揮させたい～
	
D先生 ： “なんか、いきなり新シーズンへ移行することになりました。今回も、さらに「内容豊富」になりそうでしようがないですよね(笑)。さて、シーズンの最初になるので、我々の使命（↓）を再確認しましょう。これを忘れちゃいかん・・・。このシーズンは、**Siamese Neural Network(SNN)を使った外観検査自動機の「第2弾」になります**。”

![imageSMR2-1-1](/2024-12-17-QEUR23_SMNRT10/imageSMR2-1-1.jpg)

QEU:FOUNDER ： “例によって、はじめに念を押させてもらいます。われわれのロードマップでは、今回の開発でも**SNNは、ViT(Vision Transformer)の性能を超えることはありません**。なぜなら、SNNでは、**むしろ「より少ないリソースで検査をすることを目指す」から**です。今回も、Tripletの復習が必要？”

![imageSMR2-1-2](/2024-12-17-QEUR23_SMNRT10/imageSMR2-1-2.jpg)

D先生 ： “いきなりシーズンを変えちゃったので、Tripletとは何かについて説明する必要がありますよ。”

![imageSMR2-1-3](/2024-12-17-QEUR23_SMNRT10/imageSMR2-1-3.jpg)

QEU:FOUNDER ： “この記事（↑）は、とてもいいです！絶対おすすめ！！Tripletの意味とSNNのサンプルコードがしっかり載っています。今回は、これをもとに大きく改造して、**「異常検出用」**にしました。さて、Tripletについてだが・・・。”

![imageSMR2-1-4](/2024-12-17-QEUR23_SMNRT10/imageSMR2-1-4.jpg)

QEU:FOUNDER ： “距離の計測において、**アンカー(Anchor)を設けることでより距離が正確になります**。”

D先生 ： “2点計測による距離計測では、ダメなんですか？”

![imageSMR2-1-5](/2024-12-17-QEUR23_SMNRT10/imageSMR2-1-5.jpg)

QEU:FOUNDER ： “2点計測は不確実です。この図（↑）において、外側の楕円が単位空間（均質データ群）とします。プロットが、この楕円の範囲を外れると別のクラスである可能性が出てきます。ここで、黒いプロットは「単位空間のほぼ中心」にあります。緑は、均質空間上で「ぎりぎりセーフ」であり、赤は外れです。さて、ここで質問です。Ｄ先生・・・。この3つの点の距離の関係について説明してください。”

D先生 ： “せっかくだから、アンカー（黒）を中心にして論じたいと思います。黒と赤の距離は遠いですね。それに比較して、黒と緑の距離は近いです。ちなみに、あくまで「マハラノビス距離的な解釈」で論じています。あっ、そうか・・・。C部長・・・、緑と赤の距離と緑と黒の距離について説明してください。”

C部長： “なんか、緑と赤の距離よりも、緑と黒の距離の方が遠くありませんか？緑と黒は同一クラスなのに・・・。”

QEU:FOUNDER ： “だから、2点距離では不正確なケースが発生するんですよ。だから、Tripletではアンカーという点を敢えて設けました。そのかわり、従来の意味の「教師あり学習」とは一風かわったロジックになります。それでは、プログラムにいきましょう。”

```python
# ---
# Exploring the fashion MNIST Data Set
# import necessary libraries
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
# ---
# set random seed
np.random.seed(42)

# load fashion MNIST data
(X_org_train, y_org_train), (X_org_test, y_org_test) = tf.keras.datasets.fashion_mnist.load_data()
#X_org_train.shape
#(60000, 28, 28)
# ---
# combine data first - we will generate test set later.
X = np.concatenate([X_org_train,X_org_test],axis=0)
y = np.concatenate([y_org_train,y_org_test],axis=0)
y = np.squeeze(y)

# ---
# クラスの内訳
arr_class = [
        'T-shirt/top',
        'Trouser',
        'Pullover',
        'Dress',
        'Coat',
        'Sandal',
        'Shirt',
        'Sneaker',
        'Bag',
        'Ankle boot'
        ]
# ---
# Plot Class N (0-9)
TARGET = 5  # Class index here
NUM_ARRAYS = 10

arrays = X[np.where(y==TARGET)]
random_arrays_indices = np.random.choice(len(arrays),NUM_ARRAYS)
random_arrays = arrays[random_arrays_indices]

fig = plt.figure(figsize=[NUM_ARRAYS,4])
plt.title(f'Class {TARGET}: {arr_class[TARGET]}',fontsize = 15)
plt.axis('off')

for index in range(NUM_ARRAYS):
     fig.add_subplot(2, int(NUM_ARRAYS/2), index+1)
     plt.imshow(random_arrays[index])

```

C部長： “ここまでのコードは簡単です。前回のシーズンでも使ったFASHION MNISTの読み込みですね。”

![imageSMR2-1-6](/2024-12-17-QEUR23_SMNRT10/imageSMR2-1-6.jpg)

D先生 ： “もともとのサンプルプログラムでは、CIPAR-10を使っていますよね。なぜ、あえてMNISTに変えたんですか？”

![imageSMR2-1-7](/2024-12-17-QEUR23_SMNRT10/imageSMR2-1-7.jpg)

QEU:FOUNDER ： “D先生、GJ!!この問いは特に重要です。我々は、**画像の判別をしたいわけではない**のです。もし、判別をしたいのであれば、より情報が多いほうがいいです。RGB画像（3チャンネル）は特に有利です。しかし、異常検出の場合には異常度の1チャンネルでいいんです。この差によって、プログラムは大きく改造することになりました。改造は大変だった・・・。”

D先生 ： “じゃあ、つづきにいきましょう。”

```python
####################
# TRIPLETのデータベースを生成する
####################
# ---
def create_indices_on_set(test_labels, i):
    # ---
    # Function to get indices of the same class and create couples of images 
    # Parameters
    # images (np.ndarray): mnist images
    # test_labels(np.ndarray): mnist tags 
    # ---
    # anchor
    anchor_indices = np.where(test_labels == i)[0]   #Get a list of arrays with the indices
    # positive
    positive_indices = anchor_indices
    # negative
    negative_indices = np.where(test_labels != i)[0]   #Get a list of arrays with the indices
    
    return np.array(anchor_indices), np.array(positive_indices), np.array(negative_indices)

# ---
anchor_indices, positive_indices, negative_indices = create_indices_on_set(y, 1)
#print(anchor_indices)

# ---
def select_images_on_set(images, anchor_indices, positive_indices, negative_indices, i):
    # use random choice
    # ---
    # anchor
    index_anchor = np.random.choice(anchor_indices)   
    image_anchor = images[index_anchor]
    # positive
    index_positive = np.random.choice(positive_indices)
    image_positive = images[index_positive]
    # negative
    index_negative = np.random.choice(negative_indices)
    image_negative = images[index_negative]
    
    return image_anchor, image_positive, image_negative

# ---
image_anchor, image_positive, image_negative = select_images_on_set(X, anchor_indices, posi-tive_indices, negative_indices, 1)
print(image_anchor)

# ---
# Generating Triplets
# initialize triplets array
triplets = np.empty((0, 3, 28, 28), dtype=np.uint8)

# get triplets for each class
for target in range(10):
    # ---
    anchor_indices, positive_indices, negative_indices = create_indices_on_set(y, target)
    print("target: ",target)

    # tripletを作成する
    for i in tqdm(range(3000)):
        # 各タイプから1つの画像を取得する
        image_anchor, image_positive, image_negative = select_images_on_set(X, anchor_indices, posi-tive_indices, negative_indices, target)
        triplet = np.array([image_anchor, image_positive, image_negative])
        triplets = np.append(triplets, [triplet], axis=0)

# ---
# save triplet array(ORIGINAL)
name_triplet = 'triplets_fasion_MNIST_array.npy'
path_triplet = "drive/MyDrive/"+name_triplet
np.save(path_triplet,triplets)

####################
# 生のグレースケール画像を出力する
####################
# ---
# plot triplets array to visualize
TEST_SIZE = 5
random_indices = np.random.choice(len(triplets),TEST_SIZE)

fig = plt.figure(figsize=[5,2*TEST_SIZE])
plt.title(' ANCHOR  |  POSITIVE  |  NEGATIVE ',fontsize = 15)
plt.axis('off')

for row,i in enumerate(range(0,TEST_SIZE*3,3)):
    for j in range(1,4):
        fig.add_subplot(TEST_SIZE, 3, i+j)
        random_index = random_indices[row]
        plt.imshow(triplets[random_index,j-1])

```

QEU:FOUNDER ： “ここまでのプログラムで、**「ANCHOR-POSITIVE-NEGATIVE」**で形成されたデータベースができるんです。”

![imageSMR2-1-8](/2024-12-17-QEUR23_SMNRT10/imageSMR2-1-8.jpg)

D先生 ： “画像にすると、より分かりやすくなります。それにしても、アンカーって、こんなにフラフラ動いていいのかな？アンカーって、動かないんじゃないんですか？”

QEU:FOUNDER ： “・・・（笑）。コードをさらに進めましょう。ここでは、ちょっと「変な処理」をやります。”

```python
####################################
# 平坦化されたtripletからモデルを学習する
####################################
# ---
# Preparing for Model Training/Evaluation
# Import all libraries
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm

# ---
import keras
#from keras.applications import MobileNetV2
from keras import Input, optimizers, Model
from keras.layers import Layer, Dense, Lambda
from keras.ops import norm
from tensorflow.keras.optimizers import Adam
from keras.models import Sequential, Model
from keras.saving import register_keras_serializable
# ---
import tensorflow as tf
from tensorflow.keras import backend as K
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.utils import plot_model

# ---
from sklearn.metrics import precision_recall_curve, roc_curve, roc_auc_score
from sklearn.model_selection import train_test_split
from scipy import spatial

# ---
# save triplet array
name_triplet = 'triplets_fasion_MNIST_array.npy'
path_triplet = "drive/MyDrive/"+name_triplet
# ---
# 必要ならばtripletファイルをloadすること
org_triplets = np.load(path_triplet)
org_triplets = org_triplets/255 #normalize by 255
labels = np.ones(len(org_triplets)) #create a fixed label

# ---
# IMAGE SIZE
image_size = 28*28

# ---
# Generating Triplets
# initialize triplets array
triplets = np.empty((0, 3, image_size))

# get triplets for each class
for i in tqdm(range(30000)):
    # ---
    image_anchor = org_triplets[i,0,:,:].flatten()
    image_positive = org_triplets[i,1,:,:].flatten()
    image_negative = org_triplets[i,2,:,:].flatten()
    #print("image_negative: ", image_negative)
    # ---
    triplet = np.array([image_anchor, image_positive, image_negative])
    triplets = np.append(triplets, [triplet], axis=0)

# ---
# save triplet array(FLATTEN)
name_triplet = 'triplets_fasion_MNIST_flatten.npy'
path_triplet = "drive/MyDrive/"+name_triplet
np.save(path_triplet,triplets)

# データをトレーニングセットとテストセットに分割する
labels = np.ones(len(triplets)) #create a fixed label
X_train, X_test, y_train, y_test = train_test_split(
    triplets,
    labels,
    test_size=0.05,
    random_state=42
)

```

D先生 ： “おなじ処理をまたやったんですか？次は、**「平坦化(flatten)」**させて・・・。”

QEU:FOUNDER ： “せっかく1チャンネルにしたのだから、より簡単にさせたいと思って・・・。我々は、**NSOARTCメトリックスによる合成画像を入力するのだから、SNNモデルに畳み込みをさせる必要もない**と思うんですよ。つぎは、ディープラーニングのモデルの構造を見てみましょう。”

```python
# ---
# (これは、あえて参考に出しています)
# Load pretrained model for transfer learning
# 転移学習用に事前学習済みモデルをロードする
#pretrained_model = MobileNetV2(
#    weights='imagenet', 
#    include_top=False, 
#    input_shape=(28,28)
#)    
#for layer in pretrained_model.layers:
#    layer.trainable = True

# ---
# Define the model
model = Sequential(
    [
        Input(shape=(image_size,)),
        Dense(512, activation="relu"),
        Dense(256, activation="relu"),
        Dense(128, activation=None),
    ]
)

# ---
# Model Training
# Lambdaレイヤーの関数を初期化する
@register_keras_serializable()
def cosine_distance(x,y):
    x = K.l2_normalize(x, axis=-1)
    y = K.l2_normalize(y, axis=-1)
    distance = 1 - K.batch_dot(x, y, axes=-1)
    return distance

# ---
@register_keras_serializable()
def triplet_loss(templates, margin=0.4):
    
    anchor,positive,negative = templates
    
    positive_distance = cosine_distance(anchor,positive)
    negative_distance = cosine_distance(anchor,negative)
    
    basic_loss = positive_distance-negative_distance+margin
    loss = K.maximum(basic_loss,0.0)
    
    return loss


# Define inputs
anchor = Input(shape=(image_size,), name='anchor_input')
A = model(anchor)

positive = Input(shape=(image_size,), name='positive_input')
P = model(positive)

negative = Input(shape=(image_size,), name='negative_input')
N = model(negative)

# Compute distance using Lambda layer with output_shape specified
loss = Lambda(triplet_loss)([A, P, N])
model = Model(inputs=[anchor,positive,negative],outputs=loss)

# ---
# グラウンドトゥルースラベルがないのでカスタム損失関数を作成する
# Define loss function for serialization
@register_keras_serializable()
def identity_loss(y_true, y_pred):
    return K.mean(y_pred)

model.compile(loss=identity_loss, optimizer=Adam(learning_rate=3e-5))
callbacks=[EarlyStopping(
    patience=2, 
    verbose=1, 
    restore_best_weights=True,
    monitor='val_loss'
    )]

# view model
plot_model(model, show_shapes=True, show_layer_names=True, to_file='siamese_triplet_loss_model.png')

```

QEU:FOUNDER ： “例によって、モデルの構造を図にしました。**アタマが3つ**ありますね。”

![imageSMR2-1-9](/2024-12-17-QEUR23_SMNRT10/imageSMR2-1-9.jpg)

D先生 ： “もともとのプログラムでは、モデルとして「MobileNetV2」を使っていたのか・・・。贅沢ですね。”

QEU:FOUNDER ： “MobileNetV2はRGBの3チャンネル用だから、使えないんです。もしも、1チャンネル用があれば、あえて使ったのかもしれないです。いよいよ、学習を始めましょう。”

```python
# ---
# トレーニングを開始 - ここで、y_train と y_test はダミー(すべて1)です
history = model.fit(
    x=[X_train[:,0],X_train[:,1],X_train[:,2]],
    y=y_train,
    epochs=10,
    batch_size=32,
    validation_data=([X_test[:,0],X_test[:,1],X_test[:,2]],y_test),
    callbacks=callbacks
)

# ---
# トレーニング中のトレーニング損失と検証損失をプロットできます。
# ---
plt.plot(history.history["loss"])
plt.plot(history.history["val_loss"])
plt.title("Training and Validation Loss")
plt.ylabel("loss")
plt.xlabel("epoch")
plt.legend(["train", "val"], loc="upper right")
plt.show()

```

C部長： “たった10エポックしか学習しないのですか？こんなに、スムーズに損失が減るのであれば、もっと続けられるでしょうに・・・。”

![imageSMR2-1-10](/2024-12-17-QEUR23_SMNRT10/imageSMR2-1-10.jpg)

D先生 ： “まあ、あくまでテストだから・・・。それにしても、コメントにある「ここで、y_train と y_test はダミー(すべて1)です」というのは、どういう意味ですか？”

QEU:FOUNDER ： “TRIPLETを採用したことで、通常の教師あり学習のようにラベルを付けられなくなったんですよ。そこで、いちおうダミーとしてラベルの値をすべて１としています。ここで、正確度をみてみましょう。”

D先生 ： “ダミーでしょ？意味あるのかなあ・・・。他のやりかたで評価するしかないですね。”

```python
# ---
# Model Evaluation
# ターゲットは初めのPOSITIVEは1とする。次のNEGATIVEは0とする。
X_test_anchor = X_test[:,0]
X_test_positive = X_test[:,1]
X_test_negative = X_test[:,2]

# extract the CNN model for inference
siamese_model = model.layers[3]

X_test_anchor_template = np.squeeze(siamese_model.predict(X_test_anchor))
X_test_positive_template = np.squeeze(siamese_model.predict(X_test_positive))
X_test_negative_template = np.squeeze(siamese_model.predict(X_test_negative))

y_test_targets = np.concatenate([np.ones((len(X_test),)),np.zeros((len(X_test),))])

# ---
# 角度類似度スコアで予測を取得する。
def angular_similarity(template1,template2):
    
    score = np.float32(1-np.arccos(1-spatial.distance.cosine(template1,template2))/np.pi)
    
    return score

y_predict_targets = []

for index in range(len(X_test)):
    similarity = angular_similarity(X_test_anchor_template[index],X_test_positive_template[index])
    y_predict_targets.append(similarity)
    
for index in range(len(X_test)):
    similarity = angular_similarity(X_test_anchor_template[index],X_test_negative_template[index])
    y_predict_targets.append(similarity)

# ---
# テスト データに対するモデルの精度を計算できます。（TRIPLET:この値の意味合いは検討中）
accuracy = keras.metrics.BinaryAccuracy()
accuracy.update_state(y_test_targets, y_predict_targets)
print(f"Accuracy: {accuracy.result().numpy():.2f}")

```

QEU:FOUNDER ： “そこで、TRIPLET用の評価方法にしました。”

![imageSMR2-1-11](/2024-12-17-QEUR23_SMNRT10/imageSMR2-1-11.jpg)

D先生 ： “たしかに、やり方としては間違ってはいないです。正式には、**Embeddingを使って評価**すべきだと思います。”

QEU:FOUNDER ： “それは、次回に・・・。”

![imageSMR2-1-12](/2024-12-17-QEUR23_SMNRT10/imageSMR2-1-12.jpg)

C部長 ： “そうだ！！**アンカーとして、平均画像を使いましょう**！！！”


QEU:FOUNDER ： “それも、次回に・・・。”



## ～ まとめ ～

C部長 : “この件（↓）、おもわず笑いましたね。”

[![MOVIE1](http://img.youtube.com/vi/z4NzPgHmANc/0.jpg)](http://www.youtube.com/watch?v=z4NzPgHmANc "【破綻】斉藤元彦知事会見に矛盾指摘続々！「誰が斎藤氏に投票したのか？」社会学者が分析【LIVE】朝刊全部買ってみた！12月15日")

QEU:FOUNDER ： “・・・（笑）。前回の選挙で、**「頭のいい人ほどハメられた」**んだよね。そりゃ、そうでしょう・・・。”

![imageSMR2-1-13](/2024-12-17-QEUR23_SMNRT10/imageSMR2-1-13.jpg)


C部長 : “**「パワハラ特区」**ですからね。偉い人ほど、パワハラは組織と社会にとって不可欠と思っています。”

![imageSMR2-1-14](/2024-12-17-QEUR23_SMNRT10/imageSMR2-1-14.jpg)

QEU:FOUNDER ： “思えば、前回の選挙って別の場所でも重要な選挙があったでしょう？考えてみれば、あの場所も「特区」でした・・・。これを、**「天の配剤」**というのでしょうか。”

[![MOVIE2](http://img.youtube.com/vi/rT-aJfWUsmk/0.jpg)](http://www.youtube.com/watch?v=rT-aJfWUsmk "【体罰は善なんよ】戸塚ヨットスクールの戸塚宏がYouTubeを始めるもヤバすぎる！！！")

C部長 : “この人（↑）、懐かしいですね。”

QEU:FOUNDER ： “「パワハラ特区」・・・。上は、こんな感じ（↓）だし・・・。”

![imageSMR2-1-15](/2024-12-17-QEUR23_SMNRT10/imageSMR2-1-15.jpg)

C部長 : “下はこんな感じ（↓）だし・・・。”

![imageSMR2-1-16](/2024-12-17-QEUR23_SMNRT10/imageSMR2-1-16.jpg)

QEU:FOUNDER ： “なるほど、**偉い人ほど「パワハラ大好き」と思うわけだ**。やっぱり、あの選挙は「天の配剤」・・・。”
