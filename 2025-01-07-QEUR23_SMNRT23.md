---
title: QEUR23_SMNRT23 : 学習したSNNモデルでEmbeddingを使って予測する(外観検査)
date: 2025-01-07
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "NSOARTC", "データセット", "外観検査", "Vision language Model"]
excerpt: Siamese Networkをやってみる
---

## QEUR23_SMNRT23 : 学習したSNNモデルでEmbeddingを使って予測する(外観検査)

## ～ やはり、予測にはEmbeddingを使うに限る ～

QEU:FOUNDER ： “前回で、Siamese Neural Network(SNN)でモデルを学習させました。今回は、実際に予測精度を評価しましょう。”

**(参考: Simple-128でのConfusion Matrix)**

![imageSMR2-14-1](/2025-01-07-QEUR23_SMNRT23/imageSMR2-14-1.jpg)

D先生 ： “Simpleな学習モデルでは60％程度のAccuracyでした。今回のSNNでは、どの程度レベルアップがなされるのか？”

QEU:FOUNDER ： “Siameseの場合、モデルから直接の予測結果が出ないので、**Embeddingを経由**させましょう。今回のコードの晒しも、重要な変化がある部分だけです。”

```python
# ---
# Install and import required dependencies
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset, Subset
# ---
import math
import time
import multiprocessing

# ---
####################################
# HUGGINGFACE DATASET を生成する
####################################
# ---
# NumPy配列からHugging Face Datasetの作成
data_dict = {
    "features": list(map(list, shuffled_X)),  # 各レコードの特徴をリストに変換
    "label": shuffled_label.tolist()                # ラベルをリストに変換
}

# Hugging Face Datasetの作成
dataset = Dataset.from_dict(data_dict)
transformed_dataset = dataset.with_format("torch")

# Apply transformations
def collate_fn(example):
    example["image"] = example["features"].reshape(36,39)
    example["label"] = set_label.index(example["label"])
    return example

# ---
transformed_dataset = transformed_dataset.map(collate_fn, num_proc=multiprocessing.cpu_count())
transformed_dataset = transformed_dataset.remove_columns("features")
#transformed_dataset[0]

# ---
##################################
# NETWORKS FUNCTIONS
##################################
# ---
# https://www.kaggle.com/code/faduregis/mnist-digit-classification-in-pytorch
# build model
class EmbeddingNet(nn.Module):
    def __init__(self):
        super(EmbeddingNet,self).__init__()
        self.linear1 = nn.Linear(36*39, 512) # 36 * 39 is the pixels for each image
        self.linear2 = nn.Linear(512, 256) #100 and 5o
        self.linear3 = nn.Linear(256, 256) #100 and 5o
        self.final = nn.Linear(256, 128)
        self.relu = nn.ReLU()
# Here we are just feeding the data into each layer, and returning the output, while defining an in-stance of this class.
# ここでは、このクラスのインスタンスを定義しながら、各レイヤーにデータを入力し、出力を返すだけです。
    def forward(self, img): #convert + flatten
        x = img.view(-1, 36*39)
        x = self.relu(self.linear1(x))
        x = self.relu(self.linear2(x))
        x = self.relu(self.linear3(x))
        x = self.final(x)
        return x

    def get_embedding(self, x):
        return self.forward(x)

class SiameseNet(nn.Module):
    def __init__(self, embedding_net):
        super(SiameseNet, self).__init__()
        self.embedding_net = embedding_net

    def forward(self, x1, x2):
        output1 = self.embedding_net(x1)
        output2 = self.embedding_net(x2)
        return output1, output2

    def get_embedding(self, x):
        return self.embedding_net(x)

################################
# MODEL INSTANCE SETTING
################################
# ---
# Set up the network and training parameters
# ---
embedding_net = EmbeddingNet()
model = SiameseNet(embedding_net)
cuda = torch.cuda.is_available()
if cuda:
    model.cuda()

# ----
# モデル定義が必要
model.load_state_dict(torch.load('drive/MyDrive/siamese_gaikan_model.pth'))
model.eval()

```

QEU:FOUNDER ： “前回で、モデルの重みを保存しています。今回は、モデルの構造を設定して、その後にモデルの重みを呼び出します。”

![imageSMR2-14-2](/2025-01-07-QEUR23_SMNRT23/imageSMR2-14-2.jpg)

D先生 ： “GPUは使ったんですか？”

QEU:FOUNDER ： “おおっ、そうだった・・・。計算を早くするためにGPUを使いました。ちなみに、GPUを使って学習したモデルは、予測のために呼び出したときも同じGPUが必要になる可能性があります。それでは、プログラムのつづきをドン・・・。個別の予測をしましょう。”

```python
#########################################
# ANCHORのベクトル群を生成する
# TARGET = 以下のラベルのデータ群の平均値ベクトルとなる
# label: [0, 11, 13, 21, 23, 31, 32, 33, 42, 61, 62, 63, 71, 72, 73, 81, 82, 91, 92]
#########################################
# ---
def create_anchors(dataset, TARGET):
    # ---
    # 条件をもとにフィルタリング
    cut_dataset = dataset.filter(lambda example: example["label"]==TARGET)
    # ---
    # データセットの確認
    cut_image = cut_dataset["image"]
    #print(cut_image.shape)
    cut_label = cut_dataset["label"]
    #print(cut_label)
    # ---
    # anchorを生成する
    anchor_X = torch.zeros([cut_image.shape[1], cut_image.shape[2]])
    for i in range(cut_image.shape[1]):
        for j in range(cut_image.shape[2]):
            anchor_X[i,j] = torch.mean(cut_image[:,i,j])
    #print(anchor_X)

    return anchor_X.shape[0], anchor_X

# ---
# 平均画像を変数に保管する
anchor_Xs = []
arr_Xnum  = [] 
for TARGET in range(n_classes):
    num_Xs, mx_anchor = create_anchors(transformed_dataset, TARGET)
    anchor_Xs.append(mx_anchor)
    arr_Xnum.append(num_Xs)

################################
# anchor_embeddingベクトルを生成する
################################
# ---
anchor_embedding = np.zeros([n_classes, 128])
for i in range(n_classes):
    # ---
    cut_anchor = anchor_Xs[i]
    tensor_x = torch.unsqueeze(cut_anchor,1)
    #print(tensor_x)
    # ---
    anchor_embedding[i, :] = model.get_embedding(tensor_x.cuda()).data.cpu().numpy()
# ---
print(anchor_embedding.shape)

################################
# ユークリッド距離を計算する(1.個別)
################################
# ---
# ひとつのデータを抽出する
def individual_process(i, dataset, anchor_embedding, anchor_Xs):
    # ---
    # データセットの確認
    sample_image = dataset[i]["image"]
    sample_index = dataset[i]["label"]
    #print(sample_index)
    # ---
    arr_dist = []
    for j in range(n_classes):
        anchor_image = anchor_Xs[j]
        tensor_x = torch.unsqueeze(sample_image,1)
        # ---
        sample_embedding = model.get_embedding(tensor_x.cuda()).data.cpu().numpy()
        #print(sample_embedding.flatten())
        # ---
        val_dist = distance.euclidean(anchor_embedding[j], sample_embedding.flatten())
        arr_dist.append(round(val_dist,5))
        print(f"j: {j}, Distance: {val_dist}")
    # ---
    print("--- ACTUAL DATA, Distance ---")
    print(f"iCount: {i}, arr_dist: {arr_dist}")
    print("--- MIN_INDEX ---")
    index = np.argmin(arr_dist)
    anchor_image = anchor_Xs[index]
    pred_label = set_label[index]
    print(f"INDEX: {index}, LABEL: {pred_label}")
    # ---
    fig = plt.figure(figsize=[10,5])
    plt.suptitle(f"    ANCHOR    |    MEASUREMENT   |   LABEL: {pred_label}",fontsize = 15)
    # ---
    # ANCHOR
    fig.add_subplot(1, 2, 1)
    plt.imshow(anchor_image, cmap='hot', interpolation='nearest')
    plt.axis('off')
    # ---
    # SAMPlE
    fig.add_subplot(1, 2, 2)
    plt.imshow(sample_image , cmap='hot', interpolation='nearest')
    plt.axis('off')
    # ---
    # ヒートマップを表示
    plt.tight_layout()   
    plt.show()

# ---
# ひとつのデータを抽出する
i = 1100
individual_process(i, transformed_dataset, anchor_embedding, anchor_Xs)

```

D先生 ： “個別予測の場合には、画像を出してくれるんですね。ここで、ANCHORというのはTRIPLETの用語ですね。”

![imageSMR2-14-3](/2025-01-07-QEUR23_SMNRT23/imageSMR2-14-3.jpg)

QEU:FOUNDER ： “**各ラベルの平均ベクトル**です。すべてのラベルのベクトルを「総当たり」にして、ユークリッド距離を計測します。そして、距離がもっとも小さなラベルを予測結果とします。”

D先生 ： “いまのところは、うまく行っているようです。”

QEU:FOUNDER ： “さてと・・・。仕上げとして、Confusion Matrixの生成です。”

```python
################################
# ユークリッド距離を計算する(2.バッチ)
################################
# ---
# バッチ・データを抽出する
def batch_process(i, dataset, anchor_embedding):
    # ---
    # データセットの確認
    sample_image = dataset[i]["image"]
    sample_index = dataset[i]["label"]
    #print(sample_index)
    # ---
    arr_dist = []
    for j in range(n_classes):
        anchor_image = anchor_Xs[j]
        tensor_x = torch.unsqueeze(sample_image,1)
        # ---
        sample_embedding = model.get_embedding(tensor_x.cuda()).data.cpu().numpy()
        #print(sample_embedding.flatten())
        # ---
        val_dist = distance.euclidean(anchor_embedding[j], sample_embedding.flatten())
        arr_dist.append(round(val_dist,5))
        #print(f"j: {j}, Distance: {val_dist}")
    # ---
    index = np.argmin(arr_dist)
    anchor_image = anchor_Xs[index]
    pred_label = set_label[index]
    #print(f"i: {i}, INDEX: {index}, LABEL: {pred_label}")

    return pred_label, set_label[sample_index]

# ---
# バッチ・データを抽出するを抽出する
arr_pred = []
arr_actual = []
for i in range(1000):
    pred_y, actual_y = batch_process(i, transformed_dataset, anchor_embedding)
    #print(f"i: {i}, pred: {pred_y}, actual: {actual_y}")
    arr_pred.append(pred_y)
    arr_actual.append(actual_y)
# ---
print(arr_pred)
print(arr_actual)

################################
# CREATING CONFUSION MATRIX
################################
# ---
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
#import numpy as np

# 混同行列の生成
cm = confusion_matrix(arr_actual, arr_pred)

# Confusion matrixの表示
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)

# X軸ラベル、Y軸ラベル、タイトルの追加
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')

# Confusion matrixの表示
plt.show()

```

D先生 ： “これが結果ですね。すばらしい結果です。”

![imageSMR2-14-4](/2025-01-07-QEUR23_SMNRT23/imageSMR2-14-4.jpg)

QEU:FOUNDER ： “本当は、評価用のデータを新しく準備するべきなのだが・・・。”

D先生 ： “でも、SIMPLEモデルと同じ評価方法でしょ？・・・であるならば、相対評価にはなります。”

![imageSMR2-14-5](/2025-01-07-QEUR23_SMNRT23/imageSMR2-14-5.jpg)

QEU:FOUNDER ： “まあ、しゃあない・・・。面倒くさいのでサボっていたが、**TEST用のデータセットをつくりました**。さきほどの正確度は、我々がこれから話を展開するには値が良すぎます。それでは、結果だけをドン！！”

![imageSMR2-14-6](/2025-01-07-QEUR23_SMNRT23/imageSMR2-14-6.jpg)

D先生 ： “すこしだけパフォーマンスが落ちました。それでも、十分によい数字です。これから、何をしますか？”

QEU:FOUNDER ： “それは、次回のお楽しみ・・・。”


## ～ まとめ ～

QEU:FOUNDER ： “これは良い話ですね。ただし、主題の表現がよくないです。「C国流ものづくりを学ぶ」って・・・。”

![imageSMR2-14-7](/2025-01-07-QEUR23_SMNRT23/imageSMR2-14-7.jpg)

C部長 : “正確には、**「より高度なものづくりを学ぶためにC国に教えを乞う」**でしょうね。“

QEU:FOUNDER ： “大正時代から始まるTPS流の**「根性、パワハラ、すり合わせでモノを作る」**というのは、すでに古いでしょうに・・・。あらゆる意味で、すでに遅れを取っていることを認識しなければ・・・。”

![imageSMR2-14-8](/2025-01-07-QEUR23_SMNRT23/imageSMR2-14-8.jpg)

C部長 : “すでにJ国の学校は、C国の学生に全面降伏状態です。そりゃあ、そうでしょう。J国の政府は、J国の大学生に勉強させるかわりにバイトをさせたいそうですから・・・。 “

![imageSMR2-14-9](/2025-01-07-QEUR23_SMNRT23/imageSMR2-14-9.jpg)

QEU:FOUNDER ： “**こんな愚かな議論が国会上で議論される国は他にあるのだろうか？**V国にも笑われるぜ、あのAI界のスーパースター（↓）が所属する大学のアシスタントの名前を見てみて？”

![imageSMR2-14-10](/2025-01-07-QEUR23_SMNRT23/imageSMR2-14-10.jpg)

C部長 : “おやおや・・・（笑）。 “

![imageSMR2-14-11](/2025-01-07-QEUR23_SMNRT23/imageSMR2-14-11.jpg)

QEU:FOUNDER ： “例の知日の彼（↑）がポストしている日頃のコメントは、もっと真剣に受け取らないとねえ・・・。まあ、無理か・・・。**J国スゴイ！勉強よりバイト！**”

