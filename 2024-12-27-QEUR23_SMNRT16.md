---
title: QEUR23_SMNRT16 –  TRIPLETを使ったSNN学習をやってみた
date: 2024-12-27
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "NSOARTC", "データセット", "外観検査", "Vision language Model"]
excerpt: Siamese Networkをやってみる
---

## QEUR23_SMNRT16 –  TRIPLETを使ったSNN学習をやってみた

## ～ なんと、SNNが「評価不能」という結果に・・・ ～

D先生 ： “前回は、「若干の閑話休題」としてSOART3メトリックスの高次の距離（gamma）を使ったときにおいて、モデルの学習精度をアップさせることができるかを検討しました。今回の本題の前に、前回内容を、すこしだけ補足しましょうか・・・。”

![imageSMR2-7-1](/2024-12-24-QEUR23_SMNRT15/imageSMR2-7-1.jpg)

QEU:FOUNDER ： “なるほど・・・。今回の実験の結果を考察する場合の前提になりますからね。今回は、MNISTのような画像判別ではなく、異常検出のためにSiamese Neural Network(SNN)モデルを使用します。重要なコトをいいます！！**画像判別と異常検出は全く違う技術です。**前回の「閑話休題」は、その異常検出のためにRT法を使用したらどうなるかという試みでした。”

**(RT法とは？)**

![imageSMR2-7-2](/2024-12-24-QEUR23_SMNRT15/imageSMR2-7-2.jpg)

**(RTを使うメリット)**

- 対象（標準、計測）図形が極めて似ていること
- 対象図形がブロブ（輪郭が閉じた図形）であること。
- 対象図形の画素値がより１に近く、背景がより0に近い
- 対象図形の主要な差異が回転であること

QEU:FOUNDER ： “タグチメソッドのRT法は、外観検査に適したメトリックスを生成してくれます。最終的には、このメトリックスをSNNに活用したい。ただし、このようなカスタム・メトリックをモデルに導入することは、意外と技術的に難しいのです。だから、今回は従来のユーグリッド距離の適用までやりたいです。さて、これから今回の本題（実験）に入りますが、最初に学習データを生成しなければなりません。Tripletの学習データは、すでにHugging Face(HF)にアップしています。ただし、今回は、このデータを生成したプログラムを公開しません。”

![imageSMR2-7-3](/2024-12-24-QEUR23_SMNRT15/imageSMR2-7-3.jpg)

D先生 ： “いままでのプログラムの延長ですから、まあ不要でしょう。ただ単にデータの量を変えて、さらにHFへのアップロード機能を追加するだけです。HFにアップロードする際には、「データの構造を変えなければならない」ことについてだけは、気を付けたほうがいいですね。”

![imageSMR2-7-4](/2024-12-24-QEUR23_SMNRT15/imageSMR2-7-4.jpg)

QEU:FOUNDER ： “それでは、学習用のプログラムをドン！！”

```python
# ---
# Exploring the fashion MNIST Data Set
# import necessary libraries
import tensorflow as tf
import numpy as np
import pandas as pd
from tqdm import tqdm
import matplotlib.pyplot as plt
from datasets import Dataset, load_dataset
# ---
# set random seed
np.random.seed(42)

# ---
####################
# データフレームdfから、学習に必要なXs,Ysを分解する関数
####################
# ---
def create_train_data(load_df):
    # ---
    anchor = load_df.loc[:,'arch0':'arch1403'].values.tolist()
    positive = load_df.loc[:,'pos0':'pos1403'].values.tolist()
    negative = load_df.loc[:,'neg0':'neg1403'].values.tolist()
    # ---
    triplet = []
    for i in range(len(load_df)):
        arr_anchor = anchor[i]
        arr_positive = positive[i]
        arr_negative = negative[i]
        triplet.append([arr_anchor, arr_positive, arr_negative])
    #print(X)

    label = load_df.loc[:,'plabel':'nlabel'].values
    #print(label[0:20])

    fmode = load_df.loc[:,'pmode':'nmode'].values
    #print(fmode[0:20])

    return np.array(triplet), label, fmode

# ---
dataset = load_dataset('YxBxRyXJx/TRIPLET_Tanshi_1226', split='train')
#print(datasets)
# ---
# データセットをPandasのデータフレームに変換
org_df = pd.DataFrame(dataset)  # 'train'分割を使用する場合
print(len(org_df))

# ---
# データフレームの行をランダムにシャッフル
train_df = org_df.sample(frac=1).reset_index(drop=True)
# シャッフルされたデータフレームの表示
#print(train_df)

# ---
# Train - Xs,Ysに分解する
# ---
train_triplet, train_label, train_fmode = create_train_data(train_df)
#print(train_triplet)
print(train_triplet.shape)
print(train_label)
print(train_fmode)

# ---
def create_test_data(load_df):
    # ---
    X = load_df.loc[:,'data0':'data1403'].values
    #print(X)

    label = load_df.loc[:,'label'].values
    #print(label[0:20])

    fmode = load_df.loc[:,'fmode'].values
    #print(fmode[0:20])

    return X, label, fmode

# ---
# データを分解する
# ---
dataset = load_dataset('YxBxRyXJx/NSOARTC_Tanshi_1221', split='train')
#print(datasets)
# ---
# データセットをPandasのデータフレームに変換
test_df = pd.DataFrame(dataset)  # 'train'分割を使用する場合
# データフレームの行をランダムにシャッフル
test_df = test_df.sample(frac=1).reset_index(drop=True)
# ---
# X-Y分解(シャッフル)
test_X, test_label, test_fmode = create_test_data(test_df)
print(test_label[0:20])

####################
# TRIPLETをヒートマップ表示する
####################
# ---
# plot triplets array to visualize
TEST_SIZE = 5
random_indices = np.random.choice(len(train_triplet),TEST_SIZE)

fig = plt.figure(figsize=[5,2*TEST_SIZE])
plt.title(' ANCHOR  |  POSITIVE  |  NEGATIVE ',fontsize = 15)
plt.axis('off')

for row,i in enumerate(range(0,TEST_SIZE*3,3)):
    for j in range(1,4):
        fig.add_subplot(TEST_SIZE, 3, i+j)
        plt.imshow(train_triplet[row,j-1].reshape(36,39), cmap='hot', interpolation='nearest')
# ---
# ヒートマップを表示
plt.show()

```

QEU:FOUNDER ： “このまでのプログラムでは、データセットから読み込んだTRIPLETデータをヒートマップにしました。ただし、ここで読み込んだTRIPLETデータは1次元ベクトルであり、ヒートマップにするために、一時的に2次元に変換しています。”

![imageSMR2-7-5](/2024-12-24-QEUR23_SMNRT15/imageSMR2-7-5.jpg)

QEU:FOUNDER ： “すでに説明したとおり、**ANCHORとは平均画像**です。POSITIVEは、**平均画像とおなじ不良位置のレコード**であり、**NEGATIVEは異なる位置のレコード**になります。つづきに行きましょう。いよいよ、この学習データを使って、SNNモデルを学習させます。”

```python
####################################
# 平坦化されたtripletからモデルを学習する
####################################
# ---
# Preparing for Model Training/Evaluation
# Import all libraries
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm

# ---
import keras
from keras import Input, optimizers, Model
from keras.layers import Layer, Dense, Lambda
from keras.ops import norm
from tensorflow.keras.optimizers import Adam
from keras.models import Sequential, Model
from keras.saving import register_keras_serializable
# ---
import tensorflow as tf
from tensorflow.keras import backend as K
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.utils import plot_model
# ---
from sklearn.metrics import precision_recall_curve, roc_curve, roc_auc_score
from sklearn.model_selection import train_test_split
from scipy import spatial

# ---
# Split data into our train and test set
# データをトレーニングセットとテストセットに分割する
labels = np.ones(len(train_triplet)) #create a fixed label
X_train, X_test, y_train, y_test = train_test_split(
    train_triplet,
    labels,
    test_size=0.05,
    random_state=42
)

# ---
image_size = 1404
# ---
# Define the model
model = Sequential(
    [
        Input(shape=(image_size,)),
        Dense(512, activation="relu"),
        Dense(256, activation="relu"),
        Dense(128, activation=None),
    ]
)

# ---
# Register the custom function for serialization
@register_keras_serializable()
def euclidean_distance(twin1_output, twin2_output):
    """Compute the euclidean distance (norm) of the output of
    the twin networks.
    """
    return tf.sqrt(tf.reduce_sum(tf.square(twin1_output - twin2_output), axis=1, keepdims=True))

# ---
@register_keras_serializable()
def triplet_loss(templates, margin=0.4):
    
    anchor,positive,negative = templates
    positive_distance = euclidean_distance(anchor,positive)
    negative_distance = euclidean_distance(anchor,negative)

    basic_loss = positive_distance-negative_distance+margin
    loss = K.maximum(basic_loss,0.0)
    
    return loss

# ---
# Define inputs
anchor = Input(shape=(image_size,), name='anchor_input')
A = model(anchor)

positive = Input(shape=(image_size,), name='positive_input')
P = model(positive)

negative = Input(shape=(image_size,), name='negative_input')
N = model(negative)

# Compute distance using Lambda layer with output_shape specified
loss = Lambda(triplet_loss, output_shape=(1,))([A, P, N])
model = Model(inputs=[anchor,positive,negative],outputs=loss)

# ---
# Create a custom loss function since there are no ground truths label
# グラウンドトゥルースラベルがないのでカスタム損失関数を作成する
# Define loss function for serialization
@register_keras_serializable()
def identity_loss(y_true, y_pred):
    return K.mean(y_pred)

model.compile(loss=identity_loss, optimizer=Adam(learning_rate=3e-5))
callbacks=[EarlyStopping(
    patience=2, 
    verbose=1, 
    restore_best_weights=True,
    monitor='val_loss'
    )]

# view model
plot_model(model, show_shapes=True, show_layer_names=True, to_file='siamese_triplet_euclid_loss_model.png')

# ---
# トレーニングを開始 - ここで、y_train と y_test はダミー(すべて1)です
history = model.fit(
    x=[X_train[:,0],X_train[:,1],X_train[:,2]],
    y=y_train,
    epochs=20,
    batch_size=32,
    validation_data=([X_test[:,0],X_test[:,1],X_test[:,2]],y_test),
    callbacks=callbacks
)

# ---
# トレーニング中のトレーニング損失と検証損失をプロットできます。
# ---
plt.plot(history.history["loss"])
plt.plot(history.history["val_loss"])
plt.title("Training and Validation Loss")
plt.ylabel("loss")
plt.xlabel("epoch")
plt.legend(["train", "val"], loc="upper right")
plt.show()

```

D先生 ： “これがSNNモデルがデータを学習した結果ですね。損失量の推移をみると、非常にスムーズに損失低下しています。”

![imageSMR2-7-6](/2024-12-24-QEUR23_SMNRT15/imageSMR2-7-6.jpg)

QEU:FOUNDER ： “それでは、つづいて予測の正確度の評価です。以前と同じ方法を使っています。”

```python
# ---
# Model Evaluation
# ターゲットは初めのPOSITIVEは1とする。次のNEGATIVEは0とする。
X_test_anchor = X_test[:,0]
X_test_positive = X_test[:,1]
X_test_negative = X_test[:,2]

# extract the CNN model for inference
siamese_model = model.layers[3]

X_test_anchor_template = np.squeeze(siamese_model.predict(X_test_anchor))
X_test_positive_template = np.squeeze(siamese_model.predict(X_test_positive))
X_test_negative_template = np.squeeze(siamese_model.predict(X_test_negative))

y_test_targets = np.concatenate([np.ones((len(X_test),)),np.zeros((len(X_test),))])

# ---
# 角度類似度スコアで予測を取得する。
def angular_similarity(template1,template2):
    score = np.float32(1-np.arccos(1-spatial.distance.cosine(template1,template2))/np.pi)   
    return score

y_predict_targets = []

for index in range(len(X_test)):
    similarity = angular_similarity(X_test_anchor_template[index],X_test_positive_template[index])
    y_predict_targets.append(similarity)
    
for index in range(len(X_test)):
    similarity = angular_similarity(X_test_anchor_template[index],X_test_negative_template[index])
    y_predict_targets.append(similarity)

# ---
# テスト データに対するモデルの精度を計算できます。（TRIPLET:この値の意味合いは検討中）
accuracy = keras.metrics.BinaryAccuracy()
accuracy.update_state(y_test_targets, y_predict_targets)
print(f"Accuracy: {accuracy.result().numpy():.2f}")

```

QEU:FOUNDER ： “どれぐらいの正確度になると思う？”

D先生 ： “80％ぐらいじゃないですか？”

![imageSMR2-7-7](/2024-12-24-QEUR23_SMNRT15/imageSMR2-7-7.jpg)

D先生 ： “えーっ！？なんや？この精度は！？”

![imageSMR2-7-8](/2024-12-24-QEUR23_SMNRT15/imageSMR2-7-8.jpg)

QEU:FOUNDER ： “そもそもの真実の評価を**COSIN類似度で評価している**でしょ？そもそも、外観検査の場合には、COSIN類似度がどこまで信頼できるのかという問題があるよね。”

D先生 ： “まあ確かに・・・。その問題がありますよね。”

QEU:FOUNDER ： “そもそも、今回の（Euclid距離による）SNNモデル学習で高いの予測精度がでてくるのかについて、小生には大いに疑問があるんですがね。何はともあれ、**Embeddingを使った評価に切り替えましょう**。次回につづく・・・。”


## ～ まとめ ～

QEU:FOUNDER ： “たしかに、これ（↓）は大スクープだが、意外感がないのは小生だけか？”

[![MOVIE1](http://img.youtube.com/vi/ck2xNUaRHPo/0.jpg)](http://www.youtube.com/watch?v=ck2xNUaRHPo "12/25緊急ライブ！中居正広「9000万円SEXトラブル」の真相")

C部長 : “あの放送局でしょ？あるあるです。”

![imageSMR2-7-9](/2024-12-24-QEUR23_SMNRT15/imageSMR2-7-9.jpg)

D先生: “令和の今はイケていない、この放送局だが、昔はハチャメチャで人気があったんですよ。我々、オッサン世代にとって、ぜんぜん違和感がないです。”

![imageSMR2-7-10](/2024-12-24-QEUR23_SMNRT15/imageSMR2-7-10.jpg)

QEU:FOUNDER ： “個人が悪いのではなく、**J国の根本にかかわるプラットフォームの問題**だよね。ある意味で**「とうとうきたね・・・。」感があります**。J国かかわる「あらゆる問題の根本が同じである」ことが見えてきているんですよ。”

![imageSMR2-7-11](/2024-12-24-QEUR23_SMNRT15/imageSMR2-7-11.jpg)

C部長 : “お～っと！これは、いい話だ！！”

QEU:FOUNDER ： “これを素直に喜べるの？ひょっとしたら、この話（↓）と表裏の可能性があるよ。”

![imageSMR2-7-12](/2024-12-24-QEUR23_SMNRT15/imageSMR2-7-12.jpg)

QEU:FOUNDER ： “**J国経済の「ソ連化」**・・・。”

C部長 : “ずっと昔に崩壊した国の話を・・・。”

![imageSMR2-7-13](/2024-12-24-QEUR23_SMNRT15/imageSMR2-7-13.jpg)

QEU:FOUNDER ： “たまたま、twitterに**「若き日のY先生」の動画**があったので見ながら思ったんです。D先生、この講義の動画（↑）は、Youtubeの中にありましたか？”

D先生： “FOUNDERから言われたので探したのですが見つかりませんでした。テレビの画面で見たかったのに残念・・・。それにしても、**「国が税収入を大きくして、その収入をお友達企業にばらまく」**というのは**ソ連的です**よね。昔は、特別会計がソ連的であったのだが、それが**一般会計にまで広がってきた**感じです。”

QEU:FOUNDER ： “特別会計は人々の目にふれないのだが、一般会計の場合には人々の間に触れてしまいます。つまり、一定レベルの人々の支持がないと出来ないんですよ。”

D先生: “**「あの会社が儲かっている。スゴイ！！だから、J国スゴイ」**という、合理的な根拠のない「お気持ち」ですね。”

![imageSMR2-7-14](/2024-12-24-QEUR23_SMNRT15/imageSMR2-7-14.jpg)

QEU:FOUNDER ： “**「パワハラ、ミソジニー、お気持ち・・・」**と・・・。J国が世界にリードする分野があってよかったですね。”

[![MOVIE2](http://img.youtube.com/vi/WnjDBLrV1jY/0.jpg)](http://www.youtube.com/watch?v=WnjDBLrV1jY "「お気持ち帝国」大ニッポン90年の没落")

QEU:FOUNDER ： “**「身を切るカイカク」**で税を減らすことを目指す一方で、自分たちが旗を振る万博では**「お友達には大盤振る舞い」**しています。たしかに、彼らは半分左翼、**「下半身がソ連的」**ですね。C部長、この前はイケメンが好きだと言ってませんでしたか？”

![imageSMR2-7-15](/2024-12-24-QEUR23_SMNRT15/imageSMR2-7-15.jpg)

C部長 : “嘘だー！！もう、年の瀬にもなって、いや～な話やなあ・・・。”

