---
title: QEUR23_SMNRT21 :  PyTorchと高次元Embeddingモデルで外観検査画像を予測する`
date: 2025-01-05
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "NSOARTC", "データセット", "外観検査", "Vision language Model"]
excerpt: Siamese Networkをやってみる
---

## QEUR23_SMNRT21 :  PyTorchと高次元Embeddingモデルで外観検査画像を予測する

## ～ 高次元のEmbeddingベクトルの持つ意味は？ ～

### ・・・ 前回のつづきです ・・・

QEU:FOUNDER  ： “ラベル番号が0というのは「合格品」という意味です。この混同マトリックスが（↓）意味するものは、「学習したモデルには識別能力は全然なく、予測の結果はベースとなる合格品のまま」というモデルの分解能不足を現しています。Embeddingの生成結果を見てみますか？”

![imageSMR2-12-1](/2025-01-05-QEUR23_SMNRT21/imageSMR2-12-1.jpg)

D先生 ： “このままでは、（Embeddingは）無意味ですね”

QEU:FOUNDER ： “それでは、対策としてモデルの構造を少しだけ改善します。前回のプログラムの一部だけを変更するよ・・・。”

```python
##################################
# NETWORKS FUNCTIONS
##################################
# ---
# https://www.kaggle.com/code/faduregis/mnist-digit-classification-in-pytorch
# build model
class EmbeddingNet(nn.Module):
    def __init__(self):
        super(EmbeddingNet,self).__init__()
        self.linear1 = nn.Linear(36*39, 256) #36 * 39 is the pixels for each image
        self.linear2 = nn.Linear(256, 256) #100 and 5o
        self.final = nn.Linear(256, 128)
        self.relu = nn.ReLU()
# Here we are just feeding the data into each layer, and returning the output, while defining an in-stance of this class.
# ここでは、このクラスのインスタンスを定義しながら、各レイヤーにデータを入力し、出力を返すだけです。
    def forward(self, img): #convert + flatten
        x = img.view(-1, 36*39)
        x = self.relu(self.linear1(x))
        x = self.relu(self.linear2(x))
        x = self.final(x)
        return x

    def get_embedding(self, x):
        return self.forward(x)

# ---
class ClassificationNet(nn.Module):
    def __init__(self, embedding_net, n_classes):
        super(ClassificationNet, self).__init__()
        self.embedding_net = embedding_net
        self.n_classes = n_classes
        self.nonlinear = nn.PReLU()
        self.fc1 = nn.Linear(128, n_classes)

    def forward(self, x):
        output = self.embedding_net(x)
        output = self.nonlinear(output)
        scores = F.log_softmax(self.fc1(output), dim=-1)
        return scores

    def get_embedding(self, x):
        return self.nonlinear(self.embedding_net(x))

```

QEU:FOUNDER ： “‘どこが変わったのか、わかった？”

D先生 ： “はい。前回の2という数字が、128に変わりましたね。そういえば、この2という数字は、散布図を生成するために、たった2次元のEmbeddingベクトルを出力するという意図でした。そして、この構造は、MNIST(10種類)の単純な画像の判別には、うまく機能しました。”

![imageSMR2-12-2](/2025-01-05-QEUR23_SMNRT21/imageSMR2-12-2.jpg)

QEU:FOUNDER ： “今回は、外観検査への対応として、Embeddingベクトルを128次元まで増加させました。今回のような外観検査の課題では、Embeddingベクトルの次元数を上げないと、うまく予測できないんですよ。つまり、**「より高次元の情報がないと識別ができない」**んです。つづいて、今回のモデルをと買ったパフォーマンス評価として、Confusion Matrixを見てみましょう。プログラムはすでに紹介したので、今回は省略します。”

![imageSMR2-12-3](/2025-01-05-QEUR23_SMNRT21/imageSMR2-12-3.jpg)

QEU:FOUNDER ： “ねえ・・・。今回は、前回よりも判別能力が相当あがっているでしょ？逆にいうと、前回は如何にメチャクチャなことをしていたかということなんだが・・・（笑）。”

D先生 ： “つまり、前回のプログラムの問題点は、モデルの出力ベクトルを低次元（2次元）にしたからですね。複雑な構造の画像情報を、とてつもなく少ないパラメータに情報を集約させ過ぎたんです。じゃあ、今回のプログラムではEmbeddingの散布図を作成することができますよね・・・。”

**（参考、前回の結果です）**

![imageSMR2-12-4](/2025-01-05-QEUR23_SMNRT21/imageSMR2-12-4.jpg)

QEU:FOUNDER ： “いや・・・。そう簡単には行かないです。今回のモデルで出力されるEMBEDDINGベクトルは128次元なので、散布図で差異を検出するには、**PCA（主成分分析）**を使って、2次元の情報量を集約する必要があります。それでは、PCA用のプログラムをドン！！”

```python
# ---
torch_dataset = TensorDataset(transformed_dataset["image"], transformed_dataset["label"])

########################################
# CREATE DATALOADER
########################################
# ---
# Baseline: Classification with softmax
# Set up data loaders
batch_size = 16
kwargs = {'num_workers': 2, 'pin_memory': True} if cuda else {}
dataset_loader = torch.utils.data.DataLoader(torch_dataset, batch_size=batch_size, shuffle=True, **kwargs)

# ---
##########################################
# RVALUATING BY EMBEDDING
##########################################
# ---
def extract_embeddings(dataloader, model):
    with torch.no_grad():
        model.eval()
        embeddings = np.zeros((len(dataloader.dataset), 128))
        labels = np.zeros(len(dataloader.dataset))
        k = 0
        for images, target in dataloader:
            if cuda:
                images = images.cuda()
            embeddings[k:k+len(images)] = model.get_embedding(images).data.cpu().numpy()
            labels[k:k+len(images)] = target.numpy()
            k += len(images)
    return embeddings, labels

#####################################
# EVALUATING RESULT
#####################################
# ---
ds_embeddings, ds_labels = extract_embeddings(train_loader, model)

# ---
from sklearn.decomposition import PCA
# PCAの実行
pca = PCA()
X_pca = pca.fit_transform(ds_embeddings)
# 主成分が説明する分散の割合を表示
print(pca.explained_variance_ratio_)

# ---
# PCA散布図をプロットする
def plot_embeddings(embeddings, targets, mnist_classes):
    plt.figure(figsize=(8,6))
    for i in range(len(mnist_classes)):
        inds = np.where(targets==i)[0]
        plt.scatter(embeddings[inds,0], embeddings[inds,1], alpha=0.5, color=colors[i])
    plt.xlabel('Principal Component 1')
    plt.ylabel('Principal Component 2')
    plt.title('2D Scatter Plot of the First Two Principal Components')
    plt.legend(mnist_classes)
    plt.show()

# ---
# グラフを生成する
plot_embeddings(X_pca, ds_labels, mnist_classes)

```

D先生 ： “やっと、EMBEDDINGベクトルで、ある程度の不良検出が可能なレベルに来ていますね。”

![imageSMR2-12-5](/2025-01-05-QEUR23_SMNRT21/imageSMR2-12-5.jpg)

QEU:FOUNDER ： “グラフの真ん中に分布するプロットが「OK（合格品）」の状態です。そして、**周囲に向かって、4つの「腕」が伸びています**。ちょっと意外でしたね。X方向とY方向への倒れ以外にも異常モードがあるんですね。”

![imageSMR2-12-6](/2025-01-05-QEUR23_SMNRT21/imageSMR2-12-6.jpg)

D先生 ： “あとで吟味するのも面白そうです。ただし、この分布から異常検出そのものは簡単であることがわかりました。おそらく、「ある種の距離メトリックス」を使えば、高精度の異常検出ができるでしょう。もちろん、異常モードは問いません。”

QEU:FOUNDER ： “じゃあ、前回と同様にユーグリッド距離を使って、異常の判定能力の評価をやってみる？”

D先生 ： “今回はやめましょう。もう、データを使いきってしまいました・・・（笑）。”

QEU:FOUNDER ： “じゃあ、次回のSiamese Neural Networkのプロジェクトでやってみましょう。データ量を増やすことができますからね。”


## ～ まとめ ～

QEU:FOUNDER ： “新年なので、2024年から始まる「九運」について調べてみた。”

C部長 : “**（三元）九運って、風水の概念でしょ？**あと、九運って、「よくないことばかり起こる」と聞きました。“

![imageSMR2-12-7](/2025-01-05-QEUR23_SMNRT21/imageSMR2-12-7.jpg)

QEU:FOUNDER ： “そうでもないと思うよ。過去をさかのぼると、「太平天国の乱」、「名誉革命」、「ルネッサンス」、「パックス・モンゴリカ」がそれにあたります。”

C部長 : “へえ・・・。名誉革命って、「Glorious Revolution」と呼ぶんですか・・・。あの・・・。そもそも、Revolutionって、どういう意味なんでしょうね？ “

![imageSMR2-12-8](/2025-01-05-QEUR23_SMNRT21/imageSMR2-12-8.jpg)

QEU:FOUNDER ： “Revolutionの語源は、「回転(round)」です。つまり、**「太平天国」と「名誉革命」は上から下への回転**です。**「パックス・モンゴリカ」と「ルネサンス」は東から西への回転**です。”

C部長 : “じゃあ、今回の場合は？ひょっとして・・・。”

![imageSMR2-12-9](/2025-01-05-QEUR23_SMNRT21/imageSMR2-12-9.jpg)

C部長 : “**北から南への回転でしょうね。**”

[![MOVIE1](http://img.youtube.com/vi/SNVc0of_gmg/0.jpg)](http://www.youtube.com/watch?v=SNVc0of_gmg "2025年超予測（前編）】混乱が当たり前に／20、30％の賃上げも／トランプ関税は杞憂／TOBが広がる／1ドル200円の時代")

QEU:FOUNDER ： “いやいや・・・、立派な御仁のご意見をありがたく拝聴しました。**「とにかく働け」というメッセージだけ**をいただきました・・・（笑）。”

![imageSMR2-12-10](/2025-01-05-QEUR23_SMNRT21/imageSMR2-12-10.jpg)

C部長 : “200円/ドルに行く原因が**「国力の低下」**ですか・・・。もっと早く、なんとかできたんじゃない？国力の低下を防ぐために・・・。”

![imageSMR2-12-11](/2025-01-05-QEUR23_SMNRT21/imageSMR2-12-11.jpg)

QEU:FOUNDER ： “**そんな能力がないから、いまになって若い人に対して「とにかく働け」というしかない**んでしょうに・・・（笑）。もちろん、為替の件は、十分にありうると思いますよ。世界のバランスが変わるのが、九運だから・・・。”
