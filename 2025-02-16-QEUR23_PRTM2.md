---
title: QEUR23_PRTM2 - ディープラーニングモデルをタテにならべる(Simulation Data)
date: 2025-02-16
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "NSOARTC", "データセット", "外観検査", "Vision language Model"]
excerpt: Siamese Networkをやってみる
---

## QEUR23_PRTM2 - ディープラーニングモデルをタテにならべる(Simulation Data)

## ～ これは、「中間的な結論」になります ～

D先生 ： “それでは、次のステップに行きましょう。**「外観検査に適したディープ・ラーニング」**とは何か？”

QEU:FOUNDER ： “いきなり外観検査の情報を使うのも大変なので、簡単なシミュレーション・データを使って、学習と性能評価をやってみましょう。あたらしくデータセット（↓）を作りました。”

![imagePRTM0-3-1](/2025-02-16-QEUR23_PRTM2/imagePRTM0-3-1.jpg)

D先生 ： “おや？さっきまで使っていたデータセットでは、X(feature)は1種類でした。今度は2種類を使っています。これはSimulationによる生成情報ですよね？何をしたのですか？”

QEU:FOUNDER ： “それでは、データの生成に注目してdataset生成プログラムの一部をみてみましょう。”

```python
# ---
# Create dataset
from sklearn.datasets import make_blobs
from datasets import Dataset, DatasetDict, Features, Value, Image
import numpy as np
import pandas as pd
from huggingface_hub import HfApi, HfFolder

# ---
def create_dataset(val_samples, val_centers, val_features):

    # Generate synthetic data
    Xw, Y = make_blobs(n_samples=val_samples, centers=val_centers, n_features=val_features, clus-ter_std=4.5, random_state=0)

    # Convert to list of lists for features
    Xw_list = Xw.tolist()

    # ---
    Xb_list = []
    for i in range(val_samples):
        arr_Xb = np.random.normal(0.5, 0.25, 10).tolist()
        Y_index = int(Y[i]) 
        arr_Xb[Y_index] = arr_Xb[Y_index] + 0.55
        for j, val_Xb in enumerate(arr_Xb):
            if val_Xb < 0:
                arr_Xb[j] = 0.001 
        
        Xb_list.append(arr_Xb)

    # Create a Pandas DataFrame
    df = pd.DataFrame({'feature-1': Xw_list, 'feature-2': Xb_list, 'labels': Y})

    # Convert Pandas DataFrame to Hugging Face Dataset
    dataset = Dataset.from_pandas(df)
    
    return dataset

# ---
val_centers = 10
val_features = 10

dataset_train = create_dataset(2000, val_centers, val_features)
dataset_test = create_dataset(500, val_centers, val_features)
print(dataset_train)

```

QEU:FOUNDER ： “「feature-1」と「feature-2」のデータの特性は、ロジックを見ればわかるように、全く違うんですよ。つまり、特性値の「1と2は独立」です。ただし、具体的に、2種のなにが違うのかは説明しません。自分でプログラムを動かして、生成された情報を調べてください。さて、お次はディープラーニングのプログラムに移ります。”

D先生 ： “なにを改造したんですか？わくわく・・・。”

```python
# ---
# Preprocess data
def preprocess_data(dataset):
    images_1 = []
    images_2 = []
    labels = []
    for item in dataset:
        image_1 = item['feature-1']
        image_2 = item['feature-2']
        label = item['labels']
        images_1.append(image_1)  
        images_2.append(image_2)  
        labels.append(label)
    # ---
    images_1 = np.array(images_1)
    images_2 = np.array(images_2)
    labels = np.array(labels)
    return images_1, images_2, labels

Xw_train, Xb_train, y_train = preprocess_data(train_dataset)
Xw_test, Xb_test, y_test = preprocess_data(test_dataset)
print(Xw_train[0])
print(Xb_train[0])

###############################
# ROUTINE FOR NNWeight
###############################
# ---
# Neural Network class
class NNWeight:
    def __init__(self, input_size, hidden_size1, hidden_size2, output_size, learning_rate=0.01):
        self.input_size = input_size
        self.hidden_size1 = hidden_size1
        self.hidden_size2 = hidden_size2
        self.output_size = output_size
        self.learning_rate = learning_rate

        # Initialize weights
        self.weights_input_hidden1 = np.random.randn(self.input_size, self.hidden_size1) * 0.01
        self.bias_hidden1 = np.zeros((1, self.hidden_size1))
        self.weights_hidden1_hidden2 = np.random.randn(self.hidden_size1, self.hidden_size2) * 0.01
        self.bias_hidden2 = np.zeros((1, self.hidden_size2))
        self.weights_hidden2_output = np.random.randn(self.hidden_size2, self.output_size) * 0.01
        self.bias_output = np.zeros((1, self.output_size))

    def relu(self, x):
        return np.maximum(0, x)

    def relu_derivative(self, x):
        return (x > 0).astype(float)

    def softmax(self, x):
        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))  # Prevent overflow
        return exp_x / np.sum(exp_x, axis=1, keepdims=True)

    def forward(self, X):
        # First hidden layer
        self.hidden_input1 = np.dot(X, self.weights_input_hidden1) + self.bias_hidden1
        self.hidden_output1 = self.relu(self.hidden_input1)

        # Second hidden layer
        self.hidden_input2 = np.dot(self.hidden_output1, self.weights_hidden1_hidden2) + self.bias_hidden2
        self.hidden_output2 = self.relu(self.hidden_input2)

        # Output layer
        self.output_input = np.dot(self.hidden_output2, self.weights_hidden2_output) + self.bias_output
        self.output_output = self.softmax(self.output_input)

        return self.output_output

    def backward(self, X, y, output):
        # Calculate error
        output_error = output - self.one_hot_encode(y)

        # Backpropagation to second hidden layer
        hidden2_error = np.dot(output_error, self.weights_hidden2_output.T)
        hidden2_delta = hidden2_error * self.relu_derivative(self.hidden_output2)

        # Backpropagation to first hidden layer
        hidden1_error = np.dot(hidden2_delta, self.weights_hidden1_hidden2.T)
        hidden1_delta = hidden1_error * self.relu_derivative(self.hidden_output1)

        # Update weights (with L2 regularization)
        self.weights_hidden2_output -= self.learning_rate * np.dot(self.hidden_output2.T, output_error)
        self.bias_output -= self.learning_rate * np.sum(output_error, axis=0, keepdims=True)
        
        self.weights_hidden1_hidden2 -= self.learning_rate * np.dot(self.hidden_output1.T, hid-den2_delta)
        self.bias_hidden2 -= self.learning_rate * np.sum(hidden2_delta, axis=0, keepdims=True)

        self.weights_input_hidden1 -= self.learning_rate * np.dot(X.T, hidden1_delta)
        self.bias_hidden1 -= self.learning_rate * np.sum(hidden1_delta, axis=0, keepdims=True)

    def one_hot_encode(self, y):
        one_hot = np.zeros((len(y), self.output_size))
        one_hot[np.arange(len(y)), y] = 1
        return one_hot

    def predict(self, X):
        output = self.forward(X)
        return np.argmax(output, axis=1)
        
    def predict_detail(self, X):
        output = self.forward(X)
        return output

    def calculate_loss(self, y_predicted, y_actual):
         # Cross-entropy loss
        num_samples = len(y_actual)
        loss = -np.sum(y_actual * np.log(y_predicted)) / num_samples
        return loss

    def evaluate(self, X_test, y_test):
        y_pred = self.predict(X_test)
        accuracy = np.mean(y_pred == y_test)
        return accuracy

```

D先生 ： “あれ？前回までは、活性化関数としてsigmoid関数を使っていましたよね。”

![imagePRTM0-3-2](/2025-02-16-QEUR23_PRTM2/imagePRTM0-3-2.jpg)

QEU:FOUNDER ： “活性化関数を変えたのは、feature-2系のデータを学習したときに、**Sigmoid関数では予測パフォーマンスが全然伸びなかった**からです。ReLUは、最近よく使われているのだが、その理由がわかりました。すごくいいですよ。”

D先生 ： “でも、モデルの変更部分がそれだけ？なんかしら、「新しいディープラーニングの地平（笑）」を期待したのに・・・。”

QEU:FOUNDER ： “え～っと・・・。プログラムの晒しをつづきます。”

```python
# ---
# Parameters
input_size = 10
hidden_size1 = 64  # First hidden layer size
hidden_size2 = 32  # Second hidden layer size (newly added)
output_size = 10   # 0-9 digits
learning_rate = 0.005
epochs = 100
batch_size = 32

# Train the model(Weight)
nnw = NNWeight(input_size=input_size,
                   hidden_size1=hidden_size1,
                   hidden_size2=hidden_size2,
                   output_size=output_size,
                   learning_rate=learning_rate)

# ---
num_samples = len(Xw_train)
for epoch in range(epochs):
    for i in range(0, num_samples, batch_size):
        Xw_batch = Xw_train[i:i + batch_size]
        Xb_batch = Xb_train[i:i + batch_size]
        y_batch  = y_train[i:i + batch_size]

        # Forward pass
        output = nnw.forward(Xw_batch)

        # Backward pass
        nnw.backward(Xw_batch, y_batch, output)

    if epoch % 5 == 0:
        loss = nnw.calculate_loss(nnw.forward(Xw_train), nnw.one_hot_encode(y_train))
        print(f"NNWeight - Epoch {epoch}, Loss: {loss}")

# ---
# OUTPUT: See the output balance
label_out = y_test[0:10]
print(f"label_out: {label_out[0:10]}")
# ---
X_input = Xw_test
Yw_out = nnw.predict_detail(X_input)
print(f"Yw_out: {Yw_out[0:10]}")

```

QEU:FOUNDER ： “ここまでの処理結果を見てみましょう。”

![imagePRTM0-3-3](/2025-02-16-QEUR23_PRTM2/imagePRTM0-3-3.jpg)

D先生 ： “ここまでは、前回とおなじ「feasure-1」の情報を学習しています。しいてプログラムのロジック差を上げると、いきなり分類のラベルを出力させずに、**各ラベルの予測確率を出力している**ことだけです。そして、肝心のfeature-1予測精度は？”

![imagePRTM0-3-4](/2025-02-16-QEUR23_PRTM2/imagePRTM0-3-4.jpg)

QEU:FOUNDER ： “準備したデータのバラツキのレベルを調整して、90%ちょいの精度にしました。これからが、今回の本題です。新しい概念のディープラーニング・プログラムはつづきます・・・。”

```python
# ---
# Train the model(Bias)
nnb = NNBias(input_size=input_size,
                   hidden_size1=hidden_size1,
                   hidden_size2=hidden_size2,
                   output_size=output_size,
                   learning_rate=learning_rate)

# ---
num_samples = len(Xb_train)
for epoch in range(epochs):
    for i in range(0, num_samples, batch_size):
        Xw_batch = Xw_train[i:i + batch_size]
        Xb_batch = Xb_train[i:i + batch_size]
        y_batch  = y_train[i:i + batch_size]

        # Forward pass
        output = nnb.forward(Xb_batch)

        # Backward pass
        nnb.backward(Xb_batch, y_batch, output)

    if epoch % 5 == 0:
        loss = nnb.calculate_loss(nnb.forward(Xb_train), nnb.one_hot_encode(y_train))
        print(f"NNBias - Epoch {epoch}, Loss: {loss}")

```

D先生 ： “ほう・・・。ここでは、データセットに含まれる「feature-2」のデータを学習しています。また、別途にモデルをインスタンス化して、それを**「nnb」**と定義しています。これは、どんな構造モデルですか？”

QEU:FOUNDER ： “さっきの「feature-1」のためのモデルと同じ構造です。学習するデータが違うので、別の定義にしているだけです。”

D先生 ： “な～んだ。がっかり・・・。”

![imagePRTM0-3-5](/2025-02-16-QEUR23_PRTM2/imagePRTM0-3-5.jpg)

QEU:FOUNDER ： “この「feature-2」のデータを使って、モデルを学習してみました。ここでは、正確度のみを晒します。”

D先生 ： “正確度が0.72って・・・。このデータは役に立つんですか？”

QEU:FOUNDER ： “これは大いに役立ちます！それでは、この2つの**ディープラーニング・モデルを合成**しましょう。”

D先生 ： “合成！？どうやって・・・？”

```python
# ---
# OUTPUT: Combine weight and bias
max_i = Yb_out.shape[0]
max_j = Yb_out.shape[1]
print(max_i, max_j)
# ---
Ytotal_out = Yw_out.copy()
for i in range(max_i):
    for j in range(max_j):
        Ytotal_out[i,j] = Yw_out[i,j] * Yb_out[i,j]
# ---
print(f"Ytotal_out: {Ytotal_out[0]}")

# ---
def predict_total(X):
    max_i = X.shape[0]
    #print(max_i)
    arr_output = []
    for i in range(max_i):
        val_output = np.argmax(X[i,:])
        arr_output.append(val_output)
    return np.array(arr_output)
# ---
Ypred_total = predict_total(Ytotal_out)
print(Ypred_total[0:10])

# ---
def evaluate_total(y_test, y_pred):
    accuracy = np.mean(y_pred == y_test)
    return accuracy

accuracy = evaluate_total(y_test, Ypred_total)
print(f"Total Accuracy: {accuracy}")

```

QEU:FOUNDER ： “いきなり、結果をドン！！”

![imagePRTM0-3-6](/2025-02-16-QEUR23_PRTM2/imagePRTM0-3-6.jpg)

D先生 ： “えっ！？正確度のパフォーマンスが一気に上がったじゃないですか！？なぜだろう・・・。そもそも、この「feature-2」で学習したモデルには、たった70%程度の正確度しかないじゃないですか・・・。”

QEU:FOUNDER ： “あのデータセットの2つの「feature」は、全く同じラベルを違う角度で数値化しているからです。つまり、あの**2つのデータは「独立」しています**。”

D先生： “もし、２つのモデルが独立しているのであれば、**ラベル別の確率変数を掛け算するだけで予測精度があがる**のか・・・。念のため、さっきの確率データを精査してみましょう。”

**(label)**

**label_out: ** [9 7 8 1 5]

**(feature-1)**

**Yw_out: **

[[4.91173380e-21 4.30301666e-51 3.00261286e-34 2.25788246e-17 3.03755680e-33 
2.99343377e-28 7.77161377e-19 4.05245683e-31 2.04310849e-28 1.00000000e+00]
 [2.66142479e-24 5.19785521e-21 6.04378178e-19 3.25590139e-35 1.73324611e-20 
5.04535213e-19 3.47624628e-39 1.00000000e+00 7.43976360e-13 1.15352242e-11]
 [2.69491878e-49 9.01924063e-34 2.78721527e-61 2.66864016e-37 1.96881277e-35 
1.15972916e-48 7.40290773e-47 2.07290697e-40 1.00000000e+00 4.38794696e-27]
 [5.24238680e-13 1.00000000e+00 7.88564758e-12 4.30374910e-11 8.78888335e-22 
3.91163260e-11 5.17242456e-19 7.54318311e-20 5.49237368e-18 6.90959306e-18]
 [2.45756724e-06 7.31093362e-10 7.10013255e-11 3.64472620e-08 3.83074293e-06 
9.99979826e-01 6.77887895e-10 1.38476877e-05 1.12607747e-10 1.07258482e-11]
 
**(feature-2)**

**Yb_out: **

[[2.13331147e-05 4.96946463e-04 2.62712435e-03 7.01884589e-03 1.22124944e-01 
7.85491400e-03 4.38315394e-03 8.66352173e-05 4.51029171e-04 8.54935073e-01]
 [5.38187649e-05 1.82384655e-04 1.89544213e-01 7.32256520e-01 1.05667009e-04 
4.39650242e-03 7.26021691e-02 1.79424054e-04 3.66993984e-05 6.42600756e-04]
 [1.72064398e-04 1.00685519e-04 9.19616444e-04 2.75233647e-03 1.42943541e-03 
2.45341840e-04 6.85581480e-04 2.31177407e-04 9.92164587e-01 1.29917439e-03]
 [5.98707901e-03 9.47613535e-01 7.97223020e-04 1.65928076e-03 2.74052037e-03 
1.50276311e-02 2.27360520e-02 2.75253041e-04 1.46595030e-03 1.69747574e-03]
 [1.33765600e-04 6.45614448e-04 3.37767937e-01 3.29824825e-01 4.96749671e-03 
3.06841761e-01 4.20402989e-03 1.84546698e-03 9.21890899e-03 4.55019481e-03]

QEU:FOUNDER ： “とくに、「feature-2」の数値の動きに注目してみて・・・。ちなみに、「feature-1」と「feature-2」は、各行のデータは同じラベルになっています。”

D先生 ： “「feature-1」は、正解のラベルのみに確率値（～1）が集中しています。しかし、「feature-2」の場合には、いくつかのラベルに確率値が分散しています。つまり、「正確度が70％である」というのは、予測確率が分散されていることの裏返しのわけです。”

QEU:FOUNDER ： “このような理由のため、**2つの確率分布を掛けると予測精度が上がってくる**んです。”

D先生 ： “なぜなら、その2つの学習データは「互いに独立」だから・・・。”

QEU:FOUNDER ： “今回が、本プロジェクトの「マイルストーン」になります。つづく、「まとめ編」で、もう少し詳しく解説しましょう。”


## ～ まとめ ～

C部長 : “FOUNDER・・・。今回はめずらしく「技術的なまとめ」をしたいそうで・・・。”

QEU:FOUNDER ： “今回は、「マイルストーン」というよりも、「これが結論！！」って感じのものなんです。”

C部長 : “よくわからないんですが・・・。今回のソルーションで予測精度が上がったのはありがたいことです。しかし、この手法が、ＦＯＵＮＤＥＲのいう**「外観検査のためのディープラーニングの提案」**ということと、どのような関係があるんですか？”

```python
# soaRT3メトリックスを計算する
def calc_soaRT3(tsr_sig_array, tsr_tani_array): 

    # データの抽出
    y = tsr_sig_array
    x = tsr_tani_array

    # dot回転を計測
    xx = np.dot(x,x) + 0.0001
    xy = np.dot(x,y) + 0.0001
    beta = xy/xx

    # ---
    # チェビシェフ距離を計測
    #vDistance = chebyshev(y,beta*x)
    # ミンコフスキー距離（Minkowski Distance）
    vDistance = minkowski(y,beta*x, 4) # p=4 

    # 絶対値（マンハッタン）距離を計測
    mDistance = minkowski(y,beta*x, 1) # p=1 
    
    # 値の変換
    log_beta = math.log(beta)
    log_yita = math.log(mDistance+1.0)
    log_gamma = log_yita - math.log(vDistance+1.0)
    
    return round(log_beta,5), round(log_yita,5), round(log_gamma,5)

```

QEU:FOUNDER ： “ディープラーニングをRT法（メトリックス）の性質に合わせたんです。”

![imagePRTM0-3-7](/2025-02-16-QEUR23_PRTM2/imagePRTM0-3-7.jpg)

QEU:FOUNDER ： “RT法の基本概念である「タグチ・メソッド」の数理的な考え方は、**「変動分解」**であると言われています。つまり、この処理によって出てくる「感度：β」と「ＳＮ比：η」はデータのバラツキを分解した結果であるので、そのメトリックスは**互いに独立している**といえます。”

C部長 : “「高次の変動：γ」値は、独立なんですか？”

QEU:FOUNDER ： “γ値はＳＮ比の派生であるので、ηに対しては独立していません。しかし、βに対して独立しています。この2つのメトリックス（β、γ）は、画像に含まれる異常の状態を全く異なる形で表現しています。いままでは、我々は予測のためにγ値のみを使っていました。これは、実にもったいない・・・。”

### 入力： β1～βk(10項目), γ1～γk(10項目)  → 合計20項目

C部長 : “じゃあ、ディープラーニング・モデルへの入力ベクトルを20項目（↑）にして、学習すればいいんじゃないですか？”

QEU:FOUNDER ： “２つの問題が出てくるでしょう。一つは、20項目になるのでモデルのサイズが大きくなってきます。その計算負荷を上回るメリットが出てくるのか・・・。もう一つ、さらに重要なことです。βのベクトルとγのベクトルは同じ画像を別の角度で表現したものです。それらを並列してモデルに入力させることは、**不必要な誤解をモデルに与える**のではないか？”

C部長 : “βとγベクトルを並列して入力しても、予測精度はあがらないと・・・？”

QEU:FOUNDER ： “今回の「feature-2」のモデルでは、予測精度は70％でしょ？この程度の精度しかない情報だったら、不要な情報になる可能性は大いにあります。”

![imagePRTM0-3-8](/2025-02-16-QEUR23_PRTM2/imagePRTM0-3-8.jpg)

C部長 : “もうひとつ質問です。なぜ、モデルに「Weight」と「Bias」という名前を付けたんですか？”

QEU:FOUNDER ： “この件、前から問題意識があり、ほそぼそとトライアルをやっていました。そもそもの考え方は、「W&B（↑）」のように、**2つのメトリックス（β、γ）をセット（対）にしてモデルに入力できないか**と考えていたんです。”

C部長 : “そこまでくると、**「前例のない独創的なAIだ」**・・・（笑）。”

QEU:FOUNDER ： “今のところは、この試みはうまく行っていないので、ここでは中間まとめとして、このやり方を公開したわけです。ちなみに、Weightとは「SN比：η」のことであり、一方、Biasとは「感度：β」になります。その理由は、自分で考えていただければ幸いです。”

C部長 : “2つのメトリックス（ex.β、γ）が独立でなければどうするんですか？”

[![MOVIE1](http://img.youtube.com/vi/q4hCVN7fre4/0.jpg)](http://www.youtube.com/watch?v=q4hCVN7fre4 "経営コンサルタントの倒産が過去最多…経営のプロであるはずがなぜ倒産してしまうのか？")

QEU:FOUNDER ： “このやり方が全く出来ないとは言い切れません。それでも、**あまり向かない方法になる**でしょうね。もし、ディープラーニングの仕組みを変えられれば、独立でなくても学習が可能になるでしょう。自分ができなければ、他のエライ人たちにやってもらいたいです。”

![imagePRTM0-3-9](/2025-02-16-QEUR23_PRTM2/imagePRTM0-3-9.jpg)

C部長 : “それ・・・、今、開発中ですか？まあ、非力なFOUNDERの能力で、うまく行けばいいですね。このやり方は、入力される異常情報の量が増えるので、**「一部だけ異なる画像の判別に向いたディープラーニング・モデル」**となり、このノウハウは後世に残ると思います。”

QEU:FOUNDER ： “いまのところ、新しいモデル構造ができるかどうかわかりません。できれば、このプロジェクトを続けますし、そうでなければ、このプロジェクトは終わるかもしれません。だから、今回は、「ほぼ結論」・・・！！”


