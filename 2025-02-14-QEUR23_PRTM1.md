---
title: QEUR23_PRTM1 – [学習用]numpyだけでディープラーニングをやってみる
date: 2025-02-14
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "NSOARTC", "データセット", "外観検査", "Vision language Model"]
excerpt: Siamese Networkをやってみる
---

## QEUR23_PRTM1 – [学習用]numpyだけでディープラーニングをやってみる

### ～ すごい、基本の基本から入ります ～

QEU:FOUNDER ： “それでは、新しいアプローチのディープラーニング・モデルの開発を始めましょう。じゃあ、最初に「初歩の初歩」から・・・。非常に簡単な多次元情報を使ってディープラーニングで学習します。”

![imagePRTM0-2-1](/2025-02-14-QEUR23_PRTM1/imagePRTM0-2-1.jpg)

QEU:FOUNDER ： “非常に簡単な、項目数が10のデータを作りたい。このためには、scikit-learnのモジュールを使ってデータを生成するのが簡単です。”

D先生 ： “分散状況を調整しないといけないですね。それでは、データ生成用プログラムをドン！！”

```python
# ---
import matplotlib.pyplot as plt
from sklearn.datasets import make_blobs

# ---
#n_samples
X1,Y1 = make_blobs(n_samples=300, centers=5, n_features=2, cluster_std=0.80,random_state=0)
X2,Y2 = make_blobs(n_samples=300, centers=5, n_features=2, cluster_std=1.30,random_state=0)
X3,Y3 = make_blobs(n_samples=300, centers=5, n_features=2, cluster_std=1.60,random_state=0)
X4,Y4 = make_blobs(n_samples=300, centers=5, n_features=2, cluster_std=1.90,random_state=0)

fig, ax = plt.subplots(nrows=2,ncols=2,dpi=140,sharex=True,sharey=True)
ax =ax.ravel()
ax[0].scatter(X1[:,0],X1[:,1],s=10,c=Y1,cmap="turbo")
ax[1].scatter(X2[:,0],X2[:,1],s=10,c=Y2,cmap="turbo")
ax[2].scatter(X3[:,0],X3[:,1],s=10,c=Y3,cmap="turbo")
ax[3].scatter(X4[:,0],X4[:,1],s=10,c=Y4,cmap="turbo")

ax[0].set_title("std_samples=0.8")
ax[1].set_title("std_samples=1.3")
ax[2].set_title("std_samples=1.6")
ax[3].set_title("std_samples=1.9")
plt.savefig("std_samples.png",dpi=250)
plt.show

```

D先生 ： “ダミーデータを簡単に作れるのがありがたいですね。このデータはk-meansによるクラスタリングをするための情報らしいですね。今回は、プログラムに与える分散量はどれぐらい必要ですか？”

QEU:FOUNDER ： “はっきり言って、それは「アナタの好み」の問題でしょう。ちなみに、標準偏差が3.0以下ではevaluation後の正確度が1.0になっちゃうと思います。それでは、ディープラーニングに入りましょう。ただし、**pytorchを使わず、tensorflowも使いません**。”

```python
# ---
# load database
import numpy as np
from datasets import load_dataset
import matplotlib.pyplot as plt

# Load MNIST dataset from Hugging Face Datasets
dataset = load_dataset("YxBxRyXJx/QEUdb_simple_newMODEL_250213")

# Separate training and testing data
train_dataset = dataset['train']
test_dataset = dataset['test']

# Limit the number of training samples
train_dataset = train_dataset.shuffle(seed=42).select(range(1000))
#train_dataset

# ---
# Preprocess data
def preprocess_data(dataset):
    images = []
    labels = []
    for item in dataset:
        image = item['features']
        label = item['labels']
        images.append(image)  
        labels.append(label)

    images = np.array(images)
    labels = np.array(labels)
    return images, labels

X_train, y_train = preprocess_data(train_dataset)
X_test, y_test = preprocess_data(test_dataset)
print(X_train[0])

# ---
print(y_train[0:10])

```

C部長 ： “ここまでは、学習データの導入と成形ですよね。肝心のモデル構築はどこですか？”

D先生 ： “あれ？「C部長」、いきなり登場しちゃって・・・。”

C部長 ： “**「創世記のディープラーニング」**に興味があるんですよ。”

```python
# ---
# Neural Network class
class NeuralNetwork:
    def __init__(self, input_size, hidden_size, output_size, learning_rate=0.01):
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.output_size = output_size
        self.learning_rate = learning_rate

        # Initialize weights
        self.weights_input_hidden = np.random.randn(self.input_size, self.hidden_size) * 0.01
        self.bias_hidden = np.zeros((1, self.hidden_size))
        self.weights_hidden_output = np.random.randn(self.hidden_size, self.output_size) * 0.01
        self.bias_output = np.zeros((1, self.output_size))

    def sigmoid(self, x):
        return 1 / (1 + np.exp(-x))

    def softmax(self, x):
        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))  # Prevent overflow
        return exp_x / np.sum(exp_x, axis=1, keepdims=True)

    def sigmoid_derivative(self, x):
        return x * (1 - x)

    def forward(self, X):
        # Hidden layer
        self.hidden_input = np.dot(X, self.weights_input_hidden) + self.bias_hidden
        self.hidden_output = self.sigmoid(self.hidden_input)

        # Output layer
        self.output_input = np.dot(self.hidden_output, self.weights_hidden_output) + self.bias_output
        self.output_output = self.softmax(self.output_input)

        return self.output_output

    def backward(self, X, y, output):
        # Calculate error
        output_error = output - self.one_hot_encode(y)

        # Backpropagation to hidden layer
        hidden_error = np.dot(output_error, self.weights_hidden_output.T)
        hidden_delta = hidden_error * self.sigmoid_derivative(self.hidden_output)

        # Update weights (with L2 regularization)
        self.weights_hidden_output -= self.learning_rate * np.dot(self.hidden_output.T, output_error)
        self.bias_output -= self.learning_rate * np.sum(output_error, axis=0, keepdims=True)
        self.weights_input_hidden -= self.learning_rate * np.dot(X.T, hidden_delta)
        self.bias_hidden -= self.learning_rate * np.sum(hidden_delta, axis=0, keepdims=True)

    def one_hot_encode(self, y):
        one_hot = np.zeros((len(y), self.output_size))
        one_hot[np.arange(len(y)), y] = 1
        return one_hot

    def predict(self, X):
        output = self.forward(X)
        return np.argmax(output, axis=1)

    def calculate_loss(self, y_predicted, y_actual):
         # Cross-entropy loss
        num_samples = len(y_actual)
        loss = -np.sum(y_actual * np.log(y_predicted)) / num_samples
        return loss

    def evaluate(self, X_test, y_test):
        y_pred = self.predict(X_test)
        accuracy = np.mean(y_pred == y_test)
        return accuracy

```

C部長 ： “やっぱり、numpyだけで計算すると複雑なロジックになりますね。Jeremy Howardの授業のサンプル・プログラムでは、非常に簡単なコードで学習ができました。”

![imagePRTM0-2-2](/2025-02-14-QEUR23_PRTM1/imagePRTM0-2-2.jpg)

D先生 ： “Pytorchを使っているからね。Pytorchで学習すれば、tensorの学習値に、自動的に勾配情報がついてくるんです。つまり、ここで示した多くの関数が不要になります。”

QEU:FOUNDER ： “じゃあ、実際にプログラムを動かしてみましょう。”

```python
# ---
# Parameters
input_size = 10  
hidden_size = 32
output_size = 10  # 0-9 digits
learning_rate = 0.01
epochs = 30
batch_size = 32

# Train the model
nn = NeuralNetwork(input_size=input_size, hidden_size=hidden_size, output_size=output_size, learning_rate=learning_rate)
#nn.train(X_train, y_train, epochs=epochs, batch_size=batch_size)

# ---
#def train(self, X_train, y_train, epochs=10, batch_size=32):
num_samples = len(X_train)
for epoch in range(epochs):
    for i in range(0, num_samples, batch_size):
        X_batch = X_train[i:i + batch_size]
        y_batch = y_train[i:i + batch_size]

        # Forward pass
        output = nn.forward(X_batch)

        # Backward pass
        nn.backward(X_batch, y_batch, output)

    if epoch % 5 == 0:
        loss = nn.calculate_loss(nn.forward(X_train), nn.one_hot_encode(y_train))
        print(f"Epoch {epoch}, Loss: {loss}")

# ----
# Evaluate the model
accuracy = nn.evaluate(X_test, y_test)
print(f"Accuracy: {accuracy}")

```

C部長： “わあ・・・。高い精度を出してますね。K-meansのデータなので、DL予測には「ラクちん」なデータだともいえるが・・・。”

![imagePRTM0-2-3](/2025-02-14-QEUR23_PRTM1/imagePRTM0-2-3.jpg)

QEU:FOUNDER ： “D先生・・・、ここまでで、何を学びましたか？”

D先生 ： “こんなもんかと・・・（笑）。このように原始的なコードになると、**「WeightとBias」という変数が現れてくる**んですね。Pytorchのモデルではnn.linearの作用で見えなくなるんですが。”

QEU:FOUNDER ： “小生も同じ感想です。”




## ～ まとめ ～

### ・・・ 前回のつづきです ・・・

QEU:FOUNDER ： “C国AIの秘密って、結局のところは2つだけです。一つは、**「粘り強さ」**・・・。もうひとつは・・・。”

![imagePRTM0-2-4](/2025-02-14-QEUR23_PRTM1/imagePRTM0-2-4.jpg)

QEU:FOUNDER ： “もう一つのキー・テクノロジーは「爽」です。**「爽」とは、「不合理に対する共感」です。ただし、小生の経験から言うとね・・・。C国人は、この２つを持っているから強いAIをつくる。この解説の外は無意味だね。”

C部長 : “合理的じゃ、だめですか？”

![imagePRTM0-2-5](/2025-02-14-QEUR23_PRTM1/imagePRTM0-2-5.jpg)

QEU:FOUNDER ： “**合理的な経営の行きつく先（↑）**って、こんな感じ・・・。”

C部長 : “あ～あ・・・。いっちゃった・・・。”

[![MOVIE1](http://img.youtube.com/vi/BGJt10kjqs0/0.jpg)](http://www.youtube.com/watch?v=BGJt10kjqs0 "あなたに備わる力で複雑な世の中を生き抜け。")]

QEU:FOUNDER ： “合理的な判断って、すでに確立したモノ、ファクトチェックされたものを評価した結果でしょ？そんなものって、すでに2～3周遅れの情報ですよ。それらの情報を取りあげて、皆で一斉にぎゃあぎゃあ言う感覚って、なんだろなあ・・・。そんな人たちに聞いてみたいの・・・。**「いま、やりたいことはありますか？」**って・・・。”

![imagePRTM0-2-6](/2025-02-14-QEUR23_PRTM1/imagePRTM0-2-6.jpg)

QEU:FOUNDER ： “我々全員が**「巨人の方の上に乗る」**存在なんだから、必要以上にいい気になってあれこれ言うのがおかしいことなんです。重要なのは、今、その人に推進力があるかどうかだけです。”

C部長 : “FOUNDER・・・。いまだに、「爽」ってわかりません。”

QEU:FOUNDER ： “「爽」って、E語ではcomfortableって訳されるが、**C語で人に対する形容詞にバケた瞬間に解釈が難しくなる**んですよ。身近にC国人がいれば、ちょっと聞いてみれば？「あの画像の人たちって、爽なの？」って、運が良ければ教えてくれます。ひょっとしたら困った顔をするかもしれない・・・（笑）。”

