---
title: QEUR23_SMNRT41 – PyTorchでTripletをやってみる(MNIST-その2)
date: 2025-01-13
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "NSOARTC", "データセット", "外観検査", "Vision language Model"]
excerpt: Siamese Networkをやってみる
---

## QEUR23_SMNRT41 – PyTorchでTripletをやってみる(MNIST-その2)

## ～ TRIPLETは、さすがの高精度！！ ～

QEU:FOUNDER ： “前回にひきつづいて、MNISTデータセットを使った画像判別モデルの評価です。今回はEmbeddingを使って予測します。もう、前置きはいらないです。プログラムをドン！！序盤のコードは重複するのでスキップです。”

```python
# ---
################################
# draw_images (SINGLE)
################################
# ---
# いくつかのデータを抽出して、表示する
def draw_images(dataset):
    # ---
    fig = plt.figure(figsize=[8,10])
    plt.suptitle("Data Visualization(1-4)")
    for i in range(4):
        str_label = dataset[i][1]
        # ---
        fig.add_subplot(2, 2, i+1)
        plt.title(f"LABEL:{str_label}",fontsize = 11)
        plt.imshow(torch.squeeze(dataset[i][0]), cmap='hot', interpolation='nearest')
        plt.tight_layout()
        plt.axis('off')       
    # ---
    # ヒートマップを表示
    plt.tight_layout()
    plt.show()

# ---
# データを抽出して、グラフにする
draw_images(test_dataset)

```

QEU:FOUNDER ： “特にいうことは無いです。YLCのデータです。以上！”

![imageSMR2-41-1](/2025-01-13-QEUR23_SMNRT27/imageSMR2-41-1.jpg)

D先生 ： “プログラムの紹介をつづけましょう。このモデルは、Embeddingが128次元になるモデルです。次は、SNNによる個別予測をやってみます。”

```python
# ---
# Install and import required dependencies
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset, Subset
# ---
import math
import time
# ---
##################################
# NETWORKS FUNCTIONS (TRIPLET)
##################################
# ---
# build model
class EmbeddingNet(nn.Module):
    def __init__(self):
        super(EmbeddingNet,self).__init__()
        self.linear1 = nn.Linear(28*28, 256) #28 * 28 is the pixels for each image
        self.linear2 = nn.Linear(256, 256) #100 and 5o
        self.final = nn.Linear(256, 128)
        self.relu = nn.ReLU()
# ここでは、このクラスのインスタンスを定義しながら、各レイヤーにデータを入力し、出力を返すだけです。
    def forward(self, img): #convert + flatten
        x = img.view(-1, 28*28)
        x = self.relu(self.linear1(x))
        x = self.relu(self.linear2(x))
        x = self.final(x)
        return x

    def get_embedding(self, x):
        return self.forward(x)

class TripletNet(nn.Module):
    def __init__(self, embedding_net):
        super(TripletNet, self).__init__()
        self.embedding_net = embedding_net

    def forward(self, x1, x2, x3):
        output1 = self.embedding_net(x1)
        output2 = self.embedding_net(x2)
        output3 = self.embedding_net(x3)
        return output1, output2, output3

    def get_embedding(self, x):
        return self.embedding_net(x)

################################
# MODEL INSTANCE SETTING
################################
# ---
# Set up the network and training parameters
# ---
embedding_net = EmbeddingNet()
model = TripletNet(embedding_net)
cuda = torch.cuda.is_available()
if cuda:
    model.cuda()

# ----
# モデル定義が必要
model.load_state_dict(torch.load('drive/MyDrive/siamese_mnist_triplet128_model.pth'))
model.eval()

# ---
#TripletNet(
#  (embedding_net): EmbeddingNet(
#    (linear1): Linear(in_features=784, out_features=256, bias=True)
#    (linear2): Linear(in_features=256, out_features=256, bias=True)
#    (final): Linear(in_features=256, out_features=128, bias=True)
#    (relu): ReLU()
#  )
#)

#########################################
# ANCHORのベクトル群を生成する
# TARGET = 以下のラベルのデータ群の平均値ベクトルとなる
#########################################
# ---
def create_anchors(dataset, TARGET):
    # ---
    # 条件をもとにフィルタリング
    cut_dataset = []
    for i, example in enumerate(dataset):
        if example[1] == TARGET:
            cut_dataset.append(example[0])
    
    # データセットが空でないことを確認
    if not cut_dataset:
        raise ValueError(f"No examples found for target {TARGET}")

    # データセットの確認
    cut_image = torch.stack([example[0] for example in cut_dataset])
    print("cut_image", cut_image.shape)
    #cut_image torch.Size([980, 28, 28])
    
    # anchorを生成する
    anchor_X = torch.zeros([cut_image.shape[1], cut_image.shape[2]])
    for i in range(cut_image.shape[1]):
        for j in range(cut_image.shape[2]):
            anchor_X[i, j] = torch.mean(cut_image[:, i, j])

    return cut_image.shape[0], anchor_X

# ---
# 平均画像を変数に保管する
anchor_Xs = []
arr_Xnum  = [] 
for TARGET in range(n_classes):
    num_Xs, mx_anchor = create_anchors(test_dataset, TARGET)
    anchor_Xs.append(mx_anchor)
    arr_Xnum.append(num_Xs)

################################
# anchor_embeddingベクトルを生成する
################################
# ---
anchor_embedding = np.zeros([n_classes, 128])
for i in range(n_classes):
    # ---
    cut_anchor = anchor_Xs[i]
    tensor_x = torch.unsqueeze(cut_anchor,1)
    #print(tensor_x)
    # ---
    anchor_embedding[i, :] = model.get_embedding(tensor_x.cuda()).data.cpu().numpy()
# ---
print(anchor_embedding.shape)

# ---
from scipy.spatial import distance

################################
# ユークリッド距離を計算する(1.個別)
################################
# ---
# ひとつのデータを抽出する
def individual_process(i, dataset, anchor_embedding, anchor_Xs):
    # ---
    # データセットの確認
    sample_image = dataset[i][0]
    sample_index = dataset[i][1]
    #print(sample_index)
    # ---
    arr_dist = []
    for j in range(n_classes):
        anchor_image = anchor_Xs[j]
        tensor_x = torch.unsqueeze(sample_image,1)
        # ---
        sample_embedding = model.get_embedding(tensor_x.cuda()).data.cpu().numpy()
        #print(sample_embedding.flatten())
        # ---
        val_dist = distance.euclidean(anchor_embedding[j], sample_embedding.flatten())
        arr_dist.append(round(val_dist,5))
        print(f"j: {j}, Distance: {val_dist}")
    # ---
    print("--- ACTUAL DATA, Distance ---")
    print(f"iCount: {i}, arr_dist: {arr_dist}")
    print("--- MIN_INDEX ---")
    index = np.argmin(arr_dist)
    anchor_image = anchor_Xs[index]
    pred_label = index      # set_label[index]
    #print(f"INDEX: {index}, LABEL: {pred_label}")
    # ---
    fig = plt.figure(figsize=[10,5])
    plt.suptitle(f"    ANCHOR    |    MEASUREMENT   |   LABEL: {pred_label}",fontsize = 15)
    # ---
    # ANCHOR
    fig.add_subplot(1, 2, 1)
    plt.imshow(anchor_image, cmap='hot', interpolation='nearest')
    plt.axis('off')
    # ---
    # SAMPlE
    fig.add_subplot(1, 2, 2)
    plt.imshow(sample_image.squeeze() , cmap='hot', interpolation='nearest')
    plt.axis('off')
    # ---
    # ヒートマップを表示
    plt.tight_layout()   
    plt.show()

# ---
# ひとつのデータを抽出する
i = 550
individual_process(i, test_dataset, anchor_embedding, anchor_Xs)

```

QEU:FOUNDER ： “当たり前だが、正解が出ています！！”

![imageSMR2-41-2](/2025-01-13-QEUR23_SMNRT27/imageSMR2-41-2.jpg)

D先生 ： “この出力を見ると、どのように予測が行われるのかがわかります。そうでしょ？”

QEU:FOUNDER ： “その通り。ベクトル要素の最小インディックスが予測値です。さて、（プログラムの晒しを）続けましょう。”

```python
################################
# ユークリッド距離を計算する(2.バッチ)
################################
# ---
# バッチ・データを抽出する
def batch_process(i, dataset, anchor_embedding):
    # ---
    # データセットの確認
    sample_image = dataset[i][0]
    sample_index = dataset[i][1]
    #print(sample_index)
    # ---
    arr_dist = []
    for j in range(n_classes):
        anchor_image = anchor_Xs[j]
        tensor_x = torch.unsqueeze(sample_image,1)
        # ---
        sample_embedding = model.get_embedding(tensor_x.cuda()).data.cpu().numpy()
        #print(sample_embedding.flatten())
        # ---
        val_dist = distance.euclidean(anchor_embedding[j], sample_embedding.flatten())
        arr_dist.append(round(val_dist,5))
        #print(f"j: {j}, Distance: {val_dist}")
    # ---
    #print("--- ACTUAL DATA, Distance ---")
    #print(f"iCount: {i}, arr_dist: {arr_dist}")
    index = np.argmin(arr_dist)
    anchor_image = anchor_Xs[index]
    pred_label = index  # set_label[index]
    #print(f"i: {i}, INDEX: {index}, LABEL: {pred_label}")

    return pred_label, sample_index

# ---
# バッチ・データを抽出するを抽出する
arr_pred = []
arr_actual = []
for i in range(1000):
    pred_y, actual_y = batch_process(i, test_dataset, anchor_embedding)
    #print(f"i: {i}, pred: {pred_y}, actual: {actual_y}")
    arr_pred.append(pred_y)
    arr_actual.append(actual_y)

################################
# CREATING CONFUSION MATRIX
################################
# ---
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# 混同行列の生成
cm = confusion_matrix(arr_actual, arr_pred)

# Confusion matrixの表示
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)

# X軸ラベル、Y軸ラベル、タイトルの追加
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')

# Confusion matrixの表示
plt.show()

```

QEU:FOUNDER ： “もちろん、Confusion Matrixでの評価結果はVERY GOODです。”

![imageSMR2-41-3](/2025-01-13-QEUR23_SMNRT27/imageSMR2-41-3.jpg)

D先生 ： “TRIPLETのパワーはさすがです。今回のシステムは、平均画像をANCHORになるようになっているんですよね？”

QEU:FOUNDER ： “はっきりいって、ANCHORが平均画像じゃないと「TRIPLETのありがたみ」は、ないです。それでは、次は外観検査データセットを使った事例をやっていきましょう。”


## ～ まとめ ～

QEU:FOUNDER ： “さいきん、これ（↓）が話題になっています。まあ、これは、「ありがち」かなと・・・。**J国の転換点**とも言えます。皆さん、気づいているかな？”

![imageSMR2-41-4](/2025-01-13-QEUR23_SMNRT27/imageSMR2-41-4.jpg)

C部長 : “タイトルは、**「窮すれば鈍する」**ですか・・・。 “

QEU:FOUNDER ： “昔は、「（J国の農産物は）安全、安心、おいしい」と言われていたんですよね。恐らく、すでにJ国の農家には余裕がなくなってきているんでしょう。**近年の農政の敗北の象徴がキャベツ（↓）の価格高騰**でしょう。”

![imageSMR2-41-5](/2025-01-13-QEUR23_SMNRT27/imageSMR2-41-5.jpg)

C部長 : “キャベツは、**「（外国人）実習生頼み」の典型**でしたよね。円安がここまで進むと、農作物の値段があがるのはあたりまえです。 “

![imageSMR2-41-6](/2025-01-13-QEUR23_SMNRT27/imageSMR2-41-6.jpg)

QEU:FOUNDER ： “1990年代後半、貴いエズ様が、苦労して苦労して貴い本を発行し、**本来は「モノづくりが強みのJ国」を「インバウンドだけが頼みのJ国」に変えてくれました**。そのエズ様には申し訳ないが、**このインバウンド熱はそれほど長く続かない**と思います。”

[![MOVIE1](http://img.youtube.com/vi/Zmv9wCmN0cs/0.jpg)](http://www.youtube.com/watch?v=Zmv9wCmN0cs "参院選の与党苦戦と株価／中国インバウンドの完全回復／団塊の世代全員が後期高齢者へ")

C部長 : “インバウントは、これからもっとすごくなるんじゃないですか？ “

[![MOVIE2](http://img.youtube.com/vi/EmdQdvBt3xk/0.jpg)](http://www.youtube.com/watch?v=EmdQdvBt3xk "福岡長浜海鮮市場 2024年11月新開幕海鮮食堂超中伏？！Google評分只有2.4😱｜ 長浜海鮮市場 魚業推進設施")

C部長 : “ん！？**「中伏」**って？“

QEU:FOUNDER ： “中伏って、食べ物でいうと、一言、**「まずい」**ということです（笑）。外国からの観光客は、J国の文化、風景や食事を全体的にプラスに評価している一方で、より細かく計測し、**部分的にはシビアな評価をしている**んです。そして、この中伏の本質的な問題とは・・・。”

C部長 : “中伏の問題とは・・・？“

[![MOVIE3](http://img.youtube.com/vi/MsORq4sb594/0.jpg)](http://www.youtube.com/watch?v=MsORq4sb594 "自民党が気付かない恐怖の食糧問題。最早逃げ場なし！肥料もない、農家は高齢化、種もない。")

QEU:FOUNDER ： “J国のサプライアが無理をし過ぎているんだと思います。例えてみれば、**「てんぷら屋がてんぷら丼の上に札束を載せてお客に渡している」**ようなものです。”

C部長 : “言っている意味がよくわかりません・・・(笑)。 “

QEU:FOUNDER ： “**同じ食い物を外国で食べてみ？2倍、欧米では3倍の値段がするぞ！！**いま、外国人が「（J国の食べ物は）やすいうまい」で喜んでいるが、それが可能なのは、J国のサプライアが常に無理をしているから・・・。逆の角度から言うと、J国が元先進国なので、いまのところ少しだけ体力が残っているから、なんとかなっているんです。あと3年ぐらいじゃないか？**だんだんと質が落ちてくる**。”

![imageSMR2-41-7](/2025-01-13-QEUR23_SMNRT27/imageSMR2-41-7.jpg)

QEU:FOUNDER ： “J国の農業って、**国際的な貿易協議の中でつねに交渉取引のネタにされて、その結果として弱体化をしつづけた**じゃないですか。たしか、自給率がひどいことになっているとか・・・。”

C部長 : “そして、J国が農業を犠牲にし、そのかわりとして最も重視していた分野が**EVの普及とともに大いにコケた！**“

QEU:FOUNDER ： “インバウンドでは、農業がより重要になるのだが、果たして農業の復興は間に合うのか？”

C部長 : “**「J国料理？とてもまずくて食べられないよ・・・」**と、お客が言い出して逃げるのが速いか・・・。 “
