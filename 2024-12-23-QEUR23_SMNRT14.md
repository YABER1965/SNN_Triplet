---
title: QEUR23_SMNRT14 : NSOARTメトリックスを評価する
date: 2024-12-23
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "NSOARTC", "データセット", "外観検査", "Vision language Model"]
excerpt: Siamese Networkをやってみる
---

## QEUR23_SMNRT14 : NSOARTメトリックスを評価する

## ～ 結局、低次元EUCLID距離はこの程度 ～

QEU:FOUNDER ： “さて、前回でたたき台になる学習用のデータの準備が完了したので、メトリックスを生成しましょう。”

![imageSMR2-5-1](/2024-12-23-QEUR23_SMNRT14/imageSMR2-5-1.jpg)

D先生 ： “それは、前回に話をした**「COSIN角度」**と**「EUCLID距離」**のことですね。”

QEU:FOUNDER ： “そうです。前回と同じ要領で**TRIPLET**を生成して、ヒストグラムと相関散布図を書いてみましょう。それでは、プログラムをドン！！”

```python
# ----
# データセットを読み込む
# ----
# Importing the dataset
import numpy as np
import pandas as pd
from datasets import load_dataset

dataset = load_dataset('YxBxRyXJx/NSOARTC_Tanshi_1221', split='train')
#print(datasets)

# ---
# データセットをPandasのデータフレームに変換
org_df = pd.DataFrame(dataset)  # 'train'分割を使用する場合
# データフレームの内容を表示
#print(org_df)

# ---
# 何種類のラベルがあるか？
labels = org_df.loc[:,'label'].values
set_label = list(set(labels))
print(set_label)

```

D先生 ： “そうだったっけ・・・。ラベルの種類はこれだけしかないんですね。”

![imageSMR2-5-2](/2024-12-23-QEUR23_SMNRT14/imageSMR2-5-2.jpg)

QEU:FOUNDER ： “しゃあない。もう、めんどうくさい・・・（笑）。ちなみに、**「ラベルが0」というのは正常（合格）品です**。じゃあ、つづきましょう。”

```python
####################
# データフレームdfから、学習に必要なXs,Ysを分解する関数
####################
# ---
def create_data(df):
    # ---
    X = df.loc[:,'data0':'data1403'].values
    #print(X)

    label = df.loc[:,'label'].values
    #print(label[0:20])

    fmode = df.loc[:,'fmode'].values
    #print(fmode[0:20])

    return X, label, fmode

# ---
# データフレームの行をランダムにシャッフル
#shuffled_df = org_df.sample(frac=1).reset_index(drop=True)
# シャッフルされたデータフレームの表示
#print(shuffled_df)

# ---
# X-Y分解
#shuffled_X, shuffled_label, shuffled_fmode = create_data(shuffled_df)
#print(shuffled_label[0:20])

#########################################
# <anchor, positive>
# TARGET = 0 のみ
# label: [0, 11, 13, 21, 23, 31, 32, 33, 42, 61, 62, 63, 71, 72, 73, 81, 82, 91, 92]
#########################################
# ---
# TARGETを抽出する
TARGET = 0  # データがOK
cut_df = org_df.loc[org_df['label']==TARGET,:]
#print(cut_df)

# ---
# X-Y分解する
cut_X, cut_label, cut_fmode = create_data(cut_df)
#print(cut_X.shape)
# positiveを生成する
positive_X = cut_X

# ---
# anchorを生成する
anchor_X = []
for j in range(cut_X.shape[1]):
    anchor_X.append(np.mean(cut_X[:,j]))
# ---
anchor_X = np.array(anchor_X)
print(len(anchor_X))
print("--------")
print(anchor_X)

#########################################
# <negative>
# TARGET != 0 のみ
# label: [0, 11, 13, 21, 23, 31, 32, 33, 42, 61, 62, 63, 71, 72, 73, 81, 82, 91, 92]
#########################################
# ---
# TARGETを抽出する
NEGA_TARGET = 73  # データがOK
cut_df = org_df.loc[org_df['label']==NEGA_TARGET,:]
#print(cut_df)
# X-Y分解する
cut_X, cut_label, cut_fmode = create_data(cut_df)
#print(cut_X.shape)
# negativeを生成する
negative_X = cut_X
print(negative_X.shape)

####################################
# Tripletからメトリックスを生成し、グラフ化する
####################################
# ---
# Preparing for Model Training/Evaluation
# Import all libraries
import numpy as np
import math
import matplotlib.pyplot as plt

# ---
import keras
from keras.ops import norm
import tensorflow as tf
from tensorflow.keras import backend as K

# ----
anchor = []
positive = []
negative = []
for i in range(100):
    j_pos = np.random.randint(len(positive_X))
    j_neg = np.random.randint(len(negative_X))
    anchor.append(anchor_X)
    positive.append(positive_X[j_pos])
    negative.append(negative_X[j_neg])

# ---
anchor = np.array(anchor)
positive = np.array(positive)
negative = np.array(negative)
print(negative)

###############################
# (A)COS類似度と、(B)EUCLID距離を計算する
###############################
# ---
# (A)COS類似度関数
def cosine_distance(x,y):
    x = K.l2_normalize(x, axis=-1)
    y = K.l2_normalize(y, axis=-1)
    distance = 1-K.batch_dot(x, y, axes=-1)
    return distance

# ---
# バッチ・データ生成
def create_example(anchor,positive,negative):
    # ---
    # COS類似度(positive)
    arr_cos_positive = cosine_distance(anchor,positive)
    arr_cos_positive = arr_cos_positive.numpy()
    #print("cos_positive: ",cos_positive)
    # ---
    # COS類似度(negative)
    arr_cos_negative = cosine_distance(anchor,negative)
    arr_cos_negative = arr_cos_negative.numpy()
    #print("cos_negative: ",cos_negative)
    # ---
    # COS類似度(positive-negative)
    arr_cos_similarity = arr_cos_negative.flatten() - arr_cos_positive.flatten()
    #print("arr_cos_similarity: ",arr_cos_similarity)
    
    return arr_cos_similarity

# ---
arr_cos_similarity = create_example(anchor,positive,negative)

# ---
# ヒストグラムでプロット(COSINE)
# ---
plt.hist(arr_cos_similarity, bins=16)
plt.title("Distribution of cosine similarity")
plt.ylabel("frequency")
plt.xlabel("value")
plt.show()

```

D先生 ： “最初に、特定ラベルのレコードを抽出しました。そして、COSIN類似度を計算して、ヒストグラムをプロットしたわけですね。”

![imageSMR2-5-3](/2024-12-23-QEUR23_SMNRT14/imageSMR2-5-3.jpg)

QEU:FOUNDER ： “参考として、前回の**FASION MNIST**と比較できるようにしました。D先生・・・。ぜんぜん違うでしょ？”

D先生 ： “たしかに、**値が全然ちがいますね**。”

![imageSMR2-5-4](/2024-12-23-QEUR23_SMNRT14/imageSMR2-5-4.jpg)

QEU:FOUNDER ： “外観検査では**画像の一部だけが異なる**ので、COSINメトリックスでは感度が悪くなってしまうんです。じゃあ、次のメトリックスを評価してみましょう。”

```python
# ---
# EUCLID類似度関数
def euclidean_distance(x, y):
    """Compute the euclidean distance (norm) of the output of
    the twin networks.
    """
    return tf.sqrt(tf.reduce_sum(tf.square(x - y), axis=1, keepdims=True))

# ---
# バッチ・データ生成
def create_example(anchor,positive,negative):
    # ---
    # EUCLID類似度(positive)
    arr_euc_positive = euclidean_distance(anchor,positive)
    arr_euc_positive = arr_euc_positive.numpy()
    #print("cos_positive: ",cos_positive)
    # ---
    # EUCLID類似度(negative)
    arr_euc_negative = euclidean_distance(anchor,negative)
    arr_euc_negative = arr_euc_negative.numpy()
    #print("cos_negative: ",cos_negative)
    # ---
    # EUCLID類似度(positive-negative)
    arr_euc_similarity = arr_euc_negative.flatten() - arr_euc_positive.flatten()
    #print("arr_euc_similarity: ",arr_euc_similarity)
    
    return arr_euc_similarity

# ---
arr_euc_similarity = create_example(anchor,positive,negative)

# ---
# ヒストグラムでプロット(EUCLID)
# ---
plt.hist(arr_euc_similarity, bins=16)
plt.title("Distribution of euclid similarity")
plt.ylabel("frequency")
plt.xlabel("value")
plt.show()

```

QEU:FOUNDER ： “このユークリッド距離のヒストグラムは以下のようになります。”

![imageSMR2-5-5](/2024-12-23-QEUR23_SMNRT14/imageSMR2-5-5.jpg)

D先生 ： “これも、「fashion MNIST」その比較がなされています。外観検査の場合には、画像のごく一部のみが合格品と異なりますから、EUCLID距離の値はfashin MNISTよりも小さいです。それでも、COSIN距離の場合よりも、その解像度はマシのように思います。”

QEU:FOUNDER ： “それでは、両者の相関関係を見てみましょう。これは、簡単な相関グラフで可視化することができます。”

```python
# ---
# 散布図でプロットする(COSINE-EUCLID)
# ---
plt.scatter(arr_cos_similarity*100, arr_euc_similarity)
plt.title("Correlation between cosine and euclid similarity")
plt.ylabel("euclid")
plt.xlabel("cosine")
plt.show()

```

QEU:FOUNDER ： “これ(↓)を見ると、がっかりしない？”

![imageSMR2-5-6](/2024-12-23-QEUR23_SMNRT14/imageSMR2-5-6.jpg)

D先生 ： “残念、相関図の**バラツキはほとんどない(相関係数=1.0)**ですね。”

QEU:FOUNDER ： “この部分が、外観検査の難しい部分だと思うんですよ。”

D先生 ： “そうだ！タグチメソッドのSN比の考え方を導入できませんか？”

![imageSMR2-5-7](/2024-12-23-QEUR23_SMNRT14/imageSMR2-5-7.jpg)

QEU:FOUNDER ： “それは、良い考えだ！！QEUシステムの**変動分解**の考え方によれば、COSIN距離は0次の変動であり、SN比（マンハッタン、ユークリッド）は1次の変動です。そのメトリックスを使うと、現状突破ができるかもね。でも・・・。”

```python
# ---
# EUCLID類似度関数
def euclidean_distance(x, y):
    """Compute the euclidean distance (norm) of the output of
    the twin networks.
    """
    return tf.sqrt(tf.reduce_sum(tf.square(x - y), axis=1, keepdims=True))

```

QEU:FOUNDER ： “この関数に、β（感度）成分を加えることがどうしてもできなかったんです。”

D先生 ： “そうか・・・。前回、FOUNDERは、「すでに何回もトライ・エラーをした」と言ってましたね。こういうことだったのですね。”

QEU:FOUNDER ： “まあ、より高次の変動において、どのような相関になるかは興味があるので、あとでPytorchを使って調べてみましょう。”

D先生 ： “Siamese Neural NetworkをPytorhを使ってやれませんか？”

QEU:FOUNDER ： “実は。まだうまく行っていないんです。だから、あらかじめ、「今回のシーズンは長くなるかも」と言ったんです。根気よく進めましょうよ。”

## ～ まとめ ～

### ・・・ 前回のつづきです ・・・

C部長 : “西側は常に東側を意図的に過小評価しているんですね。しかし、もともと東側はすごいから、21世紀になって無視できなくなったんですね。”

QEU:FOUNDER ： “R国の某大政治家の話に戻ります。彼がメンションしている「出生率」に関する問題の根本原因は、**「宗教＝社会の発展観の差」**だと思うんです。ついでにいうと、この宗教について、おそらく近いうちにグローバルサウスで大きな変化がでてくるでしょう。”

![imageSMR2-5-8](/2024-12-23-QEUR23_SMNRT14/imageSMR2-5-8.jpg)

C部長 : “えっ！？そうなんですか？びっくりしました。アフリカの南半分って、カソリック教なんですか？”

QEU:FOUNDER ： “アフリカ諸国の多くがF国の植民地であったからね。しかし、近年の**F国の衰退**にともない、かわりにR国経済の浸透が進んでいます。もっとも重要な側面は「食料の供給」です。R国は、アフリカへの穀物の主要輸出国ですからね。さて、そろそろ次の件にいこうか。これが、小生が言いたいことの本題なのだが・・・。”

![imageSMR2-5-9](/2024-12-23-QEUR23_SMNRT14/imageSMR2-5-9.jpg)

QEU:FOUNDER ： “ヨハネの福音ののここの部分がヨーロッパ社会の**父性観**を現していると思うし、**「科学技術の発展観」の基本**だと思っているんです。一方、21世紀以降の**J国の急速な衰退は、この観点を持っていないことにある**と思うんです。実は、福音書のこの節を読んだとき、おもわず「ある本（↓）」を思い出しました。”

![imageSMR2-5-10](/2024-12-23-QEUR23_SMNRT14/imageSMR2-5-10.jpg)

D先生 : “なんでいきなりこの本を思い出す！？しかし、これは懐かしい・・・。私は読まなかったが、大学生協の物理本コーナーに並んでいたのは覚えています。”

QEU:FOUNDER ： “あのころの大学生協の本棚って、3系列ぐらいの物理本があったかな。「バークレー物理学コース」、「ファインマン物理学」、そして**「ランダウ物理学教程」**でした。そしていまだに覚えているのは、この人の本が信じられないくらいに「（本の厚さが）薄い」ことなのです。もちろん、ながい時間を経て、この傾向は変わってしまったのかもしれないがね。”

D先生 : “（ランダウは、）超流動現象を発見した、世紀の大天才なのにね・・・。”

![imageSMR2-5-11](/2024-12-23-QEUR23_SMNRT14/imageSMR2-5-11.jpg)

QEU:FOUNDER ： “ここら辺にランダウ博士の「父性」と「社会の進歩に対する確信」を感じるんです。未来の人間は、絶対に自分よりも賢い。**・・・いや、より賢くなるべきである。**未来の彼らが覚えるべきことは、さらに増えるだろう。だったら、自分のやってきたことを最小限にまで縮約して、テキストとして次世代に残しておこうと・・・。”

### わたしは荒れ野で叫ぶ声である。『主の道をまっすぐにせよ』と。

C部長 : “たしかにOVERFITしないと、**「まっすぐ」になります**。”

![imageSMR2-5-12](/2024-12-23-QEUR23_SMNRT14/imageSMR2-5-12.jpg)

QEU:FOUNDER ： “このヨハネの福音書の反対の立場をとっているのが、西側でポピュラーな**「マタイの福音書」**になります。マタイって、キリスト教の母性的な側面の象徴だと思うんです。「一匹と九十九匹の物語(↑)」は、その典型ですね。おどろくことに、**この羊さんの話は、マタイにはあるが、ヨハネにはないのです。**”

C部長 : “いままでの話はある程度わかります。しかし、この議論は科学技術となんの関係があるんですか？”

![imageSMR2-5-13](/2024-12-23-QEUR23_SMNRT14/imageSMR2-5-13.jpg)

QEU:FOUNDER ： “昔、「ハイブリッド」というすごい技術がありましたとさ・・・。この技術は、「究極のoverfit」技術だと思うんです。ただし、**overfitされて完成した技術というのは、すでに外挿できなくなっている**んです。つまり、競争の前提が異なってくると完全に作り直しになってしまいます。”

C部長 : “「overfit=すりあわせ」論ということで、いいですか？”

QEU:FOUNDER ： “かもね（笑）。その一方、「主の道をまっすぐにしたい」国々は、比較的すみやかに環境変化に対応できたんだろうと思うよ。・・・なんか、バッハの名曲（↓）をききたくなりました。”

[![MOVIE1](http://img.youtube.com/vi/v0lMWnBzUkY/0.jpg)](http://www.youtube.com/watch?v=v0lMWnBzUkY "バッハ《マタイ受難曲》全曲 リヒター指揮（1958）")

C部長 : “なんというか・・・。今の季節に聞くと、特別に「ジーン」ときますね。”

QEU:FOUNDER ： “クリスマスだから・・・（笑）。”
