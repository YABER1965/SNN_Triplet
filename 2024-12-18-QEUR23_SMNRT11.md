---
title: QEUR23_SMNRT11 – TRIPLETに平均画像を使用する
date: 2024-12-18
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "NSOARTC", "データセット", "外観検査", "Vision language Model"]
excerpt: Siamese Networkをやってみる
---

## QEUR23_SMNRT11 – TRIPLETに平均画像を使用する

## ～ 平均画像は、意外とイイ！ ～

QEU:FOUNDER ： “それでは、前回のSiamese Neural Network(SNN)のつづきです。TRIPLETの中に平均画像をつかいます。”

![imageSMR2-2-1](/2024-12-18-QEUR23_SMNRT11/imageSMR2-2-1.jpg)

D先生 ： “平均画像は、クラス別に以下の10種類です。これで少なくとも理屈の上では**距離の定義が、より明確になります**ね。”

![imageSMR2-2-2](/2024-12-18-QEUR23_SMNRT11/imageSMR2-2-2.jpg)

QEU:FOUNDER ： “それでは、プログラムをドン！！差異の部分だけを紹介します。つまり、TRIPLETを生成する部分だけです。”

```python
########################################
# 平均画像を生成する
########################################
# ---
# 平均画像の生成
def create_images(imgs, digit_indices):
    pairs = []
    labels = []
    n = 30 #What is the minimum amount of images that we have on a specific class
    sum_images = np.zeros([10, 28, 28])   # class x i x j
    for d in range(10): #For all the classes
        for k in range(n): #For the minimum amount in one class
            index = digit_indices[d][k] #Take 2 indices in the same class
            for i in range(28):
                for j in range(28):
                    sum_images[d, i, j] = sum_images[d, i, j] + imgs[index, i, j]
    # ---
    sum_images = sum_images / float(n)
    sum_images = sum_images.astype('float32')
            
    return sum_images

def create_images_on_set(images, test_labels):
    # Function to get indices of the same class and create couples of images 
    # Parameters
    # images (np.ndarray): mnist images
    # labels(np.ndarray): mnist tags 
    # ---
    digit_indices = [np.where(test_labels == i)[0] for i in range(10)] #Get a list of arrays with the indi-ces
    digit_indices = np.array(digit_indices)
    #print(digit_indices)
    sum_images = create_images(images, digit_indices)
    
    return sum_images, digit_indices

# ----
ave_images, digit_indices = create_images_on_set(X_org_test, y_org_test)
print("--- ave_images ---")
print(ave_images.shape)
# ---
ave_indices = digit_indices[:,:30]
print("--- ave_indices ---")
print(ave_indices.shape)

####################
# (参考用)TARGET画像を出力する
####################
# ---
# クラスの内訳
arr_class = [
        'T-shirt/top',
        'Trouser',
        'Pullover',
        'Dress',
        'Coat',
        'Sandal',
        'Shirt',
        'Sneaker',
        'Bag',
        'Ankle boot'
        ]
# ---
# Plot Class N (0-9)
TARGET = 6  # Class index here
NUM_ARRAYS = 10

arrays = X[np.where(y==TARGET)]
random_arrays_indices = np.random.choice(len(arrays),NUM_ARRAYS)
random_arrays = arrays[random_arrays_indices]

fig = plt.figure(figsize=[NUM_ARRAYS,4])
plt.title(f'Class {TARGET}: {arr_class[TARGET]}',fontsize = 15)
plt.axis('off')

for index in range(NUM_ARRAYS):
     fig.add_subplot(2, int(NUM_ARRAYS/2), index+1)
     plt.imshow(random_arrays[index])

####################
# TRIPLET用のデータベースを生成する
####################
# ---
def create_indices_on_set(test_labels, i):
    # ---
    # Function to get indices of the same class and create couples of images 
    # Parameters
    # images (np.ndarray): mnist images
    # test_labels(np.ndarray): mnist tags 
    # ---
    # anchor
    anchor_indices = np.where(test_labels == i)[0]   #Get a list of arrays with the indices
    # positive
    positive_indices = anchor_indices
    # negative
    negative_indices = np.where(test_labels != i)[0]   #Get a list of arrays with the indices
    
    return np.array(anchor_indices), np.array(positive_indices), np.array(negative_indices)

# ---
def select_images_on_set(images, anchor_indices, positive_indices, negative_indices, i):
    # use random choice
    # ---
    # anchor
    index_anchor = np.random.choice(anchor_indices)   
    image_anchor = images[index_anchor]
    # positive
    index_positive = np.random.choice(positive_indices)
    image_positive = images[index_positive]
    # negative
    index_negative = np.random.choice(negative_indices)
    image_negative = images[index_negative]
    
    return image_anchor, image_positive, image_negative

# ---
# Generating Triplets
# initialize triplets array
triplets = np.empty((0, 3, 28, 28), dtype=np.uint8)

# get triplets for each class
for target in range(10):
    # ---
    anchor_indices, positive_indices, negative_indices = create_indices_on_set(y, target)
    print("target: ",target)
    # アンカー画像に入れ替える
    image_anchor = ave_images[target,:,:]
    # ---
    # tripletを作成する
    for i in tqdm(range(3000)):
        # 各タイプから1つの画像を取得する
        _, image_positive, image_negative = select_images_on_set(X, anchor_indices, positive_indices, negative_indices, target)
        triplet = np.array([image_anchor, image_positive, image_negative])
        triplets = np.append(triplets, [triplet], axis=0)

# ---
# save triplet array(ORIGINAL)
name_triplet = 'triplets_fasion_MNIST_array.npy'
path_triplet = "drive/MyDrive/"+name_triplet
np.save(path_triplet,triplets)

####################
# 生のグレースケール画像を出力する(TRIPLET)
####################
# ---
# plot triplets array to visualize
TEST_SIZE = 5
random_indices = np.random.choice(len(triplets),TEST_SIZE)

fig = plt.figure(figsize=[5,2*TEST_SIZE])
plt.title(' ANCHOR  |  POSITIVE  |  NEGATIVE ',fontsize = 15)
plt.axis('off')

for row,i in enumerate(range(0,TEST_SIZE*3,3)):
    for j in range(1,4):
        fig.add_subplot(TEST_SIZE, 3, i+j)
        random_index = random_indices[row]
        plt.imshow(triplets[random_index,j-1])

```

D先生 ： “結果がでました。前回の画像と比較できるようにしましょう。ドン！！”

![imageSMR2-2-3](/2024-12-18-QEUR23_SMNRT11/imageSMR2-2-3.jpg)

C部長 ： “ANCHORを比較すれば、その差が明確です。このようにANCHORを平均画像にすれば、**距離がより安定します**。”

![imageSMR2-2-4](/2024-12-18-QEUR23_SMNRT11/imageSMR2-2-4.jpg)

D先生 ： “つまり、この図（↑）のように、**「ANCHORが均質空間の中心にきた」**わけです。”

QEU:FOUNDER ： “じゃあ、肝心の学習結果をみてみましょう。これも「Before-After」の型式で表示します。”

![imageSMR2-2-5](/2024-12-18-QEUR23_SMNRT11/imageSMR2-2-5.jpg)

C部長： “わあ・・・。損失量の大きさがぜんぜん違います。そうすると、予測の正確度は「異次元」になるのでしょうね。”

![imageSMR2-2-6](/2024-12-18-QEUR23_SMNRT11/imageSMR2-2-6.jpg)

QEU:FOUNDER ： “う～ん・・・、残念でした。**2パーセントの効果**しかありませんでした。”

D先生 ： “いやいや・・・。ANCHOR情報のシンプル化だけで、これだけの効果があるだから、大変なモノですよ。そもそもDeep Learningは、とりあえず**「何にでも適応してしまう」**わけだし・・・。さて、次は、いよいよ学習したモデルを使って、Embeddingベクトルを計算するステップですね。”

QEU:FOUNDER ： “ここでは非常にシンプルな事例だけをやります。プログラムをドン！！”

```python
# ---
# モデルの呼び出し
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt

# ---
import keras
from keras.ops import norm
#from tensorflow.keras.models import load_model

#model = load_model("drive/MyDrive/flatten_fashionMNIST_model.keras")

# ---
# トレーニングしたモデルのレイヤーです。
model.layers
#[<InputLayer name=anchor_input, built=True>,
# <InputLayer name=positive_input, built=True>,
# <InputLayer name=negative_input, built=True>,
# <Sequential name=sequential, built=True>,
# <Lambda name=lambda, built=True>]

# ---
# load fashion MNIST data
(X_org_train, y_org_train), (X_org_test, y_org_test) = tf.keras.datasets.fashion_mnist.load_data()
X_org_train.shape

# ---
# extract the CNN model for inference
siamese_model = model.layers[3]

# ---
# ターゲットを設定します(0-9)
TARGET = 0
# ---
# ANCHORの場合
X_test_anchor = []
y_test_anchor = []
for i in range(len(X_org_test)):
    index = y_org_test[i]
    if index == TARGET:
        arrays_flatten = X_org_test[i,:,:].flatten()
        X_test_anchor.append(arrays_flatten)
        y_test_anchor.append(TARGET)
X_test_anchor = np.array(X_test_anchor)
y_test_anchor = np.array(y_test_anchor)
# ---
# NEGATIVEの場合
X_test_negative = []
y_test_negative = []
for i in range(len(X_org_test)):
    index = y_org_test[i]
    if index != TARGET:
        arrays_flatten = X_org_test[i,:,:].flatten()
        X_test_negative.append(arrays_flatten)
        y_test_negative.append(index)
X_test_negative = np.array(X_test_negative)
y_test_negative = np.array(y_test_negative)
#print(negative_arrays.shape)
# ---
X_test_anchor_embedding = np.squeeze(siamese_model.predict(X_test_anchor))
X_test_positive_embedding = X_test_anchor_embedding
X_test_negative_embedding = np.squeeze(siamese_model.predict(X_test_negative))

# ---
# あるクラスを表す画像のインディックス群をベクトル型式で出力します
anchor_number = TARGET
positive_number = anchor_number
negative_number = 1
print(f"positive_number:{positive_number}, negative_number:{negative_number}")

# ---
# ランダムで１つのインディックスを生成する
index_anchor   = np.random.randint(len(y_test_anchor))
index_positive = np.random.randint(len(y_test_anchor))
index_negative = np.random.choice(digits_negative)
print(index_anchor, index_positive, index_negative)

# ---
# 次の 3 つの画像のEMBEDDINGを生成できます。
embedding_anchor   = X_test_anchor_embedding[index_anchor]
embedding_positive = X_test_positive_embedding[index_positive]
embedding_negative = X_test_negative_embedding[index_negative]

# ---
# ANCHOR-POSITIVE画像のEMBEDDING間の距離は小さくなるはずです。
# ---
norm(embedding_anchor - embedding_positive).numpy()

# ---
# ANCHOR-NEGATIVE画像のEMBEDDING間の距離は大きくなるはずです。
# さらに、POSITIVE-NEGATIVE画像のEMBEDDING間の距離は、ANCHOR-NEGATIVEの距離よりも大きくなるはずです。
# ---
norm(embedding_anchor - embedding_negative).numpy(), norm(embedding_positive - embed-ding_negative).numpy()

```

QEU:FOUNDER ： “Embeddingをユーグリッド距離で評価をしました。たった一つの事例ですが、以下のようになりました。ドン！！”

![imageSMR2-2-7](/2024-12-18-QEUR23_SMNRT11/imageSMR2-2-7.jpg)

D先生 ： “ANCHORからPOSITIVEまでの距離が715です。そして、ANCHORからNEGATIVEまでの距離が739です。今回の**TARGETのクラスは「0(T-shirt)」**でしたよね。”

**( 分類 )**

0. T-shirt/top
1. Trouser
2. Pullover(プルオーバーセーター)
3. Dress
4. Coat
5. Sandal
6. Shirt
7. Sneaker
8. Bag
9. Ankle boot(アンクルブーツ)

QEU:FOUNDER ： “そして、POSITIVEとNEGATIVEの差異は、925の値になりました。ずいぶん大きいよね・・・。たぶん、POSITIVEのシャツは長袖だったんじゃないかな？そして、NEGATIVEのクラスはセーターと・・・。そうすると、このような値のバランスが考えられます。”

D先生 ： “う～む、面白い・・・。次は、例によって外観検査への応用になるんですか？”

![imageSMR2-2-8](/2024-12-18-QEUR23_SMNRT11/imageSMR2-2-8.jpg)

QEU:FOUNDER ： “ちょっと考え中です。その前に、やりたいことがあるのだが、いまのところできるかわからない。”



## ～ まとめ ～

### ・・・ 前回のつづきといいたいが、**大ニュース**です ・・・

C部長 : “ああ・・・。こうなったのか・・・。”

![imageSMR2-2-9](/2024-12-18-QEUR23_SMNRT11/imageSMR2-2-9.jpg)

QEU:FOUNDER ： “率直に言って、全く違和感はないよね。賢い選択だと思うよ。2社とも、現実的には**A国マーケットに頼り切りの会社**だったし・・・。”

[![MOVIE1](http://img.youtube.com/vi/9uJHCK5nkec/0.jpg)](http://www.youtube.com/watch?v=9uJHCK5nkec "America Is Getting WIPED OUT - This Is What's Coming... | Richard Wolff")

C部長 : “来年は大変な年になりそうです。”

[![MOVIE2](http://img.youtube.com/vi/tiMZCgpXuO4/0.jpg)](http://www.youtube.com/watch?v=tiMZCgpXuO4 "What's Coming Is WORSE Than A Recession - Richard Wolff's Last WARNING")

QEU:FOUNDER ： “**18か月は、何もモノを買うな**だとさ・・・。”

![imageSMR2-2-10](/2024-12-18-QEUR23_SMNRT11/imageSMR2-2-10.jpg)

QEU:FOUNDER ： “とある高名な風水師によると、2028までだってさ・・・。ホント、「九運」の威力はハンパないわ・・・。”
