---
title: QEUR23_PRTM3 - ディープラーニングモデルをタテにならべる(Build Model)
date: 2025-02-17
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "NSOARTC", "データセット", "外観検査", "Vision language Model"]
excerpt: Siamese Networkをやってみる
---

## QEUR23_PRTM3 - ディープラーニングモデルをタテにならべる(Build Model)

## ～ めでたく、「カンニングAI」の開発が完了した！ ～

QEU:FOUNDER ： “前回は、**「互いに独立したメトリックスの合成」を使ってモデルの予測精度を向上させる**ことをトライしました。”

**（メトリックス合成前）**

![imagePRTM0-4-1](/2025-02-17-QEUR23_PRTM3/imagePRTM0-4-1.jpg)

**（メトリックス合成後）**

![imagePRTM0-4-2](/2025-02-17-QEUR23_PRTM3/imagePRTM0-4-2.jpg)

D先生 ： “2つの「feature(Xs)」があり、それらが全く同じラベルを違う角度で数値化している場合には、予測の合成が可能です。ただし、この手法は、あくまで2つの情報が独立している場合です。さて、「完全に独立していない場合」には・・・？”

QEU:FOUNDER ： “全く独立していないモデルを合成しても、意味はないと思うがね・・・。それでは、ディープラーニングのモデルを「タテに連結」してみましょう。2つのモデル（W&B）を使いますが、前半のWeightモデルの構造は前回と同じです。”

D先生 ： “ここでは、２つめのBiasモデルを晒すということですね。それでは、プログラムをドン！！”

```python
###############################
# ROUTINE FOR NNBias
###############################
# ---
# Neural Network class(2nd)
class NNBias:
    def __init__(self, input_size, hidden_size1, hidden_size2, output_size, learning_rate=0.01):
        self.input_size = input_size
        self.hidden_size1 = hidden_size1
        self.hidden_size2 = hidden_size2
        self.output_size = output_size
        self.learning_rate = learning_rate

        # Initialize weights
        self.weights_input_hidden1 = np.random.randn(self.input_size, self.hidden_size1) * 0.01
        self.bias_hidden1 = np.zeros((1, self.hidden_size1))
        self.weights_hidden1_hidden2 = np.random.randn(self.hidden_size1, self.hidden_size2) * 0.01
        self.bias_hidden2 = np.zeros((1, self.hidden_size2))
        self.weights_hidden2_output = np.random.randn(self.hidden_size2, self.output_size) * 0.01
        self.bias_output = np.zeros((1, self.output_size))

    def relu(self, x):
        return np.maximum(0, x)

    def relu_derivative(self, x):
        return (x > 0).astype(float)

    def softmax(self, x):
        exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))  # Prevent overflow
        return exp_x / np.sum(exp_x, axis=1, keepdims=True)

    def forward(self, X):
        # First hidden layer
        self.hidden_input1 = np.dot(X, self.weights_input_hidden1) + self.bias_hidden1
        self.hidden_output1 = self.relu(self.hidden_input1)

        # Second hidden layer
        self.hidden_input2 = np.dot(self.hidden_output1, self.weights_hidden1_hidden2) + self.bias_hidden2
        self.hidden_output2 = self.relu(self.hidden_input2)

        # Output layer
        self.output_input = np.dot(self.hidden_output2, self.weights_hidden2_output) + self.bias_output
        self.output_output = self.softmax(self.output_input)

        return self.output_output

    def backward(self, X, y, output):
        # Calculate error
        output_error = output - self.one_hot_encode(y)

        # Backpropagation to second hidden layer
        hidden2_error = np.dot(output_error, self.weights_hidden2_output.T)
        hidden2_delta = hidden2_error * self.relu_derivative(self.hidden_output2)

        # Backpropagation to first hidden layer
        hidden1_error = np.dot(hidden2_delta, self.weights_hidden1_hidden2.T)
        hidden1_delta = hidden1_error * self.relu_derivative(self.hidden_output1)

        # Update weights (with L2 regularization)
        self.weights_hidden2_output -= self.learning_rate * np.dot(self.hidden_output2.T, output_error)
        self.bias_output -= self.learning_rate * np.sum(output_error, axis=0, keepdims=True)
        
        self.weights_hidden1_hidden2 -= self.learning_rate * np.dot(self.hidden_output1.T, hid-den2_delta)
        self.bias_hidden2 -= self.learning_rate * np.sum(hidden2_delta, axis=0, keepdims=True)

        self.weights_input_hidden1 -= self.learning_rate * np.dot(X.T, hidden1_delta)
        self.bias_hidden1 -= self.learning_rate * np.sum(hidden1_delta, axis=0, keepdims=True)

    def one_hot_encode(self, y):
        one_hot = np.zeros((len(y), self.output_size))
        one_hot[np.arange(len(y)), y] = 1
        return one_hot

    def predict(self, Xw, Xb):
        # ---
        # 改造しました！
        Yw_out = nnw.forward(Xw)
        Yb_out = self.forward(Xb)
        Ytotal_out = combine_output(Yw_out, Yb_out)

        return np.argmax(Ytotal_out, axis=1)
        
    def predict_detail(self, Xw, Xb):
        # ---
        # 改造しました！
        Yw_out = nnw.forward(Xw)
        Yb_out = self.forward(Xb)
        Ytotal_out = combine_output(Yw_out, Yb_out)

        return Ytotal_out

    def calculate_loss(self, y_predicted, y_actual):
        # Cross-entropy loss
        num_samples = len(y_actual)
        loss = -np.sum(y_actual * np.log(y_predicted)) / num_samples
        return loss

    def evaluate(self, Xw_test, Xb_test, y_test):
        # ---
        # 改造しました！    
        y_pred = self.predict(Xw_test, Xb_test)
        accuracy = np.mean(y_pred == y_test)
        return accuracy

```

QEU:FOUNDER ： “一部を改造しました。「改造しました！！」って、わざわざコメントを書いてあるんだが・・・（笑）。”

D先生 ： “なるほどね。Biasモデルのクラスの中に**「前回で完成した予測精度を上げるためのノウハウ」**を展開したわけです。”

```python
# ---
# Parameters
input_size = 10
hidden_size1 = 64  # First hidden layer size
hidden_size2 = 32  # Second hidden layer size (newly added)
output_size = 10   # 0-9 digits
learning_rate = 0.005
epochs = 100
batch_size = 32

# ---
# Train the model(Bias)
nnb = NNBias(input_size=input_size,
                   hidden_size1=hidden_size1,
                   hidden_size2=hidden_size2,
                   output_size=output_size,
                   learning_rate=learning_rate)

# ---
num_samples = len(Xb_train)
for epoch in range(epochs):
    for i in range(0, num_samples, batch_size):
        Xw_batch = Xw_train[i:i + batch_size]
        Xb_batch = Xb_train[i:i + batch_size]
        y_batch  = y_train[i:i + batch_size]

        # Forward pass
        output = nnb.forward(Xb_batch)

        # Backward pass
        nnb.backward(Xb_batch, y_batch, output)

    if epoch % 5 == 0:
        loss = nnb.calculate_loss(nnb.forward(Xb_train), nnb.one_hot_encode(y_train))
        print(f"NNBias - Epoch {epoch}, Loss: {loss}")

```

QEU:FOUNDER ： “このように予測方法(prediction function)が変わると、それに伴って学習損失(loss)の値がすこしづつかわるはずだが・・・。”

![imagePRTM0-4-3](/2025-02-17-QEUR23_PRTM3/imagePRTM0-4-3.jpg)

D先生 ： “あれ？学習損失の減り方のトレンドが前回とほとんど同じだ！！”

QEU:FOUNDER ： “これについては、小生も驚きました。何はともあれ、こうやって学習したBiasモデルの予測性能を評価してみましょう。”

![imagePRTM0-4-4](/2025-02-17-QEUR23_PRTM3/imagePRTM0-4-4.jpg)

D先生 ： “すごい！！・・・ということもないか・・・（笑）。前回のトライアルで、予測レベルが向上するという結論がでていましたからね。それにしても、学習曲線が全然イケてないのに予測の成績が上がるというのは、なんだかなあ・・・。”

![imagePRTM0-4-5](/2025-02-17-QEUR23_PRTM3/imagePRTM0-4-5.jpg)

QEU:FOUNDER ： “結局のところ。**「コレ（↑）なAI」**なんでしょうね。”

D先生 ： “・・・（笑）。こんなヘンテコなAIのしくみを、なぜ考え付いたんですか？”

![imagePRTM0-4-6](/2025-02-17-QEUR23_PRTM3/imagePRTM0-4-6.jpg)

QEU:FOUNDER ： “Jeremy Howardのディープラーニング講義の2020年版に、データによるモデル学習に関する説明がありました。この画像（↑）は、2022年版のキャプチャだが・・・。モデル学習の概念は1980年代からあって、非常にシンプルなものだって・・・。”

```python
# ---
# Biasの予測をレベルアップさせるための関数
def combine_output(Yw_out, Yb_out):
    # ---
    # OUTPUT: Combine weight and bias
    max_i = Yb_out.shape[0]
    max_j = Yb_out.shape[1]
    #print(max_i, max_j)
    # ---
    Ytotal_out = Yw_out.copy()
    for i in range(max_i):
        for j in range(max_j):
            Ytotal_out[i,j] = Yw_out[i,j] * Yb_out[i,j]
    # ---
    #print(f"Ytotal_out: {Ytotal_out[0]}")

    return Ytotal_out

def predict(self, Xw, Xb):
	# ---
	# 改造しました！
	Yw_out = nnw.forward(Xw)
	Yb_out = self.forward(Xb)
	Ytotal_out = combine_output(Yw_out, Yb_out)

	return np.argmax(Ytotal_out, axis=1)

```

QEU:FOUNDER ： “このモデル学習の概念図を見れば、**我々が改造するべき部分は「resultモジュール」だけになる**よね。”

D先生 ： “そうすると、「loss」は「result」の改造によって必然的に変わってしまいます。なるほど・・・。これからどうしますか？例によって、ひきつづき外観検査自動機をやりますか？”

![imagePRTM0-4-7](/2025-02-17-QEUR23_PRTM3/imagePRTM0-4-7.jpg)

QEU:FOUNDER ： “やりたいけど、小生の実力ではこれ以上はやれません。**このプログラムはnumpyでできている**から、インプットの大きな本格的な画像判別には使えません。誰かさんに、このプロジェクトのつづきをやってもらいましょう。”

D先生 ： “やれるとするとPytorchでしょうね。Kerasで、これをやれるのかなあ・・・。”


## ～ まとめ ～

C部長 : “えっ！？外観検査自動機のプロジェクトが、いきなり終わったんですか？”

QEU:FOUNDER ： “小生の技量で、できないのだから「どうしようもない」でしょうに・・・。もともと、外観検査自動機のテクノロジの体系は、ほぼ成熟しているので、今回は「ボーナス」です・・・。”

[![MOVIE1](http://img.youtube.com/vi/e9tL_Eg3fpM/0.jpg)](http://www.youtube.com/watch?v=e9tL_Eg3fpM "How To Solve It With Code—background on the course; a discussion with Jeremy and Hamel")

C部長 : “まあ、FOUNDERは、むしろ**「BONSAI（言語）プロジェクト」**の方を進めたいと考えていましたからね。さらには、例のJHさんの「今後の動き」に注目していると・・・。”

![imagePRTM0-4-8](/2025-02-17-QEUR23_PRTM3/imagePRTM0-4-8.jpg)

QEU:FOUNDER ： “いま、「AGIが近いうちにやってくる、うんぬん・・・」っていう話題があるでしょ？小生は、あの手の話をあまり気にしていないの・・・。しょせん、生成AIは**「中国語の部屋（↑）」の域**をでないと思うよ。もちろん、**「知識爆発」は必ず起こる**し、平の社員が部長に提出する資料の質は大いに上がるでしょう。”

![imagePRTM0-4-9](/2025-02-17-QEUR23_PRTM3/imagePRTM0-4-9.jpg)

QEU:FOUNDER ： “だけど、「AGIはその程度・・・」といえます。ただし、**ユーザーのAIへの向き合い方が変わって、初めて世の中が変わってくるんじゃないか**？”

C部長 : “AGIは、「立派な報告書を作成する」ことに対しては、今後も、更に「すごい威力」を発揮するでしょう。しかし、人のもつモチベーションを高めたり、自分の生活を充実させるためには、どこまで有効なのかなあ・・・。“

QEU:FOUNDER ： “ほとんどすべての**「いわゆるAIサービス」がUI(User Interface)でできている**でしょ？あれが最も悪いと思うんですよ・・・。”

C部長 : “UIは、だれでも使いやすいでしょう。”

QEU:FOUNDER ： “本当にAIを自由に使いこなすには、最終的には自分でコードを使いこなすようでなければ・・・。将来的には、コードでAIを動かすのは、**「（自動車運転免許のように）コモンなスキル」**になるのではないか・・・。さらには、自分でコードを作成する必要はないです。”

C部長 : “FOUNDERも、今ではあまり自分でコードを作りませんからね。AIが作成したコードを、ちょこっとだけ修正して使っています。”

[![MOVIE2](http://img.youtube.com/vi/5Sze3kHAZqE/0.jpg)](http://www.youtube.com/watch?v=5Sze3kHAZqE "The End of Finetuning — with Jeremy Howard of Fast.ai")

QEU:FOUNDER ： “このように、**AIを活用したコーディングが一般的になれば、人々のAIへの向き合い方が変わってくる**と思うんです。あと、自然言語処理モデルのファインチューニングには、すでに限界が見えてきています。ただし、コード生成のLLMモデルはそうではないかもしれない。”

C部長 : “**コードは自然言語ではない**ですからね。”

![imagePRTM0-4-10](/2025-02-17-QEUR23_PRTM3/imagePRTM0-4-10.jpg)

QEU:FOUNDER ： “Jeremy Howardは当初、自然言語処理モデル（LLM）の場合でも画像処理モデル（ex. ResNet）のように「ノード階層毎に大まかな役割分担（↑）が出来ている」と思っていたんです。もし、その仮説が当たっていれば、ＬＬＭでもファインチューニングで機能を操作(manipulate)することは容易であろうと・・・。”

C部長 : “LLMのファインチューニングって、現実には、それほど「使い手が良いモノではない」のは、「言語(LLM)モデルのもつ複雑性」が原因なんですよね。じゃあ、その一方で、コード生成のためのAIの場合はどうか？”

QEU:FOUNDER ： “自分が今まで作った基本的なシステムの概念をAIに覚えてもらって、**コード生成を極力AIに任せたい**なあと思っているんです。”

C部長 : “そうすれば、QEUシステムのコードの質が一気にあがりそうです・・・（笑）。”

[![MOVIE3](http://img.youtube.com/vi/gnZQhS2ohA4/0.jpg)](http://www.youtube.com/watch?v=gnZQhS2ohA4 "データサイエンスのリアルと未来2025【AGI はもう来る。わたしたちはどう生きようか？")

QEU:FOUNDER ： “これが、小生の「ＡＩの未来像」かな・・・？なにはともあれ、ＢＯＮＳＡＩプロジェクトに戻りましょう。”
