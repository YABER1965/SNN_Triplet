---
title: QEUR23_PRTM0 - INTRODUCTION～ RTメトリックを使った全く新しい試み
date: 2025-02-13
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "NSOARTC", "データセット", "外観検査", "Vision language Model"]
excerpt: Siamese Networkをやってみる
---

## QEUR23_PRTM0 - INTRODUCTION～ RTメトリックを使った全く新しい試み

## ～ 発想が斬新すぎて、できるかどうかわかりません(笑)  ～
	
D先生 ： “はぁ～、さっきまでNLP（大規模言語モデル）をやっていたんですが・・・。なんか、いきなり画像系の新シーズンに移行することになりました。さて、ここはシーズンの最初になるので、我々の使命（↓）を再確認しましょう。これを忘れちゃいかん・・・。このシーズンは、またもやSiamese Neural Network(SNN)を使った外観検査自動機の開発なんですか？”

![imagePRTM0-1-1](/2025-02-13-QEUR23_PRTM0/imagePRTM0-1-1.jpg)

QEU:FOUNDER ： “いままでの流れとは全く違いますよ。多分、**「見たことがないアプローチ」になる**とおもいます。ちょっと長くなるが、いままでの復習をやりましょう。ここまでの流れを理解しないと、その「斬新さ」がわからないでしょう。まずは、骨とう品として知られる「タグチ・マソッド(TM)」の説明から・・・。”

D先生 ： “「マソッド」じゃなく、「メソッド」です・・・。・・・さすがに、いまどきレガシーのTMを使う人はいるのかなあ・・・。40歳以下の（比較的）若者で・・・。”

![imagePRTM0-1-2](/2025-02-13-QEUR23_PRTM0/imagePRTM0-1-2.jpg)

QEU:FOUNDER ： “そんな人たちも、**幸せに使っていることを心から祈ります**（笑）。実は、**パラメタ設計って「古代のAI」なんですよ**。あの当時としては、すごいモノを作ったと思います。”

![imagePRTM0-1-3](/2025-02-13-QEUR23_PRTM0/imagePRTM0-1-3.jpg)

QEU:FOUNDER ： “直交表を「データの蒸留」、感度とSN比を「モデルの構築」と考えれば、まさに**AIのスキーム**なんですよ。ただし、現代は計算力が豊富だから、この方法は意味ないね。・・・さて、我々がTMのうち、今後もかろうじて生き残ると思っている「RT法（メトリックス）」の話に入るが・・・。”

D先生 ： “RT法は概念図を書けば、すごく簡単なんですよ。”

![imagePRTM0-1-4](/2025-02-13-QEUR23_PRTM0/imagePRTM0-1-4.jpg)

QEU:FOUNDER ： “Pythonプログラムで表現すれば、もっと簡単になります。もっとも、これはSOART3法の関数だが・・・。”

```python
# soaRT3メトリックスを計算する
def calc_soaRT3(tsr_sig_array, tsr_tani_array): 

    # データの抽出
    y = tsr_sig_array
    x = tsr_tani_array

    # dot回転を計測
    xx = np.dot(x,x) + 0.0001
    xy = np.dot(x,y) + 0.0001
    beta = xy/xx

    # ---
    # チェビシェフ距離を計測
    #vDistance = chebyshev(y,beta*x)
    # ミンコフスキー距離（Minkowski Distance）
    vDistance = minkowski(y,beta*x, 4) # p=4 

    # 絶対値（マンハッタン）距離を計測
    mDistance = minkowski(y,beta*x, 1) # p=1 
    
    # 値の変換
    log_beta = math.log(beta)
    log_yita = math.log(mDistance+1.0)
    log_gamma = log_yita - math.log(vDistance+1.0)
    
    return round(log_beta,5), round(log_yita,5), round(log_gamma,5)

```

C部長： “ただし、いままではSOART3を発展させた、NSOARTC法を使うんでしょ？”

**(原画像)**

![imagePRTM0-1-5](/2025-02-13-QEUR23_PRTM0/imagePRTM0-1-5.jpg)

**（中間画像と最終データ)**

![imagePRTM0-1-6](/2025-02-13-QEUR23_PRTM0/imagePRTM0-1-6.jpg)

D先生 ： “NSOARTC法というのは、計測上のスケールになる画像（標準ベクトル）と計測対象になるRGBの3チャンネル画像（計測ベクトル）を比較して、**「1チャンネルの異常度」**を抽出するプロセスです。それでは、処理フローをみてみましょう。”

**（第一ステップ）**

![imagePRTM0-1-7](/2025-02-13-QEUR23_PRTM0/imagePRTM0-1-7.jpg)

**（第二ステップ）**

![imagePRTM0-1-8](/2025-02-13-QEUR23_PRTM0/imagePRTM0-1-8.jpg)

C部長： “ここで、図のRT法とRTC法の処理には、どんな差異があるんですか？ここで、「C」というのは、**「Convolution（畳み込み）」**という意味でしたね。。”

QEU:FOUNDER ： “QEUシステムにおける畳み込みは、ユーザーが設定した部品単位で計算します。”

![imagePRTM0-1-9](/2025-02-13-QEUR23_PRTM0/imagePRTM0-1-9.jpg)

QEU:FOUNDER ： “これらの部品で畳み込みした結果の数値リストを入力し、**「標準SN比」**の計算方法で感度βとSN比ηを出力するのが、RT法の基本です。ただし、ここで普通のRT法ではなく、入力に畳み込みリストを使ったことにより、出力ηが特徴量として良くないことがみえてきました。それが、SOART3（State of Art RT）メトリックの誕生になります。”

![imagePRTM0-1-10](/2025-02-13-QEUR23_PRTM0/imagePRTM0-1-10.jpg)

C部長： “SOART3法では、より**高次の変動**としてγ値というメトリックスを新しく設定しました。**γは、ミンコフスキー距離**でしたよね。”

![imagePRTM0-1-11](/2025-02-13-QEUR23_PRTM0/imagePRTM0-1-11.jpg)

QEU:FOUNDER ： “畳み込み部品を使って、その値でRTメトリックスを計算するのは合理的ではありません。なぜなら、各々の畳み込み値がまったく異なる特性を持つので、その計算結果は**著しく非線形な特性を持ちます**。ですから、より高次のγ値を使って、初めてメトリックスに意味がでてくるんです。”

D先生 ： “・・・ということは、NSOARTC法において、2段階目のRT法をRTC法に切り替える方法もありますね。”

QEU:FOUNDER ： “今回から、第2段階も畳み込みでRT法を使います。・・・さて、ここまでが「data preparation(データ準備)」の話です。肝心の判別処理の解説に行きましょう。ここからは簡単に行きましょう。やっぱり、ViT(Vision Transformer)を使った判別が一番検出の性能がいいです。これは、今回の開発が成功したとしてもかわりません。”

![imagePRTM0-1-12](/2025-02-13-QEUR23_PRTM0/imagePRTM0-1-12.jpg)

D先生 ： “じゃあ、なんで、いまさら「新しく開発をする」の？”

QEU:FOUNDER ： “その答えは後で・・・。しかし、ViTを使った異常検出ではデータ準備作業と判別計算のための負荷が大きくなりすぎるので、Siamese Neural Networkによる外観検査スキームを開発しました。”

![imagePRTM0-1-13](/2025-02-13-QEUR23_PRTM0/imagePRTM0-1-13.jpg)

D先生 ： “この方法は、少ない学習データと軽いモデルでも動くので、**「エッジ・コンピューティング」に最適**ですね。”

![imagePRTM0-1-14](/2025-02-13-QEUR23_PRTM0/imagePRTM0-1-14.jpg)

QEU:FOUNDER ： “おどろいたことに、Tripletよりも、普通のSiameseの方が使いやすいという・・・（笑）。いままでの我々の「外観検査自動機の開発」の進捗は以上です。”

D先生 ： “また、さっきと同じ質問をします。なぜ、いまさら「このシリーズのつづき」をやるの？高級スキームはVit、普及型スキームはSiameseで十分なのに・・・。”

QEU:FOUNDER ： “すべからく、ニューラル・ネットによる物体判別は、この**大天才（↓）の掌**の上で発展していったんです。”

![imagePRTM0-1-15](/2025-02-13-QEUR23_PRTM0/imagePRTM0-1-15.jpg)

QEU:FOUNDER ： “もう一度言うよ。**「物体判別のためのニューラル・ネット」**・・・。そもそも、いままでのニューラル・ネットは、物体判別（分類:classification）を目的として発展してきました。決して、「外観検査（異常検出）」のために発展してきたのではありません。”

C部長： “つまり、現在まで確立されたニューラルネットのスキームは、画像において**「99％は同じであるが、1％が異なる事象を検出する」**ためのスキームではない・・・。”

D先生 ： “えっ！あたらしいスキームを開発するの！？”

QEU:FOUNDER ： “大いにコケる可能性もあります（笑）。”



## ～ まとめ ～

QEU:FOUNDER ： “全く新しいプロジェクトを始めたので、記念として**fast.aiの2022年版**の動画を見てみました。ずいぶん、昔から進歩しましたよね。”

[![MOVIE1](http://img.youtube.com/vi/gGxe2mN3kAg/0.jpg)](http://www.youtube.com/watch?v=gGxe2mN3kAg "Lesson0: Practical Deep Learning for Coders (fast.ai)")]

QEU:FOUNDER ： “いやあ難し過ぎて、わからん・・・（笑）。この**「tenacity」っていう言葉**だけが頭に残ったよ。”

C部長 : “なんです？それ？”

![imagePRTM0-1-16](/2025-02-13-QEUR23_PRTM0/imagePRTM0-1-16.jpg)

C部長 : “なるほど・・・。ボクには「無いモノ」だ・・・（笑）。”

[![MOVIE2](http://img.youtube.com/vi/CHCx9AUpE4U/0.jpg)](http://www.youtube.com/watch?v=CHCx9AUpE4U "DeepSeek解説。NVIDIAのGPUはオワコンなのか")]

QEU:FOUNDER ： “deepseekの話題って、もう見る気も起きないんです。アホすぎて・・・。ちなみに、この動画も見ないで貼りました。もちろん、例の選挙に出た人なので尊敬はしているのだが、なにしろすでに、この話題は「喉を通らない」・・・（笑）。”

C部長 : “C国AIの秘密がわかるとか・・・。お得じゃないですか？”

QEU:FOUNDER ： “C国AIの秘密って、結局のところは2つだけです。一つは、「粘り強さ」・・・。もうひとつは・・・。”

C部長 : “C国のAIの秘密って、なんです？”

![imagePRTM0-1-17](/2025-02-13-QEUR23_PRTM0/imagePRTM0-1-17.jpg)

QEU:FOUNDER ： “もう一つのキー・テクノロジーは「爽」です。**「爽」とは、「不合理に対する共感」です**。ただし、小生の経験から言うとね・・・。C国人は、この２つを持っているから強いAIをつくる。この解説の外は無意味だね。”
