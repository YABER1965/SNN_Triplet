---
title: QEUR23_SMNRT41 – PyTorchでTripletをやってみる(MNIST-その2)
date: 2025-01-13
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "NSOARTC", "データセット", "外観検査", "Vision language Model"]
excerpt: Siamese Networkをやってみる
---

## QEUR23_SMNRT42 – PyTorchでTripletをやってみる(外観検査)

## ～ なんで、失敗したのかなぁ・・・（笑）？ ～

QEU:FOUNDER ： “さて、TRIPLETを使って外観検査の予測をしてみましょう”

**(Siamese Neural Networkで予測した結果)**

![imageSMR2-42-1](/2025-01-14-QEUR23_SMNRT42/imageSMR2-42-1.jpg)

D先生 ： “この数字よりも、（パフォーマンスが）よくなるのかなあ・・・？”

QEU:FOUNDER ： “なにはともあれ、プログラムをドン！！類似のプログラムを何度も作っているので、徹底的に省略しますよ。”

```python
#########################################
# ANCHORのベクトル群を生成する
# TARGET = 以下のラベルのデータ群の平均値ベクトルとなる
# train_label: [0, 11, 13, 21, 23, 31, 32, 33, 42, 61, 62, 63, 71, 72, 73, 81, 82, 91, 92]
#########################################
# ---
def create_anchors(dataset, TARGET):
    # ---
    # 条件をもとにフィルタリング
    cut_dataset = dataset.filter(lambda example: example["label"]==TARGET)
    # ---
    # データセットの確認
    cut_image = cut_dataset["image"]
    #print(cut_image.shape)
    cut_label = cut_dataset["label"]
    #print(cut_label)
    # ---
    # anchorを生成する
    anchor_X = torch.zeros([cut_image.shape[1], cut_image.shape[2]])
    for i in range(cut_image.shape[1]):
        for j in range(cut_image.shape[2]):
            anchor_X[i,j] = torch.mean(cut_image[:,i,j])
    #print(anchor_X)

    return anchor_X.shape[0], anchor_X

# ---
# 平均画像を変数に保管する
anchor_Xs = []
arr_Xnum  = [] 
for TARGET in range(n_classes):
    num_Xs, mx_anchor = create_anchors(transformed_dataset, TARGET)
    anchor_Xs.append(mx_anchor)
    arr_Xnum.append(num_Xs)

##########################################
# DATASETS: SIAMESE(tRIPLET) MNIST
##########################################
from PIL import Image
from torch.utils.data import Dataset
from torch.utils.data.sampler import BatchSampler

# ---
class TripletMNIST_train(Dataset):
    def __init__(self, anchor_Xs, mnist_dataset, max_dataset, transform=None):
        # ---
        self.train_labels = mnist_dataset["label"].numpy()
        self.train_data = mnist_dataset["image"]
        self.anchor_data = anchor_Xs
        self.transform = transform
        # ---
        set_label = list(set(self.train_labels))
        self.len_label = len(set_label)
        print("len_label: ", self.len_label)
        # ---
        self.max_dataset = int(max_dataset / self.len_label)
        self.arr_idx_anchor = []
        self.arr_idx_positive = []
        self.arr_idx_negative = []
        
        # ここでmnist_datasetを属性として追加
        self.mnist_dataset = mnist_dataset
        
        for i in range(self.len_label):
            tmp_idx_positive = np.where(self.train_labels == i)[0]
            tmp_idx_negative = np.where(self.train_labels != i)[0] 
            for j in range(self.max_dataset):
                idx_positive = np.random.choice(tmp_idx_positive)
                idx_negative = np.random.choice(tmp_idx_negative)
                # ---
                self.arr_idx_anchor.append(i)
                self.arr_idx_positive.append(idx_positive)
                self.arr_idx_negative.append(idx_negative) 

    def __getitem__(self, index):
        img_anchor = self.anchor_data[self.arr_idx_anchor[index]]
        img_positive = self.train_data[self.arr_idx_positive[index]]
        img_negative = self.train_data[self.arr_idx_negative[index]]
        
        x = (img_anchor, img_positive, img_negative)
        
        if self.transform:
            img_anchor = self.transform(img_anchor)
            img_positive = self.transform(img_positive)
            img_negative = self.transform(img_negative)
            x = (img_anchor, img_positive, img_negative)
        
        return x, []

    def __len__(self):
        return len(self.arr_idx_anchor)  # ここでmnist_datasetの長さを返す

# ---
# Set up data loaders
torch_dataset = TripletMNIST_train(anchor_Xs, transformed_dataset, 70000) # Returns pairs of im-ages and target same/different

# ---
from sklearn.model_selection import train_test_split

# ---
train_dataset, test_dataset = train_test_split(torch_dataset, test_size=0.3)

```

D先生 ： “TRIPLET型式の学習データを生成する部分ですね。”

QEU:FOUNDER ： “さらに中間を省略して、つづきます。”

```python
##################################
# NETWORKS FUNCTIONS (TRIPLET)
##################################
# ---
# build model
class EmbeddingNet(nn.Module):
    def __init__(self):
        super(EmbeddingNet,self).__init__()
        self.linear1 = nn.Linear(36*39, 512) # 36 * 39 is the pixels for each image
        self.linear2 = nn.Linear(512, 256) #100 and 5o
        self.linear3 = nn.Linear(256, 256) #100 and 5o
        self.final = nn.Linear(256, 128)
        self.relu = nn.ReLU()
# Here we are just feeding the data into each layer, and returning the output, while defining an in-stance of this class.
# ここでは、このクラスのインスタンスを定義しながら、各レイヤーにデータを入力し、出力を返すだけです。
    def forward(self, img): #convert + flatten
        x = img.view(-1, 36*39)
        x = self.relu(self.linear1(x))
        x = self.relu(self.linear2(x))
        x = self.relu(self.linear3(x))
        x = self.final(x)
        return x

    def get_embedding(self, x):
        return self.forward(x)

class TripletNet(nn.Module):
    def __init__(self, embedding_net):
        super(TripletNet, self).__init__()
        self.embedding_net = embedding_net

    def forward(self, x1, x2, x3):
        output1 = self.embedding_net(x1)
        output2 = self.embedding_net(x2)
        output3 = self.embedding_net(x3)
        return output1, output2, output3

    def get_embedding(self, x):
        return self.embedding_net(x)

# ---
##########################################
# LOSS FUNCTIONS
##########################################
# ---
class TripletLoss(nn.Module):
    """
    Triplet loss
    Takes embeddings of an anchor sample, a positive sample and a negative sample
    """
    def __init__(self, margin):
        super(TripletLoss, self).__init__()
        self.margin = margin

    def forward(self, anchor, positive, negative, size_average=True):
        distance_positive = (anchor - positive).pow(2).sum(1)  # .pow(.5)
        distance_negative = (anchor - negative).pow(2).sum(1)  # .pow(.5)
        losses = F.relu(distance_positive - distance_negative + self.margin)
        return losses.mean() if size_average else losses.sum()

```

QEU:FOUNDER ： “プログラムの晒しは、ここまで！！”

D先生 ： “いや～、コードが簡単になりましたね(笑)。”

**(TRIPLET)**

![imageSMR2-42-2](/2025-01-14-QEUR23_SMNRT42/imageSMR2-42-2.jpg)

QEU:FOUNDER ： “基本的なしくみがわかれば、今回のコードなんか、もう誰もが作れるようになっているでしょう。さて、このようにEmbeddingの散布図がでました。前回のSiamese NNの結果と比較してみようか？”

**(SIAMESE)**

![imageSMR2-42-3](/2025-01-14-QEUR23_SMNRT42/imageSMR2-42-3.jpg)

D先生 ： “なるほど・・・。TRIPLETとSIAMESEのEmbeddingの分布は似ていますね。肝心の判別精度はどうですか？”

QEU:FOUNDER ： “はいよ。ドン！！”

![imageSMR2-42-4](/2025-01-14-QEUR23_SMNRT42/imageSMR2-42-4.jpg)

D先生 ： “ゲッ！悪い結果がでてしまった。なぜだろう・・・。”

QEU:FOUNDER ： “なんか、**Confusion Matrixの特定の位置に問題が集中しています**ね。またもや、「合格品と不合格品の間の混乱」なのか・・・。”

D先生 ： “そういえば、合格品（LABEL=0）のデータ数量は、他のラベルの数量と同じですか？”

QEU:FOUNDER ： “プログラムを見てください。もちろん、全てのラベルが同じ数量ですよ。”

D先生 ： “ああ・・・、そうか。**学習データの生成バランスを間違い**ましたね。合格品をアンカーとするデータは、他よりも多くしなければいけません。他の水準の5倍ぐらいは必要ですね。”


## ～ まとめ ～

### ・・・ 前回のつづきです ・・・

QEU:FOUNDER ： “J国の農業って、国際的な貿易協議の中でつねに交渉取引のネタにされて、その結果として弱体化をしつづけたじゃないですか。たしか、**近年のJ国の食料自給率がひどいことになっている**とか・・・。”

![imageSMR2-42-5](/2025-01-14-QEUR23_SMNRT42/imageSMR2-42-5.jpg)

C部長 : “J国が農業を犠牲にし、そのかわりとして最も重視していた分野がEVの普及とともに大いにコケた！ これが、大いに影響しています。“

QEU:FOUNDER ： “インバウンドでは、農業がより重要になるのだが、果たして農業の復興は間に合うのか？それに引き換え、A国は賢いわあ・・・。”

![imageSMR2-42-6](/2025-01-14-QEUR23_SMNRT42/imageSMR2-42-6.jpg)

C部長 : “え～っつつつつ？あの、無茶苦茶な要求が？ “

QEU:FOUNDER ： “A国は、もっと先を見ていると思います。たしか、E.マスクさんがブレインにいるんでしょう？”

![imageSMR2-42-7](/2025-01-14-QEUR23_SMNRT42/imageSMR2-42-7.jpg)

QEU:FOUNDER ： “BIG_TECHにいる人であれば、AIが将来に社会にもたらすものが、見当がついているはずです。確か、SAM_ALTMANが言っていたんだっけ・・・。だが、引用元が見当たらない。**近未来には、すべての人間の能力は、「ほとんど同じ」になります**。最終的な違い（成功 or 失敗）は、**「その人がもっているもの」**だけになります。この理屈を国に敷衍すれば？”

![imageSMR2-42-8](/2025-01-14-QEUR23_SMNRT42/imageSMR2-42-8.jpg)

C部長 : “国にとって、**資源が最も重要**です。たしかに、その考え方は賢い。それにしても、Tさんも、ずいぶん乱暴な進め方だなあ・・・。それほど、**A国は焦っている**んだろうか・・・。“

QEU:FOUNDER ： “もちろん、とても焦っているよ。現実として、ほぼ**「詰みの状態」**だから・・・。さて、資源の必要性については、前述の通りだが、もう一つの重大問題である海運はもっとややこしいんだよなあ。A国がC国を必要とするのは、資源が目的じゃないんですよ。Tとかいう正直者が、そう言ってくれたらしい（伝聞なので知らんが・・・）。”

![imageSMR2-42-9](/2025-01-14-QEUR23_SMNRT42/imageSMR2-42-9.jpg)

C部長 : “じゃあ、目的は何ですか？A国が、それほど焦っている理由は？“

![imageSMR2-42-10](/2025-01-14-QEUR23_SMNRT42/imageSMR2-42-10.jpg)

QEU:FOUNDER ： “**北極海航路の確保**でしょ？”

C部長 : “えっ！？パナマがあるじゃないですか？たしかに、いまGランドと同様に、話題にはなっているが・・・。“

![imageSMR2-42-11](/2025-01-14-QEUR23_SMNRT42/imageSMR2-42-11.jpg)

QEU:FOUNDER ： “**あの周辺には、すでに「水がない」んです。**今後の気候変動の進展を考えると、長期的には、あそこには「見込みはない」んじゃないか？・・・でもね。そもそも、A国って、北極海航路を気にする必要はないんです。もしも、A国の貨物鉄道路がまともであれば・・・。”

![imageSMR2-42-12](/2025-01-14-QEUR23_SMNRT42/imageSMR2-42-12.jpg)

C部長 : “へえ・・・。バフェットさんは、貨物鉄道会社のオーナーなんですか。 “

QEU:FOUNDER ： “さすがに、A国の**実体経済の根幹**がどこにあるかを心得ているよね。問題は、あの広大なA国で、鉄道網はどう見ても不足しているんですよ。もし、A国の鉄道網が、もっとしっかりしていたら、北極海航路なんかは気にしなくてもいいと思います。A国は、東海岸と西海岸を持っているのですから、そもそも**海運上で心配する必要はない**んです。”

C部長 : “A国は、**自動車会社(BIG3 etc.)に遠慮をしちゃって、長年にわたって、鉄道開発を軽視**しており、そのツケが今来たんですよね。 その意味で、A国は賢いのか、それとも「アレ」なのか・・・。“

![imageSMR2-42-13](/2025-01-14-QEUR23_SMNRT42/imageSMR2-42-13.jpg)

QEU:FOUNDER ： “それに引き換え、C国は**「しっかりと正しい道を歩いている」**と思わん？ちゃんとしているから、C国は、他の国に**余計な迷惑を掛けない**んですよ。”

![imageSMR2-42-14](/2025-01-14-QEUR23_SMNRT42/imageSMR2-42-14.jpg)

C部長 : “20年前はA国は、他と卓越してスゴイと思っていました。2010年代には、A国は、C国に追い越されて、いまはC国に差をつけられたような気がします。 “

[![MOVIE1](http://img.youtube.com/vi/zK1agQgDJVE/0.jpg)](http://www.youtube.com/watch?v=zK1agQgDJVE "斎藤元彦・兵庫県知事をかばってしまう日本の老人「上に立つ人は正しい」")

QEU:FOUNDER ： “いま、A国が、「お隣のCA国」をイジメているけど。もし、CA国がキレて、BRICSに入ってみ？**A国は、その瞬間に「見事に終わる」**から・・・。そうすれば、強い者になびくJ国のオッサンも、少しだけ変わるかな?”

