---
title: QEUR23_SMNRT20 –  PyTorchとSIMPLEなモデルで予測する(外観検査)
date: 2025-01-03
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "NSOARTC", "データセット", "外観検査", "Vision language Model"]
excerpt: Siamese Networkをやってみる
---

## QEUR23_SMNRT20 –  PyTorchとSIMPLEなモデルで予測する(外観検査)

## ～ シンプル・モデルなので、結果はダメでもともとです ～

QEU:FOUNDER ： “それでは、PyTorchを用いた学習プログラムで外観検査データを入力したときに、どの程度の予測精度がでるのかをトライしましょう。前回の画像判別事例(MNIST)では、非常に高い精度がでています。”

**(画像判別に使用したデータセット)**

![imageSMR2-11-1](/2025-01-03-QEUR23_SMNRT20/imageSMR2-11-1.jpg)

**(SIMPLEモデルで学習した結果)**

![imageSMR2-11-2](/2025-01-03-QEUR23_SMNRT20/imageSMR2-11-2.jpg)

D先生 ： “相手が「手書き文字」なので、（パフォーマンスが良いのは）あたりまえです。今回は、外観検査ですよね。ただし、画像はNSOARTCメトリックスに変換されています。”

![imageSMR2-11-3](/2025-01-03-QEUR23_SMNRT20/imageSMR2-11-3.jpg)

QEU:FOUNDER ： “そのメトリックス変換された状態については、後で見てみましょう。何はともあれ、プログラムをドン！！”

```python
# ----
# Importing the dataset
import numpy as np
import pandas as pd
from datasets import Dataset, load_dataset
# ---
import random
import matplotlib
import matplotlib.pyplot as plt

# ---
####################
# データフレームdfから、学習に必要なXs,Ysを分解する関数
####################
# ---
def create_data(load_df):
    # ---
    X = load_df.loc[:,'data0':'data1403'].values
    label = load_df.loc[:,'label'].values
    fmode = load_df.loc[:,'fmode'].values
    #print(fmode[0:20])

    return X, label, fmode

# ---
dataset = load_dataset('YxBxRyXJx/NSOARTC_Tanshi_1221', split='train')
#print(datasets)
# ---
# データセットをPandasのデータフレームに変換
org_df = pd.DataFrame(dataset)  # 'train'分割を使用する場合
# データフレームの内容を表示
#print(org_df)
# ---
# 何種類のラベルがあるか？
labels = org_df.loc[:,'label'].values
set_label = list(set(labels))
print(set_label)

# ---
# データフレームの行をランダムにシャッフル
shuffled_df = org_df.sample(frac=1).reset_index(drop=True)

# ---
# X-Y分解(シャッフル)
shuffled_X, shuffled_label, shuffled_fmode = create_data(shuffled_df)
print(shuffled_X.shape)
##print(shuffled_X[0:20])

################################
# draw_images
################################
# ---
# ひとつのデータを抽出する
def draw_images(shuffled_X, shuffled_label, shuffled_fmode):
    # ---
    fig = plt.figure(figsize=[8,10])
    plt.suptitle("Data Visualization(1-4)")
    for i in range(4):
        str_label = shuffled_label[i]
        str_fmode = shuffled_fmode[i]
        # ---
        fig.add_subplot(2, 2, i+1)
        plt.title(f"LABEL:{str_label}",fontsize = 11)
        plt.imshow(shuffled_X[i].reshape(36,39), cmap='hot', interpolation='nearest')
        plt.tight_layout()
        plt.axis('off')       
    # ---
    # ヒートマップを表示
    plt.show()

# ---
# データを抽出して、グラフにする
draw_images(shuffled_X, shuffled_label, shuffled_fmode)

```

QEU:FOUNDER ： “ここまでで、NSOARTCメトリックスの様子がわかります。もちろん、何回も紹介しているものなんですが・・・。”

![imageSMR2-11-4](/2025-01-03-QEUR23_SMNRT20/imageSMR2-11-4.jpg)

D先生 ： “全体として、全く同じ様子に見えますが、一部だけが異常になります。その異常の部分が明るい色になるんですね。その傾向を、モデルが如何に学習するかが課題です。データ数はいくらでしたっけ・・・。”

QEU:FOUNDER ： “**たった3600件しかないです。**これをtrain-testに分割するので、情報が少ないですよね。まあ、それはしようがないのです。データ数は、TRIPLETの適用で盛り返せばいいのですから・・・。ともあれ、プログラムの晒しを続けましょう。”

```python
# ---
# Install and import required dependencies
from torch.utils.data import DataLoader, TensorDataset, Subset
import torch
import torch.nn as nn
import torch.optim as optim
# ---
from tqdm.autonotebook import tqdm
import math
import time
import multiprocessing

# ---
####################################
# HUGGINGFACE DATASET を生成する
####################################
# ---
# NumPy配列からHugging Face Datasetの作成
data_dict = {
    "features": list(map(list, shuffled_X)),  # 各レコードの特徴をリストに変換
    "label": shuffled_label.tolist()                # ラベルをリストに変換
}

# Hugging Face Datasetの作成
dataset = Dataset.from_dict(data_dict)
transformed_dataset = dataset.with_format("torch")

# Apply transformations
def collate_fn(example):
    example["image"] = example["features"].reshape(36,39)
    example["label"] = set_label.index(example["label"])
    return example

# ---
transformed_dataset = transformed_dataset.map(collate_fn, num_proc=multiprocessing.cpu_count())
transformed_dataset = transformed_dataset.remove_columns("features")

# ---
# Common setup
import torch
from torch.optim import lr_scheduler
import torch.optim as optim
from torch.autograd import Variable
# ---
import torch.nn as nn
import torch.nn.functional as F
# ---
import numpy as np
import random
import matplotlib
import matplotlib.pyplot as plt

# ---
set_label = list(set(labels))
n_classes = len(set_label)
mnist_classes = set_label

##################################
# NETWORKS FUNCTIONS
##################################
# ---
# build model
class EmbeddingNet(nn.Module):
    def __init__(self):
        super(EmbeddingNet,self).__init__()
        self.linear1 = nn.Linear(36*39, 256) #28 * 28 is the pixels for each image
        self.linear2 = nn.Linear(256, 256) #100 and 5o
        self.final = nn.Linear(256, 2)
        self.relu = nn.ReLU()
# Here we are just feeding the data into each layer, and returning the output, while defining an in-stance of this class.
# ここでは、このクラスのインスタンスを定義しながら、各レイヤーにデータを入力し、出力を返すだけです。
    def forward(self, img): #convert + flatten
        x = img.view(-1, 36*39)
        x = self.relu(self.linear1(x))
        x = self.relu(self.linear2(x))
        x = self.final(x)
        return x

    def get_embedding(self, x):
        return self.forward(x)

# ---
class ClassificationNet(nn.Module):
    def __init__(self, embedding_net, n_classes):
        super(ClassificationNet, self).__init__()
        self.embedding_net = embedding_net
        self.n_classes = n_classes
        self.nonlinear = nn.PReLU()
        self.fc1 = nn.Linear(2, n_classes)

    def forward(self, x):
        output = self.embedding_net(x)
        output = self.nonlinear(output)
        scores = F.log_softmax(self.fc1(output), dim=-1)
        return scores

    def get_embedding(self, x):
        return self.nonlinear(self.embedding_net(x))

##################################
# METRICS FUNCTIONS
##################################
# ---
class Metric:
    def __init__(self):
        pass

    def __call__(self, outputs, target, loss):
        raise NotImplementedError

    def reset(self):
        raise NotImplementedError

    def value(self):
        raise NotImplementedError

    def name(self):
        raise NotImplementedError

class AccumulatedAccuracyMetric(Metric):
    """
    Works with classification model
    """
    def __init__(self):
        self.correct = 0
        self.total = 0

    def __call__(self, outputs, target, loss):
        pred = outputs[0].data.max(1, keepdim=True)[1]
        self.correct += pred.eq(target[0].data.view_as(pred)).cpu().sum()
        self.total += target[0].size(0)
        return self.value()

    def reset(self):
        self.correct = 0
        self.total = 0

    def value(self):
        return 100 * float(self.correct) / self.total

    def name(self):
        return 'Accuracy'

################################
# TRAIN - FIT FUNCTIONS
################################
# ---
def train_epoch(train_loader, model, loss_fn, optimizer, cuda, log_interval, metrics):
    for metric in metrics:
        metric.reset()

    model.train()
    losses = []
    total_loss = 0

    for batch_idx, (data, target) in enumerate(train_loader):
        target = target.long() if len(target.long()) > 0 else None
        if not type(data) in (tuple, list):
            data = (data,)
        if cuda:
            data = tuple(d.cuda() for d in data)
            if target.long() is not None:
                target = target.long().cuda()

        optimizer.zero_grad()
        outputs = model(*data)

        if type(outputs) not in (tuple, list):
            outputs = (outputs,)

        loss_inputs = outputs
        if target.long() is not None:
            target = (target,)
            loss_inputs += target

        loss_outputs = loss_fn(*loss_inputs)
        loss = loss_outputs[0] if type(loss_outputs) in (tuple, list) else loss_outputs
        losses.append(loss.item())
        total_loss += loss.item()
        loss.backward()
        optimizer.step()

        for metric in metrics:
            metric(outputs, target, loss_outputs)

        if batch_idx % log_interval == 0:
            message = 'Train: [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                batch_idx * len(data[0]), len(train_loader.dataset),
                100. * batch_idx / len(train_loader), np.mean(losses))
            for metric in metrics:
                message += '\t{}: {}'.format(metric.name(), metric.value())

            print(message)
            losses = []

    total_loss /= (batch_idx + 1)
    return total_loss, metrics

# ---
def test_epoch(val_loader, model, loss_fn, cuda, metrics):
    with torch.no_grad():
        for metric in metrics:
            metric.reset()
        model.eval()
        val_loss = 0
        for batch_idx, (data, target) in enumerate(val_loader):
            target = target.long() if len(target.long()) > 0 else None
            if not type(data) in (tuple, list):
                data = (data,)
            if cuda:
                data = tuple(d.cuda() for d in data)
                if target.long() is not None:
                    target = target.long().cuda()

            outputs = model(*data)

            if type(outputs) not in (tuple, list):
                outputs = (outputs,)
            loss_inputs = outputs
            if target.long() is not None:
                target = (target,)
                loss_inputs += target

            loss_outputs = loss_fn(*loss_inputs)
            loss = loss_outputs[0] if type(loss_outputs) in (tuple, list) else loss_outputs
            val_loss += loss.item()

            for metric in metrics:
                metric(outputs, target, loss_outputs)

    return val_loss, metrics

# ---
def fit(train_loader, val_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval, metrics=[],
        start_epoch=0):
    """
    ローダー、モデル、損失関数、およびメトリックは、特定のタスクに対して連携して動作する必要があります。
    """
    for epoch in range(0, start_epoch):
        scheduler.step()

    for epoch in range(start_epoch, n_epochs):
        scheduler.step()

        # Train stage
        train_loss, metrics = train_epoch(train_loader, model, loss_fn, optimizer, cuda, log_interval, metrics)

        message = 'Epoch: {}/{}. Train set: Average loss: {:.4f}'.format(epoch + 1, n_epochs, train_loss)
        for metric in metrics:
            message += '\t{}: {}'.format(metric.name(), metric.value())

        val_loss, metrics = test_epoch(val_loader, model, loss_fn, cuda, metrics)
        val_loss /= len(val_loader)

        message += '\nEpoch: {}/{}. Validation set: Average loss: {:.4f}'.format(epoch + 1, n_epochs,
                                                                                 val_loss)
        for metric in metrics:
            message += '\t{}: {}'.format(metric.name(), metric.value())

        print(message)

```

D先生 ： “パフォーマンスの結果がでました。やっぱり、思った通りで「ダメダメ」です。Epochと損失の推移をみても、これ以上は良くなりそうもないですね。”

![imageSMR2-11-5](/2025-01-03-QEUR23_SMNRT20/imageSMR2-11-5.jpg)

D先生 ： “確か、昔、Kerasでやってきたときにはもう少しパフォーマンスが良かったような気がします。”

QEU:FOUNDER ： “Kerasの場合は、ユーザーが細かく条件を指定しなくとも、すでに最適化されているから・・・。あと、モデルの構造も昔と違います。今回のモデルは、Embeddingが出力されるように設計されているでしょ？”

D先生 ： “そうだ！Embeddingで判別してみればいいんだ！！”

QEU:FOUNDER ： “いやあ・・・。ここまで予測精度がわるいと、Embeddingでもダメだと思います。**ちょっと反則技になる**のだが、Training-Testのデータを使って、混同マトリックスを生成してみましょう。”

```python
###############################
# CONFUSION MATRIX(こんなデータを使ってはいけない！！)
###############################
arr_actual = []
arr_pred = []
# ---
for i in range(len(transformed_dataset)):
    # ---
    tensor_x = torch.unsqueeze(transformed_dataset[i]["image"],1)
    #print(tensor_x)
    # ---
    outputs = model(tensor_x.cuda())
    #print(outputs)
    # ---
    index_output = torch.argmax(outputs)
    #print(index_output.item())
    arr_actual.append(transformed_dataset[i]["label"].item())
    arr_pred.append(index_output.item())

################################
# CREATING CONFUSION MATRIX
################################
# ---
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
#import numpy as np

# 混同行列の生成
cm = confusion_matrix(arr_actual, arr_pred)

# Confusion matrixの表示
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)

# X軸ラベル、Y軸ラベル、タイトルの追加
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')

# Confusion matrixの表示
plt.show()

```

D先生 ： “今回は、Trainデータをパフォーマンス評価に使うという「反則技」を使いました。それでも、こんなにひどいんですか！？”

![imageSMR2-11-6](/2025-01-03-QEUR23_SMNRT20/imageSMR2-11-6.jpg)

QEU:FOUNDER  ： “ここで、ラベル番号が0というのは「合格品」という意味です。このマトリックスが意味するものは、**「モデルには識別能力は全然なく、ベースとなる合格品のまま」**というモデルの分解能不足を現しています。Embeddingの生成結果を見てみますか？”

D先生 ： “無意味ですね”

QEU:FOUNDER ： “Embeddingは、Siamese Neural Networkになってから、Embedding 生成機能を使ってみましょう。”



## ～ まとめ ～

QEU:FOUNDER ： “この人（↓）の一言、いいと思いません？”

![imageSMR2-11-7](/2025-01-03-QEUR23_SMNRT20/imageSMR2-11-7.jpg)

C部長 : “えぇ～えっつ！？ちょっとヘンじゃないですか？ “

![imageSMR2-11-8](/2025-01-03-QEUR23_SMNRT20/imageSMR2-11-8.jpg)

QEU:FOUNDER ： “まずは素直ですよね。**「美しい」、「強い」、「豊か」とかいう従来の言葉を使わない**わけだし・・・(笑)。悲観ばかりしても、何も始まらないですよ。”

C部長 : “**「J国すげー」じゃ、なにも始まらない**ですよね。 “

![imageSMR2-11-9](/2025-01-03-QEUR23_SMNRT20/imageSMR2-11-9.jpg)

QEU:FOUNDER ： “**楽しくないと、何も創造できな**いしね。あともう一つ、これはVERY GOODなジョブなんだわ・・・。”

![imageSMR2-11-10](/2025-01-03-QEUR23_SMNRT20/imageSMR2-11-10.jpg)

C部長 : “うわぁ・・・。”

![imageSMR2-11-11](/2025-01-03-QEUR23_SMNRT20/imageSMR2-11-11.jpg)

QEU:FOUNDER ： “このオッサンも連れて行けばいいのに・・・。”

![imageSMR2-11-12](/2025-01-03-QEUR23_SMNRT20/imageSMR2-11-12.jpg)

QEU:FOUNDER ： “この人（↑）は、リベラルな能天気さんたちがリスペクトするが、ホントはどんなものなのか・・・。”

[![MOVIE1](http://img.youtube.com/vi/TwXZuJKbCSQ/0.jpg)](http://www.youtube.com/watch?v=TwXZuJKbCSQ "会田弘継 氏出演！「深層／真相のアメリカを考える」")

C部長 : “なるほど。**「終わり」が「始まり」の終わりを見送る。**感動的な、いい話ですね。“
