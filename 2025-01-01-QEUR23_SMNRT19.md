---
title: QEUR23_SMNRT19 : PyTorchとSNNモデルでEmbeddingを生成する(MNIST)
date: 2025-01-01
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "NSOARTC", "データセット", "外観検査", "Vision language Model"]
excerpt: Siamese Networkをやってみる
---

## QEUR23_SMNRT19 : PyTorchとSNNモデルでEmbeddingを生成する(MNIST)

## ～ 実は、「やりたいこと」は別にある・・・ ～

D先生 ： “前回のトライアルでは、PyTorchと普通のディープラーニング・モデルを使って、MNISTを学習して、Embedding ベクトルを生成することに成功しました。このEmbeddingベクトルは、MTシステムの入力シーズとして、有望になると思われます。”

![imageSMR2-10-1](/2025-01-01-QEUR23_SMNRT19/imageSMR2-10-1.jpg)

QEU:FOUNDER ： “つぎはSiamese Neural Network(SNN)も、やってみましょう。序盤のコードを削除します。”

```python
##################################
# NETWORKS FUNCTIONS
##################################
# ---
class EmbeddingNet(nn.Module):
    def __init__(self):
        super(EmbeddingNet,self).__init__()
        self.linear1 = nn.Linear(28*28, 256) #28 * 28 is the pixels for each image
        self.linear2 = nn.Linear(256, 256) #100 and 5o
        self.final = nn.Linear(256, 2)
        self.relu = nn.ReLU()
# Here we are just feeding the data into each layer, and returning the output, while defining an in-stance of this class.
# ここでは、このクラスのインスタンスを定義しながら、各レイヤーにデータを入力し、出力を返すだけです。
    def forward(self, img): #convert + flatten
        x = img.view(-1, 28*28)
        x = self.relu(self.linear1(x))
        x = self.relu(self.linear2(x))
        x = self.final(x)
        return x

    def get_embedding(self, x):
        return self.forward(x)

class SiameseNet(nn.Module):
    def __init__(self, embedding_net):
        super(SiameseNet, self).__init__()
        self.embedding_net = embedding_net

    def forward(self, x1, x2):
        output1 = self.embedding_net(x1)
        output2 = self.embedding_net(x2)
        return output1, output2

    def get_embedding(self, x):
        return self.embedding_net(x)

##################################
# METRICS FUNCTIONS
##################################
# ---
class Metric:
    def __init__(self):
        pass

    def __call__(self, outputs, target, loss):
        raise NotImplementedError

    def reset(self):
        raise NotImplementedError

    def value(self):
        raise NotImplementedError

    def name(self):
        raise NotImplementedError

class AccumulatedAccuracyMetric(Metric):
    """
    Works with classification model
    """
    def __init__(self):
        self.correct = 0
        self.total = 0

    def __call__(self, outputs, target, loss):
        pred = outputs[0].data.max(1, keepdim=True)[1]
        self.correct += pred.eq(target[0].data.view_as(pred)).cpu().sum()
        self.total += target[0].size(0)
        return self.value()

    def reset(self):
        self.correct = 0
        self.total = 0

    def value(self):
        return 100 * float(self.correct) / self.total

    def name(self):
        return 'Accuracy'

##################################
# TRAIN - FIT FUNCTIONS
##################################
# ---
def train_epoch(train_loader, model, loss_fn, optimizer, cuda, log_interval, metrics):
    for metric in metrics:
        metric.reset()

    model.train()
    losses = []
    total_loss = 0

    for batch_idx, (data, target) in enumerate(train_loader):
        target = target if len(target) > 0 else None
        if not type(data) in (tuple, list):
            data = (data,)
        if cuda:
            data = tuple(d.cuda() for d in data)
            if target is not None:
                target = target.cuda()

        optimizer.zero_grad()
        outputs = model(*data)

        if type(outputs) not in (tuple, list):
            outputs = (outputs,)

        loss_inputs = outputs
        if target is not None:
            target = (target,)
            loss_inputs += target

        loss_outputs = loss_fn(*loss_inputs)
        loss = loss_outputs[0] if type(loss_outputs) in (tuple, list) else loss_outputs
        losses.append(loss.item())
        total_loss += loss.item()
        loss.backward()
        optimizer.step()

        for metric in metrics:
            metric(outputs, target, loss_outputs)

        if batch_idx % log_interval == 0:
            message = 'Train: [{}/{} ({:.0f}%)]\tLoss: {:.6f}'.format(
                batch_idx * len(data[0]), len(train_loader.dataset),
                100. * batch_idx / len(train_loader), np.mean(losses))
            for metric in metrics:
                message += '\t{}: {}'.format(metric.name(), metric.value())

            print(message)
            losses = []

    total_loss /= (batch_idx + 1)
    return total_loss, metrics

# ---
def test_epoch(val_loader, model, loss_fn, cuda, metrics):
    with torch.no_grad():
        for metric in metrics:
            metric.reset()
        model.eval()
        val_loss = 0
        for batch_idx, (data, target) in enumerate(val_loader):
            target = target if len(target) > 0 else None
            if not type(data) in (tuple, list):
                data = (data,)
            if cuda:
                data = tuple(d.cuda() for d in data)
                if target is not None:
                    target = target.cuda()

            outputs = model(*data)

            if type(outputs) not in (tuple, list):
                outputs = (outputs,)
            loss_inputs = outputs
            if target is not None:
                target = (target,)
                loss_inputs += target

            loss_outputs = loss_fn(*loss_inputs)
            loss = loss_outputs[0] if type(loss_outputs) in (tuple, list) else loss_outputs
            val_loss += loss.item()

            for metric in metrics:
                metric(outputs, target, loss_outputs)

    return val_loss, metrics

# ---
def fit(train_loader, val_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval, metrics=[],
        start_epoch=0):
    for epoch in range(0, start_epoch):
        scheduler.step()

    for epoch in range(start_epoch, n_epochs):
        scheduler.step()

        # Train stage
        train_loss, metrics = train_epoch(train_loader, model, loss_fn, optimizer, cuda, log_interval, metrics)

        message = 'Epoch: {}/{}. Train set: Average loss: {:.4f}'.format(epoch + 1, n_epochs, train_loss)
        for metric in metrics:
            message += '\t{}: {}'.format(metric.name(), metric.value())

        val_loss, metrics = test_epoch(val_loader, model, loss_fn, cuda, metrics)
        val_loss /= len(val_loader)

        message += '\nEpoch: {}/{}. Validation set: Average loss: {:.4f}'.format(epoch + 1, n_epochs,
                                                                                 val_loss)
        for metric in metrics:
            message += '\t{}: {}'.format(metric.name(), metric.value())

        print(message)

##########################################
# DATASETS: SIAMESE MNIST
##########################################
from PIL import Image
from torch.utils.data import Dataset
from torch.utils.data.sampler import BatchSampler
# ---
class SiameseMNIST(Dataset):
    """
    Train: For each sample creates randomly a positive or a negative pair
    Test: Creates fixed pairs for testing
    """
    def __init__(self, mnist_dataset):
        self.mnist_dataset = mnist_dataset

        self.train = self.mnist_dataset.train
        self.transform = self.mnist_dataset.transform

        if self.train:
            self.train_labels = self.mnist_dataset.train_labels
            self.train_data = self.mnist_dataset.train_data
            self.labels_set = set(self.train_labels.numpy())
            self.label_to_indices = {label: np.where(self.train_labels.numpy() == label)[0]
                                     for label in self.labels_set}
        else:
            # generate fixed pairs for testing
            self.test_labels = self.mnist_dataset.test_labels
            self.test_data = self.mnist_dataset.test_data
            self.labels_set = set(self.test_labels.numpy())
            self.label_to_indices = {label: np.where(self.test_labels.numpy() == label)[0]
                                     for label in self.labels_set}

            random_state = np.random.RandomState(29)

            positive_pairs = [[i, random_state.choice(self.label_to_indices[self.test_labels[i].item()]), 1]
                              for i in range(0, len(self.test_data), 2)]

            negative_pairs = [[i, random_state.choice(self.label_to_indices[
                                        np.random.choice( list(self.labels_set - set([self.test_labels[i].item()]))                                        )
                                    ]), 0]
                              for i in range(1, len(self.test_data), 2)]
            self.test_pairs = positive_pairs + negative_pairs

    def __getitem__(self, index):
        if self.train:
            target = np.random.randint(0, 2)
            img1, label1 = self.train_data[index], self.train_labels[index].item()
            if target == 1:
                siamese_index = index
                while siamese_index == index:
                    siamese_index = np.random.choice(self.label_to_indices[label1])
            else:
                siamese_label = np.random.choice(list(self.labels_set - set([label1])))
                siamese_index = np.random.choice(self.label_to_indices[siamese_label])
            img2 = self.train_data[siamese_index]
        else:
            img1 = self.test_data[self.test_pairs[index][0]]
            img2 = self.test_data[self.test_pairs[index][1]]
            target = self.test_pairs[index][2]

        img1 = Image.fromarray(img1.numpy(), mode='L')
        img2 = Image.fromarray(img2.numpy(), mode='L')
        if self.transform is not None:
            img1 = self.transform(img1)
            img2 = self.transform(img2)
        return (img1, img2), target

    def __len__(self):
        return len(self.mnist_dataset)

##########################################
# LOSS FUNCTIONS
##########################################
# ---
class ContrastiveLoss(nn.Module):
    """
    Contrastive loss
    Takes embeddings of two samples and a target label == 1 if samples are from the same class and label == 0 otherwise
    2つのサンプルの埋め込みと、サンプルが同じクラスからのものである場合はターゲットラベル == 1、そうでない場合はラベル == 0 を取得します。
    """
    def __init__(self, margin):
        super(ContrastiveLoss, self).__init__()
        self.margin = margin
        self.eps = 1e-9

    def forward(self, output1, output2, target, size_average=True):
        distances = (output2 - output1).pow(2).sum(1)  # squared distances
        losses = 0.5 * (target.float() * distances +
                        (1 + -1 * target).float() * F.relu(self.margin - (distances + self.eps).sqrt()).pow(2))
        return losses.mean() if size_average else losses.sum()

################################
# PARAMETER SETTING
################################
# ---
# Set up the network and training parameters
# ---
margin = 1.
embedding_net = EmbeddingNet()
model = SiameseNet(embedding_net)
#cuda = torch.cuda.is_available()
if cuda:
    model.cuda()
loss_fn = ContrastiveLoss(margin)
lr = 1e-3
optimizer = optim.Adam(model.parameters(), lr=lr)
scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)
n_epochs = 10
log_interval = 100

```

D先生 ： “**2画像の差異を評価する距離は**、プログラムのどこで定義しているんですか？”

![imageSMR2-10-2](/2025-01-01-QEUR23_SMNRT19/imageSMR2-10-2.jpg)

QEU:FOUNDER ： “ここにありますよ。ホラ・・・。”

```python
positive_pairs = [[i, random_state.choice(self.label_to_indices[self.test_labels[i].item()]), 1]
				  for i in range(0, len(self.test_data), 2)]

negative_pairs = [[i, random_state.choice(self.label_to_indices[
							np.random.choice( list(self.labels_set - set([self.test_labels[i].item()]))                                        )
						]), 0]
				  for i in range(1, len(self.test_data), 2)]
self.test_pairs = positive_pairs + negative_pairs

```

D先生 ： “ああ、そうか・・・。**POSITIVE（ラベルが一致している）**のであれば、距離値を１に、**NEGATIVE（一致していない）**のであれば距離値を0にしていますね。このやり方がシンプルで、とてもいいですね。”

QEU:FOUNDER ： “じゃあ、いよいよ学習に入りましょう。”

```python
#########################################
# SIAMESE: ONE-SHOT LEARNING
#########################################
# Siamese network
# ここで、画像のペアを受け取り、同じクラスの画像の場合はそれらの間の距離が最小になるように、異なるクラスの画像の場合はあるマージン値よりも大きくなるように埋め込みをトレーニングする、シャムネットワークをトレーニングします。
# ---
# Set up data loaders
siamese_train_dataset = SiameseMNIST(train_dataset) # Returns pairs of images and target same/different
siamese_test_dataset = SiameseMNIST(test_dataset)
batch_size = 128
kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}
siamese_train_loader = torch.utils.data.DataLoader(siamese_train_dataset, batch_size=batch_size, shuffle=True, **kwargs)
siamese_test_loader = torch.utils.data.DataLoader(siamese_test_dataset, batch_size=batch_size, shuffle=False, **kwargs)

##############################
# TRAINING RUN (SIAMESE)
##############################
# ---
fit(siamese_train_loader, siamese_test_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval)

```

D先生 ： “おっと、いよいよモデル学習システムが動き出したようです。それでは学習損失の推移を見てみましょう。そういえば、前回のように正解率(accuracy)がエポック毎に出てこないんですよね。”

![imageSMR2-10-3](/2025-01-01-QEUR23_SMNRT19/imageSMR2-10-3.jpg)

QEU:FOUNDER ： “それはしようがないです。本当に正しい答えは、Embeddingして得られるものですから・・・。なにはともあれ、Embeddingの散布図をみてみましょう。ちなみに、プログラムは前回とほぼ同じなので省略します。”

![imageSMR2-10-4](/2025-01-01-QEUR23_SMNRT19/imageSMR2-10-4.jpg)

D先生 ： “おっと！前回のシンプルなディープランニングのEmbeddingとは違います。”

![imageSMR2-10-5](/2025-01-01-QEUR23_SMNRT19/imageSMR2-10-5.jpg)

QEU:FOUNDER ： “SiameseのEmbeddingのプロットの分布は、他のラベルと重複しません。その意味で、もしもEmbeddingを使うのであれば、Siamese NNを使ったほうがいいです。”

D先生 ： “なるほど、Siamese NNは、とても便利ですね。”

QEU:FOUNDER ： “次は、外観検査のデータで、同様な処理をやってみましょう。Tripletはそれからです。”


## ～ まとめ ～

### ・・・ 前回の続きです ・・・

C部長 : “BONSAI4では、従来の学習された(UNSLOTH) LLMだけでなく、RAGで使用するEmbeddingモデルも同様に学習するんですよね？“

![imageSMR2-10-6](/2025-01-01-QEUR23_SMNRT19/imageSMR2-10-6.jpg)

QEU:FOUNDER ： “YES. ここがBONSAI4の先進的なところです。通常の方法は、適当にfinetuningのための情報を入力してモデルを学習していけば、RAGを通じて、学習情報に関連した情報が手に入って、LLMで新しい答えが出力されるでしょう。ただし、それはBONSAIにおいては**「議題(AGENDA)」**にすぎません。つまり、その学習済みのEmbeddingモデルには、**「自分の意図に合っているかどうか？(POSITIVE-NEGATIVE)」という評価情報が入っていません**。もし、「POSITIVE-NEGATIVE」の情報がモデルに入っていれば、自分が意図しないNEGATIVEな情報の収集を排除できるんです。”

![imageSMR2-10-7](/2025-01-01-QEUR23_SMNRT19/imageSMR2-10-7.jpg)

C部長 : “だからこそ、このBONSAI4のEmbeddingモデルの学習では、Tripletを使用する予定ですよね？“

QEU:FOUNDER ： “一応は、その予定です。・・・でも、tripletの採用だけで、BONSAI4の考えるゴールが達成できるかどうかはわかりません。さて、今年も押し迫ってきたことだし、次は、来年度において、外観検査のプロジェクトがどのような発展を遂げるのかについても説明しましょう。久々に、Unslothの件を考えてみます。”

![imageSMR2-10-8](/2025-01-01-QEUR23_SMNRT19/imageSMR2-10-8.jpg)

QEU:FOUNDER ： “具体的には、日々レベルアップしている**VLM (LLM)をどう使いこなすか**ということです。”

![imageSMR2-10-9](/2025-01-01-QEUR23_SMNRT19/imageSMR2-10-9.jpg)

C部長 : “あれ？ いままでのトライアルの結論は、「VLMでは外観検査ができない」ということではなかったですか？“

QEU:FOUNDER ： “そうですよ。小生は、外観検査の**次の作業**について、話しています。ちょっと、サンプルコードの一部を見てみましょう。推論に関するスニペットになります。”

```python
if False:
    from unsloth import FastVisionModel
    model, tokenizer = FastVisionModel.from_pretrained(
        model_name = "lora_model", # YOUR MODEL YOU USED FOR TRAINING
        load_in_4bit = True, # Set to False for 16bit LoRA
    )
    FastVisionModel.for_inference(model) # Enable for inference!

image = dataset[0]["image"]
instruction = "You are an expert radiographer. Describe accurately what you see in this image."

messages = [
    {"role": "user", "content": [
        {"type": "image"},
        {"type": "text", "text": instruction}
    ]}
]
input_text = tokenizer.apply_chat_template(messages, add_generation_prompt = True)
inputs = tokenizer(
    image,
    input_text,
    add_special_tokens = False,
    return_tensors = "pt",
).to("cuda")

from transformers import TextStreamer
text_streamer = TextStreamer(tokenizer, skip_prompt = True)
_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128,
                   use_cache = True, temperature = 1.5, min_p = 0.1)

```

QEU:FOUNDER ： “VLMでは、当然のことながら、画像情報(image)をそのまま入力しています。**この情報を「Embeddingベクトル」にしたい**んです。”

C部長 : “せっかく出力したEmbeddingをVLMへ！？Embeddingを出力した時点で外観検査が終わっているでしょう？”

QEU:FOUNDER ： “いや、Embedding出力だけでは外観検査の判定が終わっていませんよ。さらにいうと、**「VLMは我々が思っているよりも頭がいいから」**、そのEmbedding情報を読み込んで、かなり複雑な作業ができるようになるでしょう。”

C部長 : “より細かい不良の解析とか、修理方案の提案とか・・・。”

QEU:FOUNDER ： “そんなことができたらおもしろいでしょ？ただし、Unslothを含め、他のVLM用のインスタンスがEmbeddingベクトルの入力をサポートしているかどうかは、わからないです。もし、すでに出来ているのであれば、**ロボティックスが相当に進む**と思います。”

