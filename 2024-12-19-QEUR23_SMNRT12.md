---
title: QEUR23_SMNRT12 - TRIPLET距離に工夫をしてみた
date: 2024-12-19
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "NSOARTC", "データセット", "外観検査", "Vision language Model"]
excerpt: Siamese Networkをやってみる
---

## QEUR23_SMNRT12 - TRIPLET距離に工夫をしてみた

## ～ もっと、よくできないのか？ ～

### ・・・ 前回のつづきです ・・・

D先生 ： “次は、例によって外観検査への応用になるんですか？”

![imageSMR2-3-1](/2024-12-19-QEUR23_SMNRT12/imageSMR2-3-1.jpg)

QEU:FOUNDER ： “ちょっと考え中です。実は、本格的な外観検査に行く前にSiamese Neural Network(SNN)学習に使う距離をレベルアップしたいのです。さて、今回も前回と同じ資料を参考にします。ホント、いいですよ・・・。この記事（↓）は・・・。”

![imageSMR2-3-2](/2024-12-19-QEUR23_SMNRT12/imageSMR2-3-2.jpg)

QEU:FOUNDER ： “このトリプレットの距離を改善させたい。ちなみに、機械学習で一般的に使われる距離には**COSIN角度**と**ユーグリッド距離**の2種類があります。しかし、それらには、それぞれ一長一短があって、用途による選択の見極めが難しいのです。”

![imageSMR2-3-3](/2024-12-19-QEUR23_SMNRT12/imageSMR2-3-3.jpg)

D先生 ： “ほう・・・。例えば、どのような場合に見極めが必要ですか？”

QEU:FOUNDER ： “ここでいう距離とは、2つの矢印（ベクトル）を比較するためのメトリックです。この記事の場合（↑）には、２つの矢印の角度の差が小さく、ベクトルの長さが大きく異なるために「対象に大きな違いがある」とみなされます。つまり、COSIN類似度だけでは差異を把握できないのです。”

D先生 ： “いままで我々が使ってきたSNNの事例では、どちらの距離を使っていたんでしたっけ・・・。”

![imageSMR2-3-4](/2024-12-19-QEUR23_SMNRT12/imageSMR2-3-4.jpg)

QEU:FOUNDER ： “いままでのTRILETでは、COSIN角度を使っています。**角度は画像判別に対して、とても有効なメトリックスです**。しかし、画像の一部だけ異なる異常検出では、角度の有効性が失われるのです。まあ、細かいことはさておき、実例を見ればよくわかります。プログラムをドン！！改造があった、ほんの一部だけを晒しています。”

```python
# ---
# name of triplet array(FLATTEN)
name_triplet = 'triplets_fasion_MNIST_flatten.npy'
path_triplet = "drive/MyDrive/"+name_triplet
# ---
# 必要ならばtripletファイルをloadすること
triplets = np.load(path_triplet)
labels = np.ones(len(triplets)) #create a fixed label
#print(triplets[0,0,:])

# ---
# Split data into our train and test set
# データをトレーニングセットとテストセットに分割する
labels = np.ones(len(triplets)) #create a fixed label
X_train, X_test, y_train, y_test = train_test_split(
    triplets,
    labels,
    test_size=0.05,
    random_state=42
)

# ---
# Define the model
model = Sequential(
    [
        Input(shape=(image_size,)),
        Dense(512, activation="relu"),
        Dense(256, activation="relu"),
        Dense(128, activation=None),
    ]
)

# ---
# Model Training
# Initialize functions for Lambda Layer
# Lambdaレイヤーの関数を初期化する
@register_keras_serializable()
def cosine_distance(x,y):
    x = K.l2_normalize(x, axis=-1)
    y = K.l2_normalize(y, axis=-1)
    distance = 1 - K.batch_dot(x, y, axes=-1)
    return distance

# ---
# Register the custom function for serialization
@register_keras_serializable()
def euclidean_distance(x, y):
    """Compute the euclidean distance (norm) of the output of
    the twin networks.
    """
    return tf.sqrt(tf.reduce_sum(tf.square(x - y), axis=1, keepdims=True))

# ---
@register_keras_serializable()
def triplet_loss(templates, margin_cos=0.4, margin_euc=5):
    
    anchor,positive,negative = templates
    # ---
    # A:COSINE
    positive_distance_cos = cosine_distance(anchor,positive)
    negative_distance_cos = cosine_distance(anchor,negative)
    # ---
    # B:EUCLID
    positive_distance_euc = euclidean_distance(anchor,positive)
    negative_distance_euc = euclidean_distance(anchor,negative)
    # ---
    # COMBINE AxB
    basic_loss_cos = K.maximum(negative_distance_cos-positive_distance_cos+margin_cos,0.0)
    basic_loss_euc = K.maximum(negative_distance_euc-positive_distance_euc-margin_euc,0.0)
    loss = basic_loss_cos*0.8 + basic_loss_euc*0.02
    
    return loss

# ---
# Define inputs
anchor = Input(shape=(image_size,), name='anchor_input')
positive = Input(shape=(image_size,), name='positive_input')
negative = Input(shape=(image_size,), name='negative_input')
A,P,N = model(anchor),model(positive),model(negative)
# ---
# Compute distance using Lambda layer with output_shape specified
loss = Lambda(triplet_loss, output_shape=(1,))([A, P, N])
model = Model(inputs=[anchor,positive,negative],outputs=loss)

# ---
# Create a custom loss function since there are no ground truths label
# グラウンドトゥルースラベルがないのでカスタム損失関数を作成する
# Define loss function for serialization
@register_keras_serializable()
def identity_loss(y_true, y_pred):
    return K.mean(y_pred)

model.compile(loss=identity_loss, optimizer=Adam(learning_rate=3e-5))
callbacks=[EarlyStopping(
    patience=2, 
    verbose=1, 
    restore_best_weights=True,
    monitor='val_loss'
    )]

# view model
plot_model(model, show_shapes=True, show_layer_names=True, to_file='siamese_triplet_euclid_loss_model.png')

```

D先生 ： “・・・ん！？結果として、損失がレベルアップされましたね。驚いた・・・。”

![imageSMR2-3-5](/2024-12-19-QEUR23_SMNRT12/imageSMR2-3-5.jpg)

QEU:FOUNDER ： “学習の損失値が大きく減りましたね。それでは、おまちかねの正確度の改善を見てみましょう。”

![imageSMR2-3-6](/2024-12-19-QEUR23_SMNRT12/imageSMR2-3-6.jpg)

D先生 ： “またもや、前回と同じく**２％の正確度の改善**なんですね。そうしてみると、2%の改善というのはすごく大きいのですね。それにしても、今回は、どのようなトリックを使ったのですか？”

QEU:FOUNDER ： “解析用のプログラムをつくりました。その内容を見てみましょう。”

```python
# ---
# Import all libraries
import numpy as np
import math
import matplotlib.pyplot as plt

# ---
import keras
from keras.ops import norm
import tensorflow as tf
from tensorflow.keras import backend as K
from sklearn.model_selection import train_test_split

# ---
# IMAGE SIZE
image_size = 28*28

# ---
# name of triplet array(FLATTEN)
name_triplet = 'triplets_fasion_MNIST_flatten.npy'
path_triplet = name_triplet
# ---
# 必要ならばtripletファイルをloadすること
triplets = np.load(path_triplet)
labels = np.ones(len(triplets)) #create a fixed label
print(triplets[0,0,:20])

# ---
# Split data into our train and test set
# データをトレーニングセットとテストセットに分割する
labels = np.ones(len(triplets)) #create a fixed label
X_train, X_test, y_train, y_test = train_test_split(
    triplets,
    labels,
    test_size=0.05,
    random_state=42
)

# ---
# APN分解する
anchor = X_test[:,0,:]
positive = X_test[:,1,:]
negative = X_test[:,2,:]

###############################
# COS類似度とEUCLID距離を計算する
###############################
# ---
# COS類似度関数
def cosine_distance(x,y):
    x = K.l2_normalize(x, axis=-1)
    y = K.l2_normalize(y, axis=-1)
    distance = 1-K.batch_dot(x, y, axes=-1)
    return distance

# ---
# COS類似度(positive)
arr_cos_positive = cosine_distance(anchor,positive)
arr_cos_positive = arr_cos_positive.numpy()
print(arr_cos_positive[0:50])
# ---
# COS類似度(negative)
arr_cos_negative = cosine_distance(anchor,negative)
arr_cos_negative = arr_cos_negative.numpy()
print(arr_cos_negative[0:50])
# ---
# COS類似度(positive-negative)
arr_cos_similarity = arr_cos_negative.flatten() - arr_cos_positive.flatten()
print(arr_cos_similarity[0:50])

# ---
# ヒストグラムでプロット(COSINE)
# ---
plt.hist(arr_cos_similarity, bins=16)
plt.title("Distribution of cosine similarity")
plt.ylabel("frequency")
plt.xlabel("value")
plt.show()

# ---
# EUCLID類似度関数
def euclidean_distance(x, y):
    """Compute the euclidean distance (norm) of the output of
    the twin networks.
    """
    return tf.sqrt(tf.reduce_sum(tf.square(x - y), axis=1, keepdims=True))

# ---
# EUCLID類似度(positive)
arr_euc_positive = euclidean_distance(anchor,positive)
arr_euc_positive = np.array(arr_euc_positive)
#print(arr_euc_positive[0:20])
# ---
# EUCLID類似度(negative)
arr_euc_negative = euclidean_distance(anchor,negative)
arr_euc_negative = np.array(arr_euc_negative)
#print(arr_euc_negative[0:20])
# ---
# EUCLID類似度(positive-negative)
arr_euc_similarity = arr_euc_negative.flatten() - arr_euc_positive.flatten()
print(arr_euc_similarity[0:20])

# ---
# ヒストグラムでプロット(EUCLID)
# ---
plt.hist(arr_euc_similarity, bins=16)
plt.title("Distribution of euclid similarity")
plt.ylabel("frequency")
plt.xlabel("value")
plt.show()

```

QEU:FOUNDER ： “ここまでの結果をみてみましょう。２つのメトリックスのヒストグラムを比較してみましょう。”

![imageSMR2-3-7](/2024-12-19-QEUR23_SMNRT12/imageSMR2-3-7.jpg)

QEU:FOUNDER ： “ついでに、これら2つのメトリックスを散布図をにしてみましょう。”

![imageSMR2-3-8](/2024-12-19-QEUR23_SMNRT12/imageSMR2-3-8.jpg)

D先生 ： “角度の類似度と距離の類似度には、当然のことながら、ある程度の高い相関があります。ただし、２つのメトリックスの値はかなり違います。この差異は**係数を使って修正**しなければいけませんね。”

QEU:FOUNDER ： “あと、やはり2つのメトリックスには特性上に大きな違いがあります。COSIN類似度は0に近い（似ている）が、EUCLID類似度では値が大きい（似ていない）というケースも多いです。このような場合において、どのように値を補正したらいいのかを考えました。重要なことは、簡単な関数で行うということです。複雑な関数では、SNNの距離関数の中でエラーが起きる可能性が高いです。”

```python
###############################
# 合成メトリックス：タイプB
###############################
# ---
# マージンの設定
margin_cos = 0.4
margin_euc = 5.0

# ---
# COS類似度(positive-negative)
arr_cos_positive = cosine_distance(anchor,positive)
arr_cos_negative = cosine_distance(anchor,negative)
arr_cos_similarity = K.maximum(arr_cos_negative - arr_cos_positive + margin_cos,0.0)
#print(arr_cos_similarity[0:20])
# ---
# EUCLID類似度(positive-negative)
arr_euc_positive = euclidean_distance(anchor,positive)
arr_euc_negative = euclidean_distance(anchor,negative)
arr_euc_similarity = K.maximum(arr_euc_negative - arr_euc_positive - margin_euc,0.0)
#print(arr_euc_similarity[0:20])
# ---
# 合成した類似度
arr_similarity = arr_cos_similarity*0.8 + arr_euc_similarity*0.02
#print(arr_similarity[0:20])
arr_similarity = arr_similarity.numpy().flatten()
print(arr_similarity[0:20])


# ---
# ヒストグラムでプロット(合成メトリックス：タイプB)
# ---
plt.hist(arr_similarity, bins=16)
plt.title("Distribution of combined similarity(Type_B)")
plt.ylabel("frequency")
plt.xlabel("value")
plt.show()

```

D先生 ： “なるほどねえ・・・。しきい値を設定して、2つの対象が比較的似ている領域のユーグリッド値を強制的に0にしたのですね。”

QEU:FOUNDER ： “これは、しようがないのよ。今回の事例は判別問題なので、やはり角度を主役にしたかったから・・・。このようなノウハウが、先ほど例示した学習用のプログラムに反映されているわけです。”

D先生 ： “よくわかりました。もっとプログラムがうまい人が、自分のアイデアで改造してくれるとうれしいですね。”

QEU:FOUNDER ： “小生、Keras(tensorflow)のプログラムがヘタだから・・・。うまくやれば、正確度90%も夢ではないと思います。”



## ～ まとめ ～

### ・・・ 前回のつづきです ・・・

C部長 : “来年は大変な年になりそうです。”

[![MOVIE1](http://img.youtube.com/vi/tiMZCgpXuO4/0.jpg)](http://www.youtube.com/watch?v=tiMZCgpXuO4 "What's Coming Is WORSE Than A Recession - Richard Wolff's Last WARNING")

QEU:FOUNDER ： “**18か月は何もモノを買うな**だとさ・・・。株価もかなり動いているし、この年末は2008年の年末に似てきました。”

![imageSMR2-3-9](/2024-12-19-QEUR23_SMNRT12/imageSMR2-3-9.jpg)

QEU:FOUNDER ： “ただし、A国の場合には、株価はバタバタしても実体経済には影響は少ないかもね。ただし、J国の場合は少し違い、来る年は・・・。”

![imageSMR2-3-10](/2024-12-19-QEUR23_SMNRT12/imageSMR2-3-10.jpg)

C部長 : “J国は、**「あ～あ・・・。ダメダメ・・・。」がつづく**のでしょうね。”

QEU:FOUNDER ： “いやいや、わからんよ・・・。スゴイ人が、やっと本気を出してくれると思うし・・・。”

### おっさん（＠QCサークル講話）；「従業員の皆さんにはテレビを見てください。皆が同じように考えてください。」
### オッサン（＠車中、N社検査不正について）： 「“検査不正”っていうのはなァ、（組織外に不正を）漏らしたヤツが悪いんだよ・・・」
### オッサン（海外工場のあいさつにて）：「私の使命はこの会社で終身雇用制を実現することにある・・・。」

C部長 : “これまで、私たちはオッサンの本気をず～っと待っていました。ちょっと我慢の限界です！”

[![MOVIE2](http://img.youtube.com/vi/GohyOClBqu4/0.jpg)](http://www.youtube.com/watch?v=GohyOClBqu4 "【君たちには貧しくなる自由がある】【挑戦童貞を捨てよ！】竹中平蔵・経済？学者の発言。")

QEU:FOUNDER ： “君たちには貧しくなる自由がある・・・。小生は、彼らをいままで心から尊敬していました。「やればできるオッサン」だって・・・。もうすぐ、そこらへんの見方を変える必要があるかもね。せめて自分たちが壊してきた分だけでも、挽回して欲しいと思っていたのだが・・・。”
