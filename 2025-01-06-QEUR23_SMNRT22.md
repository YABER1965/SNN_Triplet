---
title: QEUR23_SMNRT22 : PyTorchとSNNモデルでEmbeddingを生成する(外観検査)
date: 2025-01-06
tags: ["QEUシステム", "メトリックス", "Python言語", "Unsloth", "NSOARTC", "データセット", "外観検査", "Vision language Model"]
excerpt: Siamese Networkをやってみる
---

## QEUR23_SMNRT22 : PyTorchとSNNモデルでEmbeddingを生成する(外観検査)

## ～ やはり、SiameseNNは良い方法だ！ ～

QEU:FOUNDER ： “前回は、シンプルなモデルを高次元Embedding(128)に改造することで、予測精度が向上しました。じゃあ、やっと外観検査用のSiamese Neural Network（SNN）の開発にはいりましょう。あっ、PyTorchで作ったシステムですよ。Kerasで組み立てたシステムは、すでに開発済みです。”

![imageSMR2-13-1](/2025-01-06-QEUR23_SMNRT22/imageSMR2-13-1.jpg)

D先生 ： “よっしゃぁ・・・！！今回は、前回とプログラムがほとんど変わらないですよね。”

QEU:FOUNDER ： “NO・・・。**モデルの形態がSiamese(ヘッドが２つ)になるので、それに伴っていろいろ変わっています。**それでも、ごく最初のデータの読み込みと出力の解析はほとんど同じです。ここでは、大きな変更がある部分だけを晒してみましょう。ドン！！”

```python
##########################################
# DATASETS: SIAMESE MNIST
##########################################
from PIL import Image
from torch.utils.data import Dataset
from torch.utils.data.sampler import BatchSampler

# ---
class SiameseMNIST_train(Dataset):
    """
    Train: For each sample creates randomly a positive or a negative pair
    Test: Creates fixed pairs for testing
    """
    def __init__(self, mnist_dataset, max_dataset, transform=None):
        self.train_labels = mnist_dataset["label"]
        self.train_data = mnist_dataset["image"]
        self.transform = transform
        # ---
        set_label = list(set(self.train_labels))
        self.len_label = len(set_label)
        print("len_label: ", self.len_label)
        # ---
        self.max_dataset = max_dataset
        self.arr_idx_image1 = []
        self.arr_idx_image2 = []
        self.arr_target = []
        for i in range(self.max_dataset):
            idx_image1 = np.random.randint(self.len_label)
            idx_image2 = np.random.randint(self.len_label)
            # ---
            label_image1 = self.train_labels[idx_image1]
            label_image2 = self.train_labels[idx_image2]
            if label_image1 == label_image2:
                target = 1
            else:
                target = 0
            # ---
            self.arr_idx_image1.append(idx_image1)
            self.arr_idx_image2.append(idx_image2)
            self.arr_target.append(target)
            
    def __getitem__(self, index):
        img1 = self.train_data[self.arr_idx_image1[index]]
        img2 = self.train_data[self.arr_idx_image2[index]]
        target = self.arr_target[index]
        x = (img1, img2)
        # ---
        if self.transform:
            img1 = self.transform(img1)
            img2 = self.transform(img2)
            x = (img1, img2)
            
        return x, target

    def __len__(self):
        return self.max_dataset

# ---
# Set up data loaders
torch_dataset = SiameseMNIST_train(transformed_dataset, 70000) # Returns pairs of images and target same/different

# ---
from sklearn.model_selection import train_test_split

siamese_train_dataset, siamese_test_dataset = train_test_split(torch_dataset, test_size=0.3)

####################
# SIAMESEにまとめられた画像を出力する
####################
# ---
# plot triplets array to visualize
TEST_SIZE = 5
#random_indices = np.random.randint(siamese_train_dataset)

fig = plt.figure(figsize=[6*TEST_SIZE, 15])
plt.title('  IMAGE1  |  IMAGE2  ',fontsize = 20)
plt.suptitle(f"Data Visualization(1-{TEST_SIZE})",fontsize = 20)
plt.axis('off')
for i in range(TEST_SIZE):
    # ---
    fig.add_subplot(TEST_SIZE, 2, 2*i+1)
    random_index = np.random.randint(len(siamese_train_dataset))
    image1 = siamese_train_dataset[random_index][0][0].squeeze()
    label = siamese_train_dataset[random_index][1]
    plt.title(f'Label: {label}')
    plt.imshow(image1)
    # ---
    fig.add_subplot(TEST_SIZE, 2, 2*i+2)
    image2 = siamese_train_dataset[random_index][0][1].squeeze()
    plt.imshow(image2)
# ---
# ヒートマップを表示
plt.tight_layout()
plt.show()

```

QEU:FOUNDER ： “これで、SNNに入力するためのイメージのペアが生成されます。”

![imageSMR2-13-2](/2025-01-06-QEUR23_SMNRT22/imageSMR2-13-2.jpg)

QEU:FOUNDER ： “このように、入力データが生成できたので次にいきましょう。プログラムは、さらにつづきます。”

```python
#############################################
# DATA LOADER
#############################################
# ---
cuda = torch.cuda.is_available()
batch_size = 128
kwargs = {'num_workers': 1, 'pin_memory': True} if cuda else {}
siamese_train_loader = torch.utils.data.DataLoader(siamese_train_dataset, batch_size=batch_size, shuffle=True, **kwargs)
siamese_test_loader = torch.utils.data.DataLoader(siamese_test_dataset, batch_size=batch_size, shuffle=False, **kwargs)

##################################
# NETWORKS FUNCTIONS
##################################
# ---
# https://www.kaggle.com/code/faduregis/mnist-digit-classification-in-pytorch
# build model
class EmbeddingNet(nn.Module):
    def __init__(self):
        super(EmbeddingNet,self).__init__()
        self.linear1 = nn.Linear(36*39, 512) # 36 * 39 is the pixels for each image
        self.linear2 = nn.Linear(512, 256) #100 and 5o
        self.linear3 = nn.Linear(256, 256) #100 and 5o
        self.final = nn.Linear(256, 128)
        self.relu = nn.ReLU()
# Here we are just feeding the data into each layer, and returning the output, while defining an in-stance of this class.
# ここでは、このクラスのインスタンスを定義しながら、各レイヤーにデータを入力し、出力を返すだけです。
    def forward(self, img): #convert + flatten
        x = img.view(-1, 36*39)
        x = self.relu(self.linear1(x))
        x = self.relu(self.linear2(x))
        x = self.relu(self.linear3(x))
        x = self.final(x)
        return x

    def get_embedding(self, x):
        return self.forward(x)

class SiameseNet(nn.Module):
    def __init__(self, embedding_net):
        super(SiameseNet, self).__init__()
        self.embedding_net = embedding_net

    def forward(self, x1, x2):
        output1 = self.embedding_net(x1)
        output2 = self.embedding_net(x2)
        return output1, output2

    def get_embedding(self, x):
        return self.embedding_net(x)

##################################
# METRICS FUNCTIONS
##################################
# ---
class Metric:
    def __init__(self):
        pass

    # ---
	# 省略

##################################
# TRAIN - FIT FUNCTIONS
##################################
# ---
def train_epoch(train_loader, model, loss_fn, optimizer, cuda, log_interval, metrics):
    for metric in metrics:
        metric.reset()

    # ---
	# 省略

# ---
def test_epoch(val_loader, model, loss_fn, cuda, metrics):
    with torch.no_grad():
    # ---
	# 省略
	
# ---
def fit(train_loader, val_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval, metrics=[],
        start_epoch=0):
    for epoch in range(0, start_epoch):
        scheduler.step()

    # ---
	# 省略
	
# ---
##########################################
# LOSS FUNCTIONS
##########################################
# ---
class ContrastiveLoss(nn.Module):
    """
    Contrastive loss
    Takes embeddings of two samples and a target label == 1 if samples are from the same class and label == 0 otherwise
    2つのサンプルの埋め込みと、サンプルが同じクラスからのものである場合はターゲットラベル == 1、そうでない場合はラベル == 0 を取得します。
    """
    def __init__(self, margin):
        super(ContrastiveLoss, self).__init__()
        self.margin = margin
        self.eps = 1e-9

    def forward(self, output1, output2, target, size_average=True):
        distances = (output2 - output1).pow(2).sum(1)  # squared distances
        losses = 0.5 * (target.float() * distances +
                        (1 + -1 * target).float() * F.relu(self.margin - (distances + self.eps).sqrt()).pow(2))
        return losses.mean() if size_average else losses.sum()

################################
# PARAMETER SETTING
################################
# ---
# Set up the network and training parameters
# ---
margin = 1.
embedding_net = EmbeddingNet()
model = SiameseNet(embedding_net)
cuda = torch.cuda.is_available()
if cuda:
    model.cuda()
loss_fn = ContrastiveLoss(margin)
lr = 5e-4
optimizer = optim.Adam(model.parameters(), lr=lr)
scheduler = lr_scheduler.StepLR(optimizer, 8, gamma=0.1, last_epoch=-1)
n_epochs = 30
log_interval = 100

##############################
# TRAINING RUN (SIAMESE)
##############################
# ---
arr_training_loss, arr_validation_loss = fit(siamese_train_loader, siamese_test_loader, model, loss_fn, optimizer, scheduler, n_epochs, cuda, log_interval)

# ---
def plot_loss(arr_training_loss, arr_validation_loss):
    # ---
    x = list(range(len(arr_training_loss)))
    # ---
    plt.figure(figsize=(10,6))
    plt.title("TRANING AND VALIDATION LOSS TREND",fontsize = 14)
    plt.plot(x, arr_training_loss, marker="o", label="train")
    plt.plot(x, arr_validation_loss, marker="o", label="validation")
    plt.xlabel('epoch')
    plt.ylabel('loss')
    plt.legend(loc='upper center',fontsize = 11)
    plt.show()
# ---
plot_loss(arr_training_loss, arr_validation_loss)

```

D先生 ： “今回は、わかりやすくするように、学習損失をグラフ化しました。これで、うまく学習が進んでいる様子が見えます。実際には、20エポック程度の反復で十分かもしれません。”

![imageSMR2-13-3](/2025-01-06-QEUR23_SMNRT22/imageSMR2-13-3.jpg)

QEU:FOUNDER ： “Embeddingベクトルの次元数を128にまで増やしているから、損失の減少トレンドもスムーズだね。さて、ここで学習したモデルの予測結果をみてみましょう。”

D先生 ： “おっと、混同マトリックス(Confusion Matrix)での評価ですね。”

QEU:FOUNDER ： “それは、あとで・・・。SNNでは、Simpleモデルのような直接の予測評価は難しいので、ここではEmbeddingの散布図だけを見てみましょう。もちろん、PCA(主成分分析)で情報を集約をしています。プログラムは前回を参照、散布図の結果だけドン！！”

**（今回の結果: Siamese-128）**

![imageSMR2-13-4](/2025-01-06-QEUR23_SMNRT22/imageSMR2-13-4.jpg)

D先生 ： “分布に重複が少なく、とても良い予測パフォーマンスが期待できますね。SNNでの誤判別は少なくなるでしょう。”

**（前回の結果: Simple-128）**

![imageSMR2-13-5](/2025-01-06-QEUR23_SMNRT22/imageSMR2-13-5.jpg)

QEU:FOUNDER ： “次回は、Embeddingを活用した予測です。Confusion Matrixを生成しましょう。”

D先生 ： “定量的な性能評価が必要ですね。”


## ～ まとめ ～

## ・・・ 前回のつづきです ・・・

QEU:FOUNDER ： “いやいや・・・、立派な御仁のご意見をありがたく拝聴しました。**「とにかく働け」というメッセージだけ**をいただきました・・・（笑）。”

[![MOVIE1](http://img.youtube.com/vi/SNVc0of_gmg/0.jpg)](http://www.youtube.com/watch?v=SNVc0of_gmg "2025年超予測（前編）】混乱が当たり前に／20、30％の賃上げも／トランプ関税は杞憂／TOBが広がる／1ドル200円の時代")

C部長 : “ほう・・・。200円/ドルに行く原因が**「国力の低下」**ですか・・・。この人の意見を政治に発信すれば、もっと早く、なんとかできたんじゃない？その国力の低下を防ぐために・・・。”

![imageSMR2-13-6](/2025-01-06-QEUR23_SMNRT22/imageSMR2-13-6.jpg)

QEU:FOUNDER ： “まあね。**そんな能力がないから、いまごろになって若い人に対して「とにかく働け」と喚くしかない**んでしょうに・・・（笑）。もちろん、この為替の予測は、十分にありうると思いますよ。世界のバランスが変わるのが九運だから・・・。さてと・・・、これ（↓）を見てみて・・・。”

![imageSMR2-13-7](/2025-01-06-QEUR23_SMNRT22/imageSMR2-13-7.jpg)

QEU:FOUNDER ： “これは、さっき挙げたグラフと表裏の関係になります。地域的な格差は、すでにわかっているとして、もう一つ思いついたことはないかい・・・？”

C部長 : “資源系の産業に属するメガ企業って、世界的にも少ないんですね。あっても、それらが石油関連だけなのか・・・。必要な資源って、世の中に数多くあるのに不思議ですよねえ。 “

![imageSMR2-13-8](/2025-01-06-QEUR23_SMNRT22/imageSMR2-13-8.jpg)

QEU:FOUNDER ： “リチウムなんかは最近は重要になっているよね。「それらの資源が、なぜ資源国の主要産業の成長に寄与していないのか」という理由は、タダひとつ・・・。いままで、**（どこかの国から）徹底的に搾取されていたから・・・**。それが、これから少しづつ変わってくると思います。”

![imageSMR2-13-9](/2025-01-06-QEUR23_SMNRT22/imageSMR2-13-9.jpg)

C部長 : “将来的に、資源国には、その資源を活用するための大きな会社があるのは当たり前ですよね。そうすると、世の中の物価がいろいろ上がってくるでしょうね。 “

QEU:FOUNDER ： “今後、あらゆる物価は、どんどん上がってくると思います。もっとスゴイ予言をしようか？このC部長が大好きな件（↓）なんだけど・・・。”

![imageSMR2-13-10](/2025-01-06-QEUR23_SMNRT22/imageSMR2-13-10.jpg)

C部長 : “ボクは、ひそかに**「トンデモのファン」**です。う～ん、1999年の件は、惜しかった・・・（笑）。FOUNDER・・・。知らなかったんですが、法王に関する予言もあるんですか？これを見ると、法王が黒人になるのかな？“

![imageSMR2-13-11](/2025-01-06-QEUR23_SMNRT22/imageSMR2-13-11.jpg)

QEU:FOUNDER ： “（黒人がローマ法王になって）何の問題がある！？すでにラテンアメリカの人が法王になったよね。さらに、アフリカ大陸は、クリスチャンの巨大マーケットです。政治力と経済力を持った彼らが反乱を起こすと、たかがバチカンなんか、すぐに**「ペシャンコ」**になりますよ。そもそも、あの宗教の起源はどこなのよ？”

![imageSMR2-13-12](/2025-01-06-QEUR23_SMNRT22/imageSMR2-13-12.jpg)

C部長 : “そう考えてみれば、彼の予言が成就することが当たり前です。 “

QEU:FOUNDER ： “結局、**ノストラダムスって16世紀のF国人なので白人だけの世界しか知らない**のです。だから、ある日、黒人が法王になる夢を見たのでパニックを起こしたのだろうって・・・。ただし、彼が見た夢は正夢だろうって・・・。”

![imageSMR2-13-13](/2025-01-06-QEUR23_SMNRT22/imageSMR2-13-13.jpg)

QEU:FOUNDER ： “こういうことを、雑誌「ム―」に投稿したいのだがダメかな？”

C部長 : “ボツです・・・。捻りがまだ足りません。 “
