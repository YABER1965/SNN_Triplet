---
title: QEUR23_SMNRT41 â€“ PyTorchã§Tripletã‚’ã‚„ã£ã¦ã¿ã‚‹(MNIST-ãã®2)
date: 2025-01-13
tags: ["QEUã‚·ã‚¹ãƒ†ãƒ ", "ãƒ¡ãƒˆãƒªãƒƒã‚¯ã‚¹", "Pythonè¨€èª", "Unsloth", "NSOARTC", "ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ", "å¤–è¦³æ¤œæŸ»", "Vision language Model"]
excerpt: Siamese Networkã‚’ã‚„ã£ã¦ã¿ã‚‹
---

## QEUR23_SMNRT41 â€“ PyTorchã§Tripletã‚’ã‚„ã£ã¦ã¿ã‚‹(MNIST-ãã®2)

## ï½ TRIPLETã¯ã€ã•ã™ãŒã®é«˜ç²¾åº¦ï¼ï¼ ï½

QEU:FOUNDER ï¼š â€œå‰å›ã«ã²ãã¤ã¥ã„ã¦ã€MNISTãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã£ãŸç”»åƒåˆ¤åˆ¥ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã§ã™ã€‚ä»Šå›ã¯Embeddingã‚’ä½¿ã£ã¦äºˆæ¸¬ã—ã¾ã™ã€‚ã‚‚ã†ã€å‰ç½®ãã¯ã„ã‚‰ãªã„ã§ã™ã€‚ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’ãƒ‰ãƒ³ï¼ï¼åºç›¤ã®ã‚³ãƒ¼ãƒ‰ã¯é‡è¤‡ã™ã‚‹ã®ã§ã‚¹ã‚­ãƒƒãƒ—ã§ã™ã€‚â€

```python
# ---
################################
# draw_images (SINGLE)
################################
# ---
# ã„ãã¤ã‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¦ã€è¡¨ç¤ºã™ã‚‹
def draw_images(dataset):
    # ---
    fig = plt.figure(figsize=[8,10])
    plt.suptitle("Data Visualization(1-4)")
    for i in range(4):
        str_label = dataset[i][1]
        # ---
        fig.add_subplot(2, 2, i+1)
        plt.title(f"LABEL:{str_label}",fontsize = 11)
        plt.imshow(torch.squeeze(dataset[i][0]), cmap='hot', interpolation='nearest')
        plt.tight_layout()
        plt.axis('off')       
    # ---
    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’è¡¨ç¤º
    plt.tight_layout()
    plt.show()

# ---
# ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã—ã¦ã€ã‚°ãƒ©ãƒ•ã«ã™ã‚‹
draw_images(test_dataset)

```

QEU:FOUNDER ï¼š â€œç‰¹ã«ã„ã†ã“ã¨ã¯ç„¡ã„ã§ã™ã€‚YLCã®ãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚ä»¥ä¸Šï¼â€

![imageSMR2-41-1](/2025-01-13-QEUR23_SMNRT27/imageSMR2-41-1.jpg)

Då…ˆç”Ÿ ï¼š â€œãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®ç´¹ä»‹ã‚’ã¤ã¥ã‘ã¾ã—ã‚‡ã†ã€‚ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯ã€EmbeddingãŒ128æ¬¡å…ƒã«ãªã‚‹ãƒ¢ãƒ‡ãƒ«ã§ã™ã€‚æ¬¡ã¯ã€SNNã«ã‚ˆã‚‹å€‹åˆ¥äºˆæ¸¬ã‚’ã‚„ã£ã¦ã¿ã¾ã™ã€‚â€

```python
# ---
# Install and import required dependencies
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset, Subset
# ---
import math
import time
# ---
##################################
# NETWORKS FUNCTIONS (TRIPLET)
##################################
# ---
# build model
class EmbeddingNet(nn.Module):
    def __init__(self):
        super(EmbeddingNet,self).__init__()
        self.linear1 = nn.Linear(28*28, 256) #28 * 28 is the pixels for each image
        self.linear2 = nn.Linear(256, 256) #100 and 5o
        self.final = nn.Linear(256, 128)
        self.relu = nn.ReLU()
# ã“ã“ã§ã¯ã€ã“ã®ã‚¯ãƒ©ã‚¹ã®ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’å®šç¾©ã—ãªãŒã‚‰ã€å„ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«ãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›ã—ã€å‡ºåŠ›ã‚’è¿”ã™ã ã‘ã§ã™ã€‚
    def forward(self, img): #convert + flatten
        x = img.view(-1, 28*28)
        x = self.relu(self.linear1(x))
        x = self.relu(self.linear2(x))
        x = self.final(x)
        return x

    def get_embedding(self, x):
        return self.forward(x)

class TripletNet(nn.Module):
    def __init__(self, embedding_net):
        super(TripletNet, self).__init__()
        self.embedding_net = embedding_net

    def forward(self, x1, x2, x3):
        output1 = self.embedding_net(x1)
        output2 = self.embedding_net(x2)
        output3 = self.embedding_net(x3)
        return output1, output2, output3

    def get_embedding(self, x):
        return self.embedding_net(x)

################################
# MODEL INSTANCE SETTING
################################
# ---
# Set up the network and training parameters
# ---
embedding_net = EmbeddingNet()
model = TripletNet(embedding_net)
cuda = torch.cuda.is_available()
if cuda:
    model.cuda()

# ----
# ãƒ¢ãƒ‡ãƒ«å®šç¾©ãŒå¿…è¦
model.load_state_dict(torch.load('drive/MyDrive/siamese_mnist_triplet128_model.pth'))
model.eval()

# ---
#TripletNet(
#  (embedding_net): EmbeddingNet(
#    (linear1): Linear(in_features=784, out_features=256, bias=True)
#    (linear2): Linear(in_features=256, out_features=256, bias=True)
#    (final): Linear(in_features=256, out_features=128, bias=True)
#    (relu): ReLU()
#  )
#)

#########################################
# ANCHORã®ãƒ™ã‚¯ãƒˆãƒ«ç¾¤ã‚’ç”Ÿæˆã™ã‚‹
# TARGET = ä»¥ä¸‹ã®ãƒ©ãƒ™ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ç¾¤ã®å¹³å‡å€¤ãƒ™ã‚¯ãƒˆãƒ«ã¨ãªã‚‹
#########################################
# ---
def create_anchors(dataset, TARGET):
    # ---
    # æ¡ä»¶ã‚’ã‚‚ã¨ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    cut_dataset = []
    for i, example in enumerate(dataset):
        if example[1] == TARGET:
            cut_dataset.append(example[0])
    
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒç©ºã§ãªã„ã“ã¨ã‚’ç¢ºèª
    if not cut_dataset:
        raise ValueError(f"No examples found for target {TARGET}")

    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç¢ºèª
    cut_image = torch.stack([example[0] for example in cut_dataset])
    print("cut_image", cut_image.shape)
    #cut_image torch.Size([980, 28, 28])
    
    # anchorã‚’ç”Ÿæˆã™ã‚‹
    anchor_X = torch.zeros([cut_image.shape[1], cut_image.shape[2]])
    for i in range(cut_image.shape[1]):
        for j in range(cut_image.shape[2]):
            anchor_X[i, j] = torch.mean(cut_image[:, i, j])

    return cut_image.shape[0], anchor_X

# ---
# å¹³å‡ç”»åƒã‚’å¤‰æ•°ã«ä¿ç®¡ã™ã‚‹
anchor_Xs = []
arr_Xnum  = [] 
for TARGET in range(n_classes):
    num_Xs, mx_anchor = create_anchors(test_dataset, TARGET)
    anchor_Xs.append(mx_anchor)
    arr_Xnum.append(num_Xs)

################################
# anchor_embeddingãƒ™ã‚¯ãƒˆãƒ«ã‚’ç”Ÿæˆã™ã‚‹
################################
# ---
anchor_embedding = np.zeros([n_classes, 128])
for i in range(n_classes):
    # ---
    cut_anchor = anchor_Xs[i]
    tensor_x = torch.unsqueeze(cut_anchor,1)
    #print(tensor_x)
    # ---
    anchor_embedding[i, :] = model.get_embedding(tensor_x.cuda()).data.cpu().numpy()
# ---
print(anchor_embedding.shape)

# ---
from scipy.spatial import distance

################################
# ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã‚’è¨ˆç®—ã™ã‚‹(1.å€‹åˆ¥)
################################
# ---
# ã²ã¨ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã™ã‚‹
def individual_process(i, dataset, anchor_embedding, anchor_Xs):
    # ---
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç¢ºèª
    sample_image = dataset[i][0]
    sample_index = dataset[i][1]
    #print(sample_index)
    # ---
    arr_dist = []
    for j in range(n_classes):
        anchor_image = anchor_Xs[j]
        tensor_x = torch.unsqueeze(sample_image,1)
        # ---
        sample_embedding = model.get_embedding(tensor_x.cuda()).data.cpu().numpy()
        #print(sample_embedding.flatten())
        # ---
        val_dist = distance.euclidean(anchor_embedding[j], sample_embedding.flatten())
        arr_dist.append(round(val_dist,5))
        print(f"j: {j}, Distance: {val_dist}")
    # ---
    print("--- ACTUAL DATA, Distance ---")
    print(f"iCount: {i}, arr_dist: {arr_dist}")
    print("--- MIN_INDEX ---")
    index = np.argmin(arr_dist)
    anchor_image = anchor_Xs[index]
    pred_label = index      # set_label[index]
    #print(f"INDEX: {index}, LABEL: {pred_label}")
    # ---
    fig = plt.figure(figsize=[10,5])
    plt.suptitle(f"    ANCHOR    |    MEASUREMENT   |   LABEL: {pred_label}",fontsize = 15)
    # ---
    # ANCHOR
    fig.add_subplot(1, 2, 1)
    plt.imshow(anchor_image, cmap='hot', interpolation='nearest')
    plt.axis('off')
    # ---
    # SAMPlE
    fig.add_subplot(1, 2, 2)
    plt.imshow(sample_image.squeeze() , cmap='hot', interpolation='nearest')
    plt.axis('off')
    # ---
    # ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã‚’è¡¨ç¤º
    plt.tight_layout()   
    plt.show()

# ---
# ã²ã¨ã¤ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã™ã‚‹
i = 550
individual_process(i, test_dataset, anchor_embedding, anchor_Xs)

```

QEU:FOUNDER ï¼š â€œå½“ãŸã‚Šå‰ã ãŒã€æ­£è§£ãŒå‡ºã¦ã„ã¾ã™ï¼ï¼â€

![imageSMR2-41-2](/2025-01-13-QEUR23_SMNRT27/imageSMR2-41-2.jpg)

Då…ˆç”Ÿ ï¼š â€œã“ã®å‡ºåŠ›ã‚’è¦‹ã‚‹ã¨ã€ã©ã®ã‚ˆã†ã«äºˆæ¸¬ãŒè¡Œã‚ã‚Œã‚‹ã®ã‹ãŒã‚ã‹ã‚Šã¾ã™ã€‚ãã†ã§ã—ã‚‡ï¼Ÿâ€

QEU:FOUNDER ï¼š â€œãã®é€šã‚Šã€‚ãƒ™ã‚¯ãƒˆãƒ«è¦ç´ ã®æœ€å°ã‚¤ãƒ³ãƒ‡ã‚£ãƒƒã‚¯ã‚¹ãŒäºˆæ¸¬å€¤ã§ã™ã€‚ã•ã¦ã€ï¼ˆãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®æ™’ã—ã‚’ï¼‰ç¶šã‘ã¾ã—ã‚‡ã†ã€‚â€

```python
################################
# ãƒ¦ãƒ¼ã‚¯ãƒªãƒƒãƒ‰è·é›¢ã‚’è¨ˆç®—ã™ã‚‹(2.ãƒãƒƒãƒ)
################################
# ---
# ãƒãƒƒãƒãƒ»ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã™ã‚‹
def batch_process(i, dataset, anchor_embedding):
    # ---
    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç¢ºèª
    sample_image = dataset[i][0]
    sample_index = dataset[i][1]
    #print(sample_index)
    # ---
    arr_dist = []
    for j in range(n_classes):
        anchor_image = anchor_Xs[j]
        tensor_x = torch.unsqueeze(sample_image,1)
        # ---
        sample_embedding = model.get_embedding(tensor_x.cuda()).data.cpu().numpy()
        #print(sample_embedding.flatten())
        # ---
        val_dist = distance.euclidean(anchor_embedding[j], sample_embedding.flatten())
        arr_dist.append(round(val_dist,5))
        #print(f"j: {j}, Distance: {val_dist}")
    # ---
    #print("--- ACTUAL DATA, Distance ---")
    #print(f"iCount: {i}, arr_dist: {arr_dist}")
    index = np.argmin(arr_dist)
    anchor_image = anchor_Xs[index]
    pred_label = index  # set_label[index]
    #print(f"i: {i}, INDEX: {index}, LABEL: {pred_label}")

    return pred_label, sample_index

# ---
# ãƒãƒƒãƒãƒ»ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºã™ã‚‹ã‚’æŠ½å‡ºã™ã‚‹
arr_pred = []
arr_actual = []
for i in range(1000):
    pred_y, actual_y = batch_process(i, test_dataset, anchor_embedding)
    #print(f"i: {i}, pred: {pred_y}, actual: {actual_y}")
    arr_pred.append(pred_y)
    arr_actual.append(actual_y)

################################
# CREATING CONFUSION MATRIX
################################
# ---
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay

# æ··åŒè¡Œåˆ—ã®ç”Ÿæˆ
cm = confusion_matrix(arr_actual, arr_pred)

# Confusion matrixã®è¡¨ç¤º
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap=plt.cm.Blues)

# Xè»¸ãƒ©ãƒ™ãƒ«ã€Yè»¸ãƒ©ãƒ™ãƒ«ã€ã‚¿ã‚¤ãƒˆãƒ«ã®è¿½åŠ 
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')

# Confusion matrixã®è¡¨ç¤º
plt.show()

```

QEU:FOUNDER ï¼š â€œã‚‚ã¡ã‚ã‚“ã€Confusion Matrixã§ã®è©•ä¾¡çµæœã¯VERY GOODã§ã™ã€‚â€

![imageSMR2-41-3](/2025-01-13-QEUR23_SMNRT27/imageSMR2-41-3.jpg)

Då…ˆç”Ÿ ï¼š â€œTRIPLETã®ãƒ‘ãƒ¯ãƒ¼ã¯ã•ã™ãŒã§ã™ã€‚ä»Šå›ã®ã‚·ã‚¹ãƒ†ãƒ ã¯ã€å¹³å‡ç”»åƒã‚’ANCHORã«ãªã‚‹ã‚ˆã†ã«ãªã£ã¦ã„ã‚‹ã‚“ã§ã™ã‚ˆã­ï¼Ÿâ€

QEU:FOUNDER ï¼š â€œã¯ã£ãã‚Šã„ã£ã¦ã€ANCHORãŒå¹³å‡ç”»åƒã˜ã‚ƒãªã„ã¨ã€ŒTRIPLETã®ã‚ã‚ŠãŒãŸã¿ã€ã¯ã€ãªã„ã§ã™ã€‚ãã‚Œã§ã¯ã€æ¬¡ã¯å¤–è¦³æ¤œæŸ»ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ã£ãŸäº‹ä¾‹ã‚’ã‚„ã£ã¦ã„ãã¾ã—ã‚‡ã†ã€‚â€


## ï½ ã¾ã¨ã‚ ï½

QEU:FOUNDER ï¼š â€œã•ã„ãã‚“ã€ã“ã‚Œï¼ˆâ†“ï¼‰ãŒè©±é¡Œã«ãªã£ã¦ã„ã¾ã™ã€‚ã¾ã‚ã€ã“ã‚Œã¯ã€ã€Œã‚ã‚ŠãŒã¡ã€ã‹ãªã¨ãƒ»ãƒ»ãƒ»ã€‚**Jå›½ã®è»¢æ›ç‚¹**ã¨ã‚‚è¨€ãˆã¾ã™ã€‚çš†ã•ã‚“ã€æ°—ã¥ã„ã¦ã„ã‚‹ã‹ãªï¼Ÿâ€

![imageSMR2-41-4](/2025-01-13-QEUR23_SMNRT27/imageSMR2-41-4.jpg)

Céƒ¨é•· : â€œã‚¿ã‚¤ãƒˆãƒ«ã¯ã€**ã€Œçª®ã™ã‚Œã°éˆã™ã‚‹ã€**ã§ã™ã‹ãƒ»ãƒ»ãƒ»ã€‚ â€œ

QEU:FOUNDER ï¼š â€œæ˜”ã¯ã€ã€Œï¼ˆJå›½ã®è¾²ç”£ç‰©ã¯ï¼‰å®‰å…¨ã€å®‰å¿ƒã€ãŠã„ã—ã„ã€ã¨è¨€ã‚ã‚Œã¦ã„ãŸã‚“ã§ã™ã‚ˆã­ã€‚æã‚‰ãã€ã™ã§ã«Jå›½ã®è¾²å®¶ã«ã¯ä½™è£•ãŒãªããªã£ã¦ãã¦ã„ã‚‹ã‚“ã§ã—ã‚‡ã†ã€‚**è¿‘å¹´ã®è¾²æ”¿ã®æ•—åŒ—ã®è±¡å¾´ãŒã‚­ãƒ£ãƒ™ãƒ„ï¼ˆâ†“ï¼‰ã®ä¾¡æ ¼é«˜é¨°**ã§ã—ã‚‡ã†ã€‚â€

![imageSMR2-41-5](/2025-01-13-QEUR23_SMNRT27/imageSMR2-41-5.jpg)

Céƒ¨é•· : â€œã‚­ãƒ£ãƒ™ãƒ„ã¯ã€**ã€Œï¼ˆå¤–å›½äººï¼‰å®Ÿç¿’ç”Ÿé ¼ã¿ã€ã®å…¸å‹**ã§ã—ãŸã‚ˆã­ã€‚å††å®‰ãŒã“ã“ã¾ã§é€²ã‚€ã¨ã€è¾²ä½œç‰©ã®å€¤æ®µãŒã‚ãŒã‚‹ã®ã¯ã‚ãŸã‚Šã¾ãˆã§ã™ã€‚ â€œ

![imageSMR2-41-6](/2025-01-13-QEUR23_SMNRT27/imageSMR2-41-6.jpg)

QEU:FOUNDER ï¼š â€œ1990å¹´ä»£å¾ŒåŠã€è²´ã„ã‚¨ã‚ºæ§˜ãŒã€è‹¦åŠ´ã—ã¦è‹¦åŠ´ã—ã¦è²´ã„æœ¬ã‚’ç™ºè¡Œã—ã€**æœ¬æ¥ã¯ã€Œãƒ¢ãƒã¥ãã‚ŠãŒå¼·ã¿ã®Jå›½ã€ã‚’ã€Œã‚¤ãƒ³ãƒã‚¦ãƒ³ãƒ‰ã ã‘ãŒé ¼ã¿ã®Jå›½ã€ã«å¤‰ãˆã¦ãã‚Œã¾ã—ãŸ**ã€‚ãã®ã‚¨ã‚ºæ§˜ã«ã¯ç”³ã—è¨³ãªã„ãŒã€**ã“ã®ã‚¤ãƒ³ãƒã‚¦ãƒ³ãƒ‰ç†±ã¯ãã‚Œã»ã©é•·ãç¶šã‹ãªã„**ã¨æ€ã„ã¾ã™ã€‚â€

[![MOVIE1](http://img.youtube.com/vi/Zmv9wCmN0cs/0.jpg)](http://www.youtube.com/watch?v=Zmv9wCmN0cs "å‚é™¢é¸ã®ä¸å…šè‹¦æˆ¦ã¨æ ªä¾¡ï¼ä¸­å›½ã‚¤ãƒ³ãƒã‚¦ãƒ³ãƒ‰ã®å®Œå…¨å›å¾©ï¼å›£å¡Šã®ä¸–ä»£å…¨å“¡ãŒå¾ŒæœŸé«˜é½¢è€…ã¸")

Céƒ¨é•· : â€œã‚¤ãƒ³ãƒã‚¦ãƒ³ãƒˆã¯ã€ã“ã‚Œã‹ã‚‰ã‚‚ã£ã¨ã™ã”ããªã‚‹ã‚“ã˜ã‚ƒãªã„ã§ã™ã‹ï¼Ÿ â€œ

[![MOVIE2](http://img.youtube.com/vi/EmdQdvBt3xk/0.jpg)](http://www.youtube.com/watch?v=EmdQdvBt3xk "ç¦å²¡é•·æµœæµ·é®®å¸‚å ´ 2024å¹´11æœˆæ–°é–‹å¹•æµ·é®®é£Ÿå ‚è¶…ä¸­ä¼ï¼Ÿï¼Googleè©•åˆ†åªæœ‰2.4ğŸ˜±ï½œ é•·æµœæµ·é®®å¸‚å ´ é­šæ¥­æ¨é€²è¨­æ–½")

Céƒ¨é•· : â€œã‚“ï¼ï¼Ÿ**ã€Œä¸­ä¼ã€**ã£ã¦ï¼Ÿâ€œ

QEU:FOUNDER ï¼š â€œä¸­ä¼ã£ã¦ã€é£Ÿã¹ç‰©ã§ã„ã†ã¨ã€ä¸€è¨€ã€**ã€Œã¾ãšã„ã€**ã¨ã„ã†ã“ã¨ã§ã™ï¼ˆç¬‘ï¼‰ã€‚å¤–å›½ã‹ã‚‰ã®è¦³å…‰å®¢ã¯ã€Jå›½ã®æ–‡åŒ–ã€é¢¨æ™¯ã‚„é£Ÿäº‹ã‚’å…¨ä½“çš„ã«ãƒ—ãƒ©ã‚¹ã«è©•ä¾¡ã—ã¦ã„ã‚‹ä¸€æ–¹ã§ã€ã‚ˆã‚Šç´°ã‹ãè¨ˆæ¸¬ã—ã€**éƒ¨åˆ†çš„ã«ã¯ã‚·ãƒ“ã‚¢ãªè©•ä¾¡ã‚’ã—ã¦ã„ã‚‹**ã‚“ã§ã™ã€‚ãã—ã¦ã€ã“ã®ä¸­ä¼ã®æœ¬è³ªçš„ãªå•é¡Œã¨ã¯ãƒ»ãƒ»ãƒ»ã€‚â€

Céƒ¨é•· : â€œä¸­ä¼ã®å•é¡Œã¨ã¯ãƒ»ãƒ»ãƒ»ï¼Ÿâ€œ

[![MOVIE3](http://img.youtube.com/vi/MsORq4sb594/0.jpg)](http://www.youtube.com/watch?v=MsORq4sb594 "è‡ªæ°‘å…šãŒæ°—ä»˜ã‹ãªã„ææ€–ã®é£Ÿç³§å•é¡Œã€‚æœ€æ—©é€ƒã’å ´ãªã—ï¼è‚¥æ–™ã‚‚ãªã„ã€è¾²å®¶ã¯é«˜é½¢åŒ–ã€ç¨®ã‚‚ãªã„ã€‚")

QEU:FOUNDER ï¼š â€œJå›½ã®ã‚µãƒ—ãƒ©ã‚¤ã‚¢ãŒç„¡ç†ã‚’ã—éãã¦ã„ã‚‹ã‚“ã ã¨æ€ã„ã¾ã™ã€‚ä¾‹ãˆã¦ã¿ã‚Œã°ã€**ã€Œã¦ã‚“ã·ã‚‰å±‹ãŒã¦ã‚“ã·ã‚‰ä¸¼ã®ä¸Šã«æœ­æŸã‚’è¼‰ã›ã¦ãŠå®¢ã«æ¸¡ã—ã¦ã„ã‚‹ã€**ã‚ˆã†ãªã‚‚ã®ã§ã™ã€‚â€

Céƒ¨é•· : â€œè¨€ã£ã¦ã„ã‚‹æ„å‘³ãŒã‚ˆãã‚ã‹ã‚Šã¾ã›ã‚“ãƒ»ãƒ»ãƒ»(ç¬‘)ã€‚ â€œ

QEU:FOUNDER ï¼š â€œ**åŒã˜é£Ÿã„ç‰©ã‚’å¤–å›½ã§é£Ÿã¹ã¦ã¿ï¼Ÿ2å€ã€æ¬§ç±³ã§ã¯3å€ã®å€¤æ®µãŒã™ã‚‹ãï¼ï¼**ã„ã¾ã€å¤–å›½äººãŒã€Œï¼ˆJå›½ã®é£Ÿã¹ç‰©ã¯ï¼‰ã‚„ã™ã„ã†ã¾ã„ã€ã§å–œã‚“ã§ã„ã‚‹ãŒã€ãã‚ŒãŒå¯èƒ½ãªã®ã¯ã€Jå›½ã®ã‚µãƒ—ãƒ©ã‚¤ã‚¢ãŒå¸¸ã«ç„¡ç†ã‚’ã—ã¦ã„ã‚‹ã‹ã‚‰ãƒ»ãƒ»ãƒ»ã€‚é€†ã®è§’åº¦ã‹ã‚‰è¨€ã†ã¨ã€Jå›½ãŒå…ƒå…ˆé€²å›½ãªã®ã§ã€ã„ã¾ã®ã¨ã“ã‚å°‘ã—ã ã‘ä½“åŠ›ãŒæ®‹ã£ã¦ã„ã‚‹ã‹ã‚‰ã€ãªã‚“ã¨ã‹ãªã£ã¦ã„ã‚‹ã‚“ã§ã™ã€‚ã‚ã¨3å¹´ãã‚‰ã„ã˜ã‚ƒãªã„ã‹ï¼Ÿ**ã ã‚“ã ã‚“ã¨è³ªãŒè½ã¡ã¦ãã‚‹**ã€‚â€

![imageSMR2-41-7](/2025-01-13-QEUR23_SMNRT27/imageSMR2-41-7.jpg)

QEU:FOUNDER ï¼š â€œJå›½ã®è¾²æ¥­ã£ã¦ã€**å›½éš›çš„ãªè²¿æ˜“å”è­°ã®ä¸­ã§ã¤ã­ã«äº¤æ¸‰å–å¼•ã®ãƒã‚¿ã«ã•ã‚Œã¦ã€ãã®çµæœã¨ã—ã¦å¼±ä½“åŒ–ã‚’ã—ã¤ã¥ã‘ãŸ**ã˜ã‚ƒãªã„ã§ã™ã‹ã€‚ãŸã—ã‹ã€è‡ªçµ¦ç‡ãŒã²ã©ã„ã“ã¨ã«ãªã£ã¦ã„ã‚‹ã¨ã‹ãƒ»ãƒ»ãƒ»ã€‚â€

Céƒ¨é•· : â€œãã—ã¦ã€Jå›½ãŒè¾²æ¥­ã‚’çŠ ç‰²ã«ã—ã€ãã®ã‹ã‚ã‚Šã¨ã—ã¦æœ€ã‚‚é‡è¦–ã—ã¦ã„ãŸåˆ†é‡ãŒ**EVã®æ™®åŠã¨ã¨ã‚‚ã«å¤§ã„ã«ã‚³ã‚±ãŸï¼**â€œ

QEU:FOUNDER ï¼š â€œã‚¤ãƒ³ãƒã‚¦ãƒ³ãƒ‰ã§ã¯ã€è¾²æ¥­ãŒã‚ˆã‚Šé‡è¦ã«ãªã‚‹ã®ã ãŒã€æœãŸã—ã¦è¾²æ¥­ã®å¾©èˆˆã¯é–“ã«åˆã†ã®ã‹ï¼Ÿâ€

Céƒ¨é•· : â€œ**ã€ŒJå›½æ–™ç†ï¼Ÿã¨ã¦ã‚‚ã¾ãšãã¦é£Ÿã¹ã‚‰ã‚Œãªã„ã‚ˆãƒ»ãƒ»ãƒ»ã€**ã¨ã€ãŠå®¢ãŒè¨€ã„å‡ºã—ã¦é€ƒã’ã‚‹ã®ãŒé€Ÿã„ã‹ãƒ»ãƒ»ãƒ»ã€‚ â€œ
